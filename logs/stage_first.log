2025-12-23 21:10:17,979 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,979 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:10:17,979 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:10:17,979 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,979 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:10:17,979 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,979 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:10:17,979 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:10:17,980 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:10:17,980 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:10:17,980 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:10:17,981 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:10:17,981 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,981 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:10:17,981 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,981 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:10:17,981 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:10:17,981 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:10:22,457 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 3,4
2025-12-23 21:10:22,457 - inference.local_inference - INFO - ============================================================
2025-12-23 21:10:22,457 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:10:22,457 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:10:22,457 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - 数据集名称: gsm8k
2025-12-23 21:18:04,810 - __main__ - INFO - 数据集路径: dataset/gsm8k/test.jsonl
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - 使用数据集适配层加载: gsm8k
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - [数据集适配层] 开始加载数据集: gsm8k
2025-12-23 21:18:04,810 - __main__ - INFO - [数据集适配层] 文件路径: dataset/gsm8k/test.jsonl
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,814 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 1319 条
2025-12-23 21:18:04,814 - __main__ - INFO - 预处理 GSM8K 数据集: 1319 条
2025-12-23 21:18:04,815 - __main__ - INFO - [数据集适配层] 预处理完成: 1319 条有效数据
2025-12-23 21:18:04,815 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:18:04,815 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,815 - __main__ - INFO - 数据集加载成功，共 1319 条数据
2025-12-23 21:18:04,815 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,815 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:18:04,815 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,815 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:18:04,816 - __main__ - INFO - 共需处理 1319 条数据，批次大小: 64
2025-12-23 21:18:04,816 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,816 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:18:04,816 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,816 - __main__ - INFO - 处理批次 [1-128/1319]
2025-12-23 21:18:04,816 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:18:04,816 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:18:09,265 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 3,4
2025-12-23 21:18:09,266 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:09,266 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:18:09,266 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:18:09,266 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:18,317 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,317 - __main__ - INFO - 数据集名称: math
2025-12-23 21:18:18,317 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:18:18,317 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,317 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:18:18,317 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,318 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:18:18,318 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:18:18,318 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:18:18,321 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:18:18,321 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:18:18,321 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:18:18,321 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:18:18,321 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:18:18,321 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:18:18,323 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:18:18,323 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,323 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:18:18,323 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,323 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:18:18,323 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:18:18,323 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:18:22,920 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:18:22,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:22,920 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:18:22,920 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:18:22,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - 数据集名称: svamp
2025-12-23 21:18:37,402 - __main__ - INFO - 数据集路径: dataset/svamp/test.json
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - 使用数据集适配层加载: svamp
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - [数据集适配层] 开始加载数据集: svamp
2025-12-23 21:18:37,402 - __main__ - INFO - [数据集适配层] 文件路径: dataset/svamp/test.json
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:18:37,403 - __main__ - INFO - 预处理 SVAMP 数据集: 300 条
2025-12-23 21:18:37,403 - __main__ - INFO - [数据集适配层] 预处理完成: 300 条有效数据
2025-12-23 21:18:37,403 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:18:37,403 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - 数据集加载成功，共 300 条数据
2025-12-23 21:18:37,403 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:18:37,403 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:18:37,404 - __main__ - INFO - 共需处理 300 条数据，批次大小: 64
2025-12-23 21:18:37,404 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,404 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:18:37,404 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,404 - __main__ - INFO - 处理批次 [1-128/300]
2025-12-23 21:18:37,404 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:18:37,404 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:18:41,920 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-23 21:18:41,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:41,920 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:18:41,920 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:18:41,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:27:43,309 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:27:43,309 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,311 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:27:43,311 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:27:43,311 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:27:43,311 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:27:43,311 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,311 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:27:43,311 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,311 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:27:43,311 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,312 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:27:43,313 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:27:43,313 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,313 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:27:43,313 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,313 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:27:43,313 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:27:43,313 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:27:49,749 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-23 21:27:49,749 - inference.local_inference - INFO - ============================================================
2025-12-23 21:27:49,749 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:27:49,749 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:27:49,749 - inference.local_inference - INFO - ============================================================
2025-12-23 21:28:45,832 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:28:53,577 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:28:53,578 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,031 - __main__ - INFO - 数据集名称: math
2025-12-23 21:28:58,031 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,031 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,031 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:28:58,031 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:28:58,037 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:28:58,037 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:28:58,037 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:28:58,037 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:28:58,037 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:28:58,037 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:28:58,038 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:28:58,038 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,038 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:28:58,038 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,038 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:28:58,038 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:28:58,038 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:29:02,453 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:29:02,454 - inference.local_inference - INFO - ============================================================
2025-12-23 21:29:02,454 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:29:02,454 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:29:02,454 - inference.local_inference - INFO - ============================================================
2025-12-23 21:29:57,521 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:30:37,035 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:30:37,036 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:31:28,875 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:31:28,876 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:32:58,940 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:32:58,941 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-23 21:32:58,941 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-23 21:32:58,941 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-23 21:33:03,766 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:33:03,766 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:33:07,625 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-23 21:33:07,625 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-23 21:34:43,583 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:34:43,583 - __main__ - INFO - 处理批次 [129-256/500]
2025-12-23 21:34:43,584 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:34:43,584 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:35:25,482 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:35:25,482 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:35:33,555 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-23 21:35:33,555 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,090 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:36:38,090 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,090 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,090 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:36:38,090 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:36:38,091 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:36:38,091 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:36:38,091 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:36:38,091 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:36:38,091 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:36:38,091 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:36:38,092 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:36:38,092 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,092 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:36:38,092 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,092 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:36:38,092 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:36:38,092 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:36:42,512 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-23 21:36:42,512 - inference.local_inference - INFO - ============================================================
2025-12-23 21:36:42,512 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:36:42,512 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:36:42,512 - inference.local_inference - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - 数据集名称: math
2025-12-23 21:36:55,809 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:36:55,809 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,812 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:36:55,812 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:36:55,812 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:36:55,812 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:36:55,812 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,812 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:36:55,812 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,812 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:36:55,812 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,813 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:36:55,813 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:36:55,813 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,813 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:36:55,813 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,813 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:36:55,813 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:36:55,813 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:37:00,126 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:37:00,126 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:00,126 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:37:00,126 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:37:00,126 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:13,582 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,582 - __main__ - INFO - 数据集名称: svamp
2025-12-23 21:37:13,582 - __main__ - INFO - 数据集路径: dataset/svamp/test.json
2025-12-23 21:37:13,583 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,583 - __main__ - INFO - 使用数据集适配层加载: svamp
2025-12-23 21:37:13,583 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,583 - __main__ - INFO - [数据集适配层] 开始加载数据集: svamp
2025-12-23 21:37:13,583 - __main__ - INFO - [数据集适配层] 文件路径: dataset/svamp/test.json
2025-12-23 21:37:13,583 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:37:13,586 - __main__ - INFO - 预处理 SVAMP 数据集: 300 条
2025-12-23 21:37:13,586 - __main__ - INFO - [数据集适配层] 预处理完成: 300 条有效数据
2025-12-23 21:37:13,586 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:37:13,586 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - 数据集加载成功，共 300 条数据
2025-12-23 21:37:13,586 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:37:13,586 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:37:13,587 - __main__ - INFO - 共需处理 300 条数据，批次大小: 64
2025-12-23 21:37:13,587 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,587 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:37:13,587 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,587 - __main__ - INFO - 处理批次 [1-128/300]
2025-12-23 21:37:13,587 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:37:13,587 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:37:18,053 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-23 21:37:18,053 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:18,053 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:37:18,053 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:37:18,053 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:38,586 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:37:46,719 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:37:46,720 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:37:59,025 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:38:13,900 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:38:28,331 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:38:28,332 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:38:37,409 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:38:37,409 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:39:59,709 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:39:59,710 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:39:59,710 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,711 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:39:59,712 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:39:59,712 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,712 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:39:59,712 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,712 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:39:59,712 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:39:59,712 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:40:04,038 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-23 21:40:04,038 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:04,038 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:40:04,038 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:40:04,038 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:11,591 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,591 - __main__ - INFO - 数据集名称: math
2025-12-23 21:40:11,591 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:40:11,592 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,592 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:40:11,592 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,592 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:40:11,592 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:40:11,592 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:40:11,595 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:40:11,595 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:40:11,595 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:40:11,595 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:40:11,595 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:40:11,595 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:40:16,050 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:40:16,050 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:16,050 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:40:16,050 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:40:16,050 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:31,427 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,427 - __main__ - INFO - 数据集名称: svamp
2025-12-23 21:40:31,427 - __main__ - INFO - 数据集路径: dataset/svamp/test.json
2025-12-23 21:40:31,428 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,428 - __main__ - INFO - 使用数据集适配层加载: svamp
2025-12-23 21:40:31,428 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,428 - __main__ - INFO - [数据集适配层] 开始加载数据集: svamp
2025-12-23 21:40:31,428 - __main__ - INFO - [数据集适配层] 文件路径: dataset/svamp/test.json
2025-12-23 21:40:31,428 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,428 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:40:31,428 - __main__ - INFO - 预处理 SVAMP 数据集: 300 条
2025-12-23 21:40:31,429 - __main__ - INFO - [数据集适配层] 预处理完成: 300 条有效数据
2025-12-23 21:40:31,429 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 数据集加载成功，共 300 条数据
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:40:31,429 - __main__ - INFO - 共需处理 300 条数据，批次大小: 64
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 处理批次 [1-128/300]
2025-12-23 21:40:31,429 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:40:31,429 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:40:35,860 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-23 21:40:35,860 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:35,860 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:40:35,860 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:40:35,860 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:59,212 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:41:07,460 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:41:07,461 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:41:11,878 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:41:32,625 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:41:43,907 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:41:43,907 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:41:48,858 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:41:48,859 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:43:41,028 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:43:41,029 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:44:01,566 - __main__ - INFO - ============================================================
2025-12-23 21:44:01,567 - __main__ - INFO - 数据集名称: mmlu
2025-12-23 21:44:01,567 - __main__ - INFO - 数据集路径: dataset/mmlu_json/auxiliary_train.json
2025-12-23 21:44:01,567 - __main__ - INFO - ============================================================
2025-12-23 21:44:01,567 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-23 21:44:01,567 - __main__ - INFO - ============================================================
2025-12-23 21:44:01,567 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-23 21:44:01,567 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu_json/auxiliary_train.json
2025-12-23 21:44:01,567 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,507 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:44:04,507 - __main__ - INFO - 预处理 MMLU 数据集: 99842 条
2025-12-23 21:44:04,593 - __main__ - INFO - [数据集适配层] 预处理完成: 99842 条有效数据
2025-12-23 21:44:04,593 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:44:04,593 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,618 - __main__ - INFO - 数据集加载成功，共 99842 条数据
2025-12-23 21:44:04,620 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,622 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:44:04,626 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,627 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:44:04,665 - __main__ - INFO - 共需处理 99842 条数据，批次大小: 64
2025-12-23 21:44:04,665 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,665 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:44:04,665 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,665 - __main__ - INFO - 处理批次 [1-128/99842]
2025-12-23 21:44:04,665 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:44:04,665 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:44:09,458 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-23 21:44:09,459 - inference.local_inference - INFO - ============================================================
2025-12-23 21:44:09,459 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:44:09,459 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:44:09,459 - inference.local_inference - INFO - ============================================================
2025-12-23 21:44:11,674 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:44:11,674 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:44:14,742 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:44:14,742 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:45:18,287 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:45:18,288 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-23 21:45:18,288 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-23 21:45:18,288 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-23 21:45:19,754 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:45:27,105 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-23 21:45:27,105 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-23 21:45:40,449 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:45:40,449 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:45:51,368 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:45:51,369 - __main__ - INFO - 处理批次 [129-256/300]
2025-12-23 21:45:51,369 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:45:51,369 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:45:57,029 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:45:57,029 - __main__ - INFO - 处理批次 [129-256/500]
2025-12-23 21:45:57,030 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:45:57,030 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:46:01,664 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:46:01,664 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:46:32,801 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:46:32,801 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:47:58,148 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-23 21:47:58,148 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-23 21:48:04,597 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:48:04,597 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:48:34,400 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:48:34,400 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:48:54,932 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:48:54,932 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:49:33,034 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-23 21:49:33,034 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-23 21:49:33,034 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-23 21:49:33,074 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-23 21:49:33,074 - __main__ - INFO - ============================================================
2025-12-23 21:49:33,074 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-23 21:49:33,074 - __main__ - INFO - ============================================================
2025-12-23 21:49:33,074 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-23 21:49:33,075 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-23 21:49:33,075 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:49:43,786 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:49:43,786 - __main__ - INFO - 处理批次 [129-256/99842]
2025-12-23 21:49:43,787 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:49:43,787 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:50:05,036 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:50:05,037 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:50:10,173 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-23 21:50:10,173 - __main__ - INFO - 处理批次 [257-300/300]
2025-12-23 21:50:10,173 - __main__ - INFO -   → 生成Baseline答案 (44 条)...
2025-12-23 21:50:10,173 - __main__ - INFO - 批量生成Baseline答案: 44 条
2025-12-23 21:50:16,815 - __main__ - INFO -   → 生成差异分析 (44 条)...
2025-12-23 21:50:16,815 - __main__ - INFO - 批量生成差异分析: 44 条
2025-12-23 21:50:41,585 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-23 21:50:41,585 - __main__ - INFO - 处理批次 [257-384/500]
2025-12-23 21:50:41,585 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:50:41,585 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:50:59,458 - __main__ - INFO - API批次 [1-30] 完成
2025-12-23 21:50:59,458 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-23 21:50:59,458 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:51:36,383 - __main__ - INFO - API批次 [31-60] 完成
2025-12-23 21:51:36,384 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-23 21:51:36,384 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:51:37,952 - __main__ - INFO -   → 生成Rejected原则 (44 条)...
2025-12-23 21:51:37,953 - __main__ - INFO - 批量生成原则（弱模型）: 44 条
2025-12-23 21:51:46,404 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:51:46,404 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:51:46,465 - inference.local_inference - ERROR - 批量推理失败: Prompt length of 4383 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4383 is longer than the maximum model length of 4096.
2025-12-23 21:51:46,468 - __main__ - ERROR - 生成DPO数据时发生错误: Prompt length of 4383 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/stage_first.py", line 434, in prepare_stage1
    diffs = batch_generate_differences(questions, baseline_answers, labels)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/stage_first.py", line 343, in batch_generate_differences
    return batch_generate_difference_list(questions, preds, labels)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/module/plan_module.py", line 78, in batch_generate_difference_list
    return batch_inference(prompts)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4383 is longer than the maximum model length of 4096.
2025-12-23 21:51:47,539 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 21:51:47,539 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-23 21:52:15,143 - __main__ - INFO - API批次 [61-90] 完成
2025-12-23 21:52:15,144 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-23 21:52:15,144 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:52:31,529 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:52:31,530 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:52:35,803 - __main__ - INFO - 批次 [257-300] 本地推理完成
2025-12-23 21:52:35,804 - __main__ - INFO - 阶段1完成: 共生成 300 条本地推理结果
2025-12-23 21:52:35,804 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-23 21:52:35,855 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-23 21:52:35,855 - __main__ - INFO - ============================================================
2025-12-23 21:52:35,855 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-23 21:52:35,855 - __main__ - INFO - ============================================================
2025-12-23 21:52:35,855 - __main__ - INFO - API分批处理: 每批 30 条，共 10 批
2025-12-23 21:52:35,855 - __main__ - INFO - API批次 [1-30/300] 开始处理...
2025-12-23 21:52:35,855 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:52:54,841 - __main__ - INFO - API批次 [91-120] 完成
2025-12-23 21:52:54,842 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-23 21:52:54,842 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:53:13,115 - __main__ - INFO - API批次 [1-30] 完成
2025-12-23 21:53:13,116 - __main__ - INFO - API批次 [31-60/300] 开始处理...
2025-12-23 21:53:13,117 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:53:59,545 - __main__ - INFO - API批次 [31-60] 完成
2025-12-23 21:53:59,545 - __main__ - INFO - API批次 [61-90/300] 开始处理...
2025-12-23 21:53:59,545 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:54:03,013 - __main__ - INFO - API批次 [121-150] 完成
2025-12-23 21:54:03,014 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-23 21:54:03,014 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:54:09,350 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-23 21:54:09,351 - __main__ - INFO - 处理批次 [257-384/99842]
2025-12-23 21:54:09,352 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:54:09,352 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:54:31,245 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:54:31,245 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:54:34,092 - __main__ - INFO - API批次 [61-90] 完成
2025-12-23 21:54:34,093 - __main__ - INFO - API批次 [91-120/300] 开始处理...
2025-12-23 21:54:34,094 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:54:49,409 - __main__ - INFO - API批次 [151-180] 完成
2025-12-23 21:54:49,410 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-23 21:54:49,410 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:55:15,950 - __main__ - INFO - API批次 [91-120] 完成
2025-12-23 21:55:15,951 - __main__ - INFO - API批次 [121-150/300] 开始处理...
2025-12-23 21:55:15,951 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:55:31,030 - __main__ - INFO - API批次 [181-210] 完成
2025-12-23 21:55:31,031 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-23 21:55:31,031 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:00,585 - __main__ - INFO - API批次 [211-240] 完成
2025-12-23 21:56:00,586 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-23 21:56:00,586 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:03,028 - __main__ - INFO - API批次 [121-150] 完成
2025-12-23 21:56:03,029 - __main__ - INFO - API批次 [151-180/300] 开始处理...
2025-12-23 21:56:03,029 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:29,906 - __main__ - INFO - API批次 [241-250] 完成
2025-12-23 21:56:29,907 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-23 21:56:29,907 - __main__ - INFO - 开始数据质量检查...
2025-12-23 21:56:29,907 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-23 21:56:29,907 - __main__ - INFO - ============================================================
2025-12-23 21:56:29,907 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-23 21:56:29,907 - __main__ - INFO - ============================================================
2025-12-23 21:56:29,908 - __main__ - INFO - 预检查数据完整性...
2025-12-23 21:56:29,908 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-23 21:56:29,909 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-23 21:56:29,909 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-23 21:56:29,923 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-23 21:56:29,942 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-23 21:56:29,953 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-23 21:56:29,964 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-23 21:56:29,975 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-23 21:56:29,985 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-23 21:56:29,985 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-23 21:56:30,962 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 21:56:30,990 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-23 21:56:37,633 - __main__ - INFO - API批次 [151-180] 完成
2025-12-23 21:56:37,634 - __main__ - INFO - API批次 [181-210/300] 开始处理...
2025-12-23 21:56:37,634 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:56,208 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:56:56,208 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:57:03,165 - __main__ - INFO - API批次 [181-210] 完成
2025-12-23 21:57:03,166 - __main__ - INFO - API批次 [211-240/300] 开始处理...
2025-12-23 21:57:03,166 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:57:36,091 - __main__ - INFO - API批次 [211-240] 完成
2025-12-23 21:57:36,091 - __main__ - INFO - API批次 [241-270/300] 开始处理...
2025-12-23 21:57:36,092 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:58:29,351 - __main__ - INFO - API批次 [241-270] 完成
2025-12-23 21:58:29,352 - __main__ - INFO - API批次 [271-300/300] 开始处理...
2025-12-23 21:58:29,352 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:58:36,679 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-23 21:58:36,679 - __main__ - INFO - 处理批次 [385-512/99842]
2025-12-23 21:58:36,680 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:58:36,680 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:58:59,087 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:58:59,087 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:59:05,385 - __main__ - INFO - API批次 [271-300] 完成
2025-12-23 21:59:05,385 - __main__ - INFO - 阶段2完成: 共生成 300 条Chosen结果
2025-12-23 21:59:05,385 - __main__ - INFO - 开始数据质量检查...
2025-12-23 21:59:05,385 - __main__ - INFO - ✅ 数据质量检查通过: 300 条chosen全部非空
2025-12-23 21:59:05,385 - __main__ - INFO - ============================================================
2025-12-23 21:59:05,385 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-23 21:59:05,385 - __main__ - INFO - ============================================================
2025-12-23 21:59:05,385 - __main__ - INFO - 预检查数据完整性...
2025-12-23 21:59:05,386 - __main__ - INFO - Chosen非空率: 300/300 (100.0%)
2025-12-23 21:59:05,386 - __main__ - INFO - Rejected非空率: 300/300 (100.0%)
2025-12-23 21:59:05,386 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-23 21:59:05,395 - __main__ - INFO - 已保存 50/300 条到JSONL
2025-12-23 21:59:05,408 - __main__ - INFO - 已保存 100/300 条到JSONL
2025-12-23 21:59:05,422 - __main__ - INFO - 已保存 150/300 条到JSONL
2025-12-23 21:59:05,433 - __main__ - INFO - 已保存 200/300 条到JSONL
2025-12-23 21:59:05,444 - __main__ - INFO - 已保存 250/300 条到JSONL
2025-12-23 21:59:05,454 - __main__ - INFO - 已保存 300/300 条到JSONL
2025-12-23 21:59:05,466 - __main__ - INFO - DPO数据生成完成: output/dpo_svamp.jsonl
2025-12-23 21:59:05,466 - __main__ - INFO - 共保存 300 条数据到JSONL格式
2025-12-23 21:59:06,344 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 21:59:06,374 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-23 22:01:23,248 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:01:23,248 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:03:06,065 - __main__ - INFO - 批次 [385-512] 本地推理完成
2025-12-23 22:03:06,065 - __main__ - INFO - 处理批次 [513-640/99842]
2025-12-23 22:03:06,066 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:03:06,066 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:03:31,499 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:03:31,499 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:05:55,840 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:05:55,841 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:07:37,633 - __main__ - INFO - 批次 [513-640] 本地推理完成
2025-12-23 22:07:37,633 - __main__ - INFO - 处理批次 [641-768/99842]
2025-12-23 22:07:37,634 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:07:37,634 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:07:59,638 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:07:59,639 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:10:25,101 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:10:25,101 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:12:04,083 - __main__ - INFO - 批次 [641-768] 本地推理完成
2025-12-23 22:12:04,084 - __main__ - INFO - 处理批次 [769-896/99842]
2025-12-23 22:12:04,085 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:12:04,085 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:12:25,756 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:12:25,757 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:14:50,528 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:14:50,528 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:16:31,990 - __main__ - INFO - 批次 [769-896] 本地推理完成
2025-12-23 22:16:31,991 - __main__ - INFO - 处理批次 [897-1024/99842]
2025-12-23 22:16:31,991 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:16:31,991 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:16:54,942 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:16:54,942 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:19:19,847 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:19:19,847 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:20:57,342 - __main__ - INFO - 批次 [897-1024] 本地推理完成
2025-12-23 22:20:57,343 - __main__ - INFO - 处理批次 [1025-1152/99842]
2025-12-23 22:20:57,343 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:20:57,343 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:21:18,254 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:21:18,255 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:23:47,016 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:23:47,016 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:25:25,433 - __main__ - INFO - 批次 [1025-1152] 本地推理完成
2025-12-23 22:25:25,433 - __main__ - INFO - 处理批次 [1153-1280/99842]
2025-12-23 22:25:25,433 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:25:25,433 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:25:40,751 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:25:40,751 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:28:13,186 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:28:13,186 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:29:49,603 - __main__ - INFO - 批次 [1153-1280] 本地推理完成
2025-12-23 22:29:49,603 - __main__ - INFO - 处理批次 [1281-1408/99842]
2025-12-23 22:29:49,603 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:29:49,603 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:30:01,548 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:30:01,548 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:32:34,159 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:32:34,159 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:34:15,100 - __main__ - INFO - 批次 [1281-1408] 本地推理完成
2025-12-23 22:34:15,101 - __main__ - INFO - 处理批次 [1409-1536/99842]
2025-12-23 22:34:15,101 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:34:15,101 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:34:27,799 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:34:27,799 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:37:00,738 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:37:00,738 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:38:36,984 - __main__ - INFO - 批次 [1409-1536] 本地推理完成
2025-12-23 22:38:36,985 - __main__ - INFO - 处理批次 [1537-1664/99842]
2025-12-23 22:38:36,985 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:38:36,986 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:38:49,396 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:38:49,397 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:41:22,991 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:41:22,992 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:42:57,153 - __main__ - INFO - 批次 [1537-1664] 本地推理完成
2025-12-23 22:42:57,154 - __main__ - INFO - 处理批次 [1665-1792/99842]
2025-12-23 22:42:57,154 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:42:57,154 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:43:57,395 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:43:57,395 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:43:57,497 - inference.local_inference - ERROR - 批量推理失败: Prompt length of 4386 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4386 is longer than the maximum model length of 4096.
2025-12-23 22:43:57,499 - __main__ - ERROR - 生成DPO数据时发生错误: Prompt length of 4386 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/stage_first.py", line 434, in prepare_stage1
    diffs = batch_generate_differences(questions, baseline_answers, labels)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/stage_first.py", line 343, in batch_generate_differences
    return batch_generate_difference_list(questions, preds, labels)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/module/plan_module.py", line 78, in batch_generate_difference_list
    return batch_inference(prompts)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4386 is longer than the maximum model length of 4096.
2025-12-23 22:43:58,979 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 22:43:58,979 - inference.local_inference - INFO - CUDA缓存已清理
