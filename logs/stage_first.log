2025-12-23 21:10:17,979 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,979 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:10:17,979 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:10:17,979 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,979 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:10:17,979 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,979 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:10:17,979 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:10:17,980 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:10:17,980 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:10:17,980 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:10:17,980 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,980 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:10:17,981 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:10:17,981 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,981 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:10:17,981 - __main__ - INFO - ============================================================
2025-12-23 21:10:17,981 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:10:17,981 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:10:17,981 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:10:22,457 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 3,4
2025-12-23 21:10:22,457 - inference.local_inference - INFO - ============================================================
2025-12-23 21:10:22,457 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:10:22,457 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:10:22,457 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - 数据集名称: gsm8k
2025-12-23 21:18:04,810 - __main__ - INFO - 数据集路径: dataset/gsm8k/test.jsonl
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - 使用数据集适配层加载: gsm8k
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,810 - __main__ - INFO - [数据集适配层] 开始加载数据集: gsm8k
2025-12-23 21:18:04,810 - __main__ - INFO - [数据集适配层] 文件路径: dataset/gsm8k/test.jsonl
2025-12-23 21:18:04,810 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,814 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 1319 条
2025-12-23 21:18:04,814 - __main__ - INFO - 预处理 GSM8K 数据集: 1319 条
2025-12-23 21:18:04,815 - __main__ - INFO - [数据集适配层] 预处理完成: 1319 条有效数据
2025-12-23 21:18:04,815 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:18:04,815 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,815 - __main__ - INFO - 数据集加载成功，共 1319 条数据
2025-12-23 21:18:04,815 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,815 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:18:04,815 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,815 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:18:04,816 - __main__ - INFO - 共需处理 1319 条数据，批次大小: 64
2025-12-23 21:18:04,816 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,816 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:18:04,816 - __main__ - INFO - ============================================================
2025-12-23 21:18:04,816 - __main__ - INFO - 处理批次 [1-128/1319]
2025-12-23 21:18:04,816 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:18:04,816 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:18:09,265 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 3,4
2025-12-23 21:18:09,266 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:09,266 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:18:09,266 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:18:09,266 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:18,317 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,317 - __main__ - INFO - 数据集名称: math
2025-12-23 21:18:18,317 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:18:18,317 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,317 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:18:18,317 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,318 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:18:18,318 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:18:18,318 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:18:18,321 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:18:18,321 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:18:18,321 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:18:18,321 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:18:18,321 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:18:18,321 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,321 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:18:18,323 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:18:18,323 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,323 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:18:18,323 - __main__ - INFO - ============================================================
2025-12-23 21:18:18,323 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:18:18,323 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:18:18,323 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:18:22,920 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:18:22,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:22,920 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:18:22,920 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:18:22,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - 数据集名称: svamp
2025-12-23 21:18:37,402 - __main__ - INFO - 数据集路径: dataset/svamp/test.json
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - 使用数据集适配层加载: svamp
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,402 - __main__ - INFO - [数据集适配层] 开始加载数据集: svamp
2025-12-23 21:18:37,402 - __main__ - INFO - [数据集适配层] 文件路径: dataset/svamp/test.json
2025-12-23 21:18:37,402 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:18:37,403 - __main__ - INFO - 预处理 SVAMP 数据集: 300 条
2025-12-23 21:18:37,403 - __main__ - INFO - [数据集适配层] 预处理完成: 300 条有效数据
2025-12-23 21:18:37,403 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:18:37,403 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - 数据集加载成功，共 300 条数据
2025-12-23 21:18:37,403 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:18:37,403 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,403 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:18:37,404 - __main__ - INFO - 共需处理 300 条数据，批次大小: 64
2025-12-23 21:18:37,404 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,404 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:18:37,404 - __main__ - INFO - ============================================================
2025-12-23 21:18:37,404 - __main__ - INFO - 处理批次 [1-128/300]
2025-12-23 21:18:37,404 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:18:37,404 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:18:41,920 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-23 21:18:41,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:18:41,920 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:18:41,920 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:18:41,920 - inference.local_inference - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:27:43,309 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,309 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:27:43,309 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:27:43,309 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,311 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:27:43,311 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:27:43,311 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:27:43,311 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:27:43,311 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,311 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:27:43,311 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,311 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:27:43,311 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,312 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:27:43,313 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:27:43,313 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,313 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:27:43,313 - __main__ - INFO - ============================================================
2025-12-23 21:27:43,313 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:27:43,313 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:27:43,313 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:27:49,749 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-23 21:27:49,749 - inference.local_inference - INFO - ============================================================
2025-12-23 21:27:49,749 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:27:49,749 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:27:49,749 - inference.local_inference - INFO - ============================================================
2025-12-23 21:28:45,832 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:28:53,577 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:28:53,578 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,031 - __main__ - INFO - 数据集名称: math
2025-12-23 21:28:58,031 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,031 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,031 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:28:58,031 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:28:58,031 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:28:58,037 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:28:58,037 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:28:58,037 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:28:58,037 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:28:58,037 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:28:58,037 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,037 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:28:58,038 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:28:58,038 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,038 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:28:58,038 - __main__ - INFO - ============================================================
2025-12-23 21:28:58,038 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:28:58,038 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:28:58,038 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:29:02,453 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:29:02,454 - inference.local_inference - INFO - ============================================================
2025-12-23 21:29:02,454 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:29:02,454 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:29:02,454 - inference.local_inference - INFO - ============================================================
2025-12-23 21:29:57,521 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:30:37,035 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:30:37,036 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:31:28,875 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:31:28,876 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:32:58,940 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:32:58,941 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-23 21:32:58,941 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-23 21:32:58,941 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-23 21:33:03,766 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:33:03,766 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:33:07,625 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-23 21:33:07,625 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-23 21:34:43,583 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:34:43,583 - __main__ - INFO - 处理批次 [129-256/500]
2025-12-23 21:34:43,584 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:34:43,584 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:35:25,482 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:35:25,482 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:35:33,555 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-23 21:35:33,555 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,090 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:36:38,090 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,090 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,090 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:36:38,090 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:36:38,090 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:36:38,091 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:36:38,091 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:36:38,091 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:36:38,091 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:36:38,091 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:36:38,091 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,091 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:36:38,092 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:36:38,092 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,092 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:36:38,092 - __main__ - INFO - ============================================================
2025-12-23 21:36:38,092 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:36:38,092 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:36:38,092 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:36:42,512 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-23 21:36:42,512 - inference.local_inference - INFO - ============================================================
2025-12-23 21:36:42,512 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:36:42,512 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:36:42,512 - inference.local_inference - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - 数据集名称: math
2025-12-23 21:36:55,809 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,809 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:36:55,809 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:36:55,809 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,812 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:36:55,812 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:36:55,812 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:36:55,812 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:36:55,812 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,812 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:36:55,812 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,812 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:36:55,812 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,813 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:36:55,813 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:36:55,813 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,813 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:36:55,813 - __main__ - INFO - ============================================================
2025-12-23 21:36:55,813 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:36:55,813 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:36:55,813 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:37:00,126 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:37:00,126 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:00,126 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:37:00,126 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:37:00,126 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:13,582 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,582 - __main__ - INFO - 数据集名称: svamp
2025-12-23 21:37:13,582 - __main__ - INFO - 数据集路径: dataset/svamp/test.json
2025-12-23 21:37:13,583 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,583 - __main__ - INFO - 使用数据集适配层加载: svamp
2025-12-23 21:37:13,583 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,583 - __main__ - INFO - [数据集适配层] 开始加载数据集: svamp
2025-12-23 21:37:13,583 - __main__ - INFO - [数据集适配层] 文件路径: dataset/svamp/test.json
2025-12-23 21:37:13,583 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:37:13,586 - __main__ - INFO - 预处理 SVAMP 数据集: 300 条
2025-12-23 21:37:13,586 - __main__ - INFO - [数据集适配层] 预处理完成: 300 条有效数据
2025-12-23 21:37:13,586 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:37:13,586 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - 数据集加载成功，共 300 条数据
2025-12-23 21:37:13,586 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:37:13,586 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,586 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:37:13,587 - __main__ - INFO - 共需处理 300 条数据，批次大小: 64
2025-12-23 21:37:13,587 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,587 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:37:13,587 - __main__ - INFO - ============================================================
2025-12-23 21:37:13,587 - __main__ - INFO - 处理批次 [1-128/300]
2025-12-23 21:37:13,587 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:37:13,587 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:37:18,053 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-23 21:37:18,053 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:18,053 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:37:18,053 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:37:18,053 - inference.local_inference - INFO - ============================================================
2025-12-23 21:37:38,586 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:37:46,719 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:37:46,720 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:37:59,025 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:38:13,900 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:38:28,331 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:38:28,332 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:38:37,409 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:38:37,409 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:39:59,709 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - 数据集名称: bbh
2025-12-23 21:39:59,710 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:39:59,710 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-23 21:39:59,710 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,710 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:39:59,710 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,711 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:39:59,712 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-23 21:39:59,712 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,712 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:39:59,712 - __main__ - INFO - ============================================================
2025-12-23 21:39:59,712 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-23 21:39:59,712 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:39:59,712 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:40:04,038 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-23 21:40:04,038 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:04,038 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:40:04,038 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:40:04,038 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:11,591 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,591 - __main__ - INFO - 数据集名称: math
2025-12-23 21:40:11,591 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-23 21:40:11,592 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,592 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-23 21:40:11,592 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,592 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-23 21:40:11,592 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-23 21:40:11,592 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-23 21:40:11,595 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-23 21:40:11,595 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-23 21:40:11,595 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:40:11,595 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:40:11,595 - __main__ - INFO - ============================================================
2025-12-23 21:40:11,595 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-23 21:40:11,595 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:40:11,595 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:40:16,050 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-23 21:40:16,050 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:16,050 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:40:16,050 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:40:16,050 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:31,427 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,427 - __main__ - INFO - 数据集名称: svamp
2025-12-23 21:40:31,427 - __main__ - INFO - 数据集路径: dataset/svamp/test.json
2025-12-23 21:40:31,428 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,428 - __main__ - INFO - 使用数据集适配层加载: svamp
2025-12-23 21:40:31,428 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,428 - __main__ - INFO - [数据集适配层] 开始加载数据集: svamp
2025-12-23 21:40:31,428 - __main__ - INFO - [数据集适配层] 文件路径: dataset/svamp/test.json
2025-12-23 21:40:31,428 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,428 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:40:31,428 - __main__ - INFO - 预处理 SVAMP 数据集: 300 条
2025-12-23 21:40:31,429 - __main__ - INFO - [数据集适配层] 预处理完成: 300 条有效数据
2025-12-23 21:40:31,429 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 数据集加载成功，共 300 条数据
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:40:31,429 - __main__ - INFO - 共需处理 300 条数据，批次大小: 64
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:40:31,429 - __main__ - INFO - ============================================================
2025-12-23 21:40:31,429 - __main__ - INFO - 处理批次 [1-128/300]
2025-12-23 21:40:31,429 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:40:31,429 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:40:35,860 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-23 21:40:35,860 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:35,860 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:40:35,860 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:40:35,860 - inference.local_inference - INFO - ============================================================
2025-12-23 21:40:59,212 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:41:07,460 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:41:07,461 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:41:11,878 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:41:32,625 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:41:43,907 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:41:43,907 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:41:48,858 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:41:48,859 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:43:41,028 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:43:41,029 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:44:01,566 - __main__ - INFO - ============================================================
2025-12-23 21:44:01,567 - __main__ - INFO - 数据集名称: mmlu
2025-12-23 21:44:01,567 - __main__ - INFO - 数据集路径: dataset/mmlu_json/auxiliary_train.json
2025-12-23 21:44:01,567 - __main__ - INFO - ============================================================
2025-12-23 21:44:01,567 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-23 21:44:01,567 - __main__ - INFO - ============================================================
2025-12-23 21:44:01,567 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-23 21:44:01,567 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu_json/auxiliary_train.json
2025-12-23 21:44:01,567 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,507 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-23 21:44:04,507 - __main__ - INFO - 预处理 MMLU 数据集: 99842 条
2025-12-23 21:44:04,593 - __main__ - INFO - [数据集适配层] 预处理完成: 99842 条有效数据
2025-12-23 21:44:04,593 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-23 21:44:04,593 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,618 - __main__ - INFO - 数据集加载成功，共 99842 条数据
2025-12-23 21:44:04,620 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,622 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-23 21:44:04,626 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,627 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-23 21:44:04,665 - __main__ - INFO - 共需处理 99842 条数据，批次大小: 64
2025-12-23 21:44:04,665 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,665 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-23 21:44:04,665 - __main__ - INFO - ============================================================
2025-12-23 21:44:04,665 - __main__ - INFO - 处理批次 [1-128/99842]
2025-12-23 21:44:04,665 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:44:04,665 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:44:09,458 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-23 21:44:09,459 - inference.local_inference - INFO - ============================================================
2025-12-23 21:44:09,459 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-23 21:44:09,459 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-23 21:44:09,459 - inference.local_inference - INFO - ============================================================
2025-12-23 21:44:11,674 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:44:11,674 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:44:14,742 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:44:14,742 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:45:18,287 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:45:18,288 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-23 21:45:18,288 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-23 21:45:18,288 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-23 21:45:19,754 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-23 21:45:27,105 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-23 21:45:27,105 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-23 21:45:40,449 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:45:40,449 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:45:51,368 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:45:51,369 - __main__ - INFO - 处理批次 [129-256/300]
2025-12-23 21:45:51,369 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:45:51,369 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:45:57,029 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:45:57,029 - __main__ - INFO - 处理批次 [129-256/500]
2025-12-23 21:45:57,030 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:45:57,030 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:46:01,664 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:46:01,664 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:46:32,801 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:46:32,801 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:47:58,148 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-23 21:47:58,148 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-23 21:48:04,597 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:48:04,597 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:48:34,400 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:48:34,400 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:48:54,932 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:48:54,932 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:49:33,034 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-23 21:49:33,034 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-23 21:49:33,034 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-23 21:49:33,074 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-23 21:49:33,074 - __main__ - INFO - ============================================================
2025-12-23 21:49:33,074 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-23 21:49:33,074 - __main__ - INFO - ============================================================
2025-12-23 21:49:33,074 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-23 21:49:33,075 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-23 21:49:33,075 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:49:43,786 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-23 21:49:43,786 - __main__ - INFO - 处理批次 [129-256/99842]
2025-12-23 21:49:43,787 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:49:43,787 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:50:05,036 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:50:05,037 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:50:10,173 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-23 21:50:10,173 - __main__ - INFO - 处理批次 [257-300/300]
2025-12-23 21:50:10,173 - __main__ - INFO -   → 生成Baseline答案 (44 条)...
2025-12-23 21:50:10,173 - __main__ - INFO - 批量生成Baseline答案: 44 条
2025-12-23 21:50:16,815 - __main__ - INFO -   → 生成差异分析 (44 条)...
2025-12-23 21:50:16,815 - __main__ - INFO - 批量生成差异分析: 44 条
2025-12-23 21:50:41,585 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-23 21:50:41,585 - __main__ - INFO - 处理批次 [257-384/500]
2025-12-23 21:50:41,585 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:50:41,585 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:50:59,458 - __main__ - INFO - API批次 [1-30] 完成
2025-12-23 21:50:59,458 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-23 21:50:59,458 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:51:36,383 - __main__ - INFO - API批次 [31-60] 完成
2025-12-23 21:51:36,384 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-23 21:51:36,384 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:51:37,952 - __main__ - INFO -   → 生成Rejected原则 (44 条)...
2025-12-23 21:51:37,953 - __main__ - INFO - 批量生成原则（弱模型）: 44 条
2025-12-23 21:51:46,404 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:51:46,404 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:51:46,465 - inference.local_inference - ERROR - 批量推理失败: Prompt length of 4383 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4383 is longer than the maximum model length of 4096.
2025-12-23 21:51:46,468 - __main__ - ERROR - 生成DPO数据时发生错误: Prompt length of 4383 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/stage_first.py", line 434, in prepare_stage1
    diffs = batch_generate_differences(questions, baseline_answers, labels)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/stage_first.py", line 343, in batch_generate_differences
    return batch_generate_difference_list(questions, preds, labels)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/module/plan_module.py", line 78, in batch_generate_difference_list
    return batch_inference(prompts)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4383 is longer than the maximum model length of 4096.
2025-12-23 21:51:47,539 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 21:51:47,539 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-23 21:52:15,143 - __main__ - INFO - API批次 [61-90] 完成
2025-12-23 21:52:15,144 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-23 21:52:15,144 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:52:31,529 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:52:31,530 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:52:35,803 - __main__ - INFO - 批次 [257-300] 本地推理完成
2025-12-23 21:52:35,804 - __main__ - INFO - 阶段1完成: 共生成 300 条本地推理结果
2025-12-23 21:52:35,804 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-23 21:52:35,855 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-23 21:52:35,855 - __main__ - INFO - ============================================================
2025-12-23 21:52:35,855 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-23 21:52:35,855 - __main__ - INFO - ============================================================
2025-12-23 21:52:35,855 - __main__ - INFO - API分批处理: 每批 30 条，共 10 批
2025-12-23 21:52:35,855 - __main__ - INFO - API批次 [1-30/300] 开始处理...
2025-12-23 21:52:35,855 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:52:54,841 - __main__ - INFO - API批次 [91-120] 完成
2025-12-23 21:52:54,842 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-23 21:52:54,842 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:53:13,115 - __main__ - INFO - API批次 [1-30] 完成
2025-12-23 21:53:13,116 - __main__ - INFO - API批次 [31-60/300] 开始处理...
2025-12-23 21:53:13,117 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:53:59,545 - __main__ - INFO - API批次 [31-60] 完成
2025-12-23 21:53:59,545 - __main__ - INFO - API批次 [61-90/300] 开始处理...
2025-12-23 21:53:59,545 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:54:03,013 - __main__ - INFO - API批次 [121-150] 完成
2025-12-23 21:54:03,014 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-23 21:54:03,014 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:54:09,350 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-23 21:54:09,351 - __main__ - INFO - 处理批次 [257-384/99842]
2025-12-23 21:54:09,352 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:54:09,352 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:54:31,245 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:54:31,245 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:54:34,092 - __main__ - INFO - API批次 [61-90] 完成
2025-12-23 21:54:34,093 - __main__ - INFO - API批次 [91-120/300] 开始处理...
2025-12-23 21:54:34,094 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:54:49,409 - __main__ - INFO - API批次 [151-180] 完成
2025-12-23 21:54:49,410 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-23 21:54:49,410 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:55:15,950 - __main__ - INFO - API批次 [91-120] 完成
2025-12-23 21:55:15,951 - __main__ - INFO - API批次 [121-150/300] 开始处理...
2025-12-23 21:55:15,951 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:55:31,030 - __main__ - INFO - API批次 [181-210] 完成
2025-12-23 21:55:31,031 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-23 21:55:31,031 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:00,585 - __main__ - INFO - API批次 [211-240] 完成
2025-12-23 21:56:00,586 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-23 21:56:00,586 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:03,028 - __main__ - INFO - API批次 [121-150] 完成
2025-12-23 21:56:03,029 - __main__ - INFO - API批次 [151-180/300] 开始处理...
2025-12-23 21:56:03,029 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:29,906 - __main__ - INFO - API批次 [241-250] 完成
2025-12-23 21:56:29,907 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-23 21:56:29,907 - __main__ - INFO - 开始数据质量检查...
2025-12-23 21:56:29,907 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-23 21:56:29,907 - __main__ - INFO - ============================================================
2025-12-23 21:56:29,907 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-23 21:56:29,907 - __main__ - INFO - ============================================================
2025-12-23 21:56:29,908 - __main__ - INFO - 预检查数据完整性...
2025-12-23 21:56:29,908 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-23 21:56:29,909 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-23 21:56:29,909 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-23 21:56:29,923 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-23 21:56:29,942 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-23 21:56:29,953 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-23 21:56:29,964 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-23 21:56:29,975 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-23 21:56:29,985 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-23 21:56:29,985 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-23 21:56:30,962 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 21:56:30,990 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-23 21:56:37,633 - __main__ - INFO - API批次 [151-180] 完成
2025-12-23 21:56:37,634 - __main__ - INFO - API批次 [181-210/300] 开始处理...
2025-12-23 21:56:37,634 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:56:56,208 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 21:56:56,208 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 21:57:03,165 - __main__ - INFO - API批次 [181-210] 完成
2025-12-23 21:57:03,166 - __main__ - INFO - API批次 [211-240/300] 开始处理...
2025-12-23 21:57:03,166 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:57:36,091 - __main__ - INFO - API批次 [211-240] 完成
2025-12-23 21:57:36,091 - __main__ - INFO - API批次 [241-270/300] 开始处理...
2025-12-23 21:57:36,092 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:58:29,351 - __main__ - INFO - API批次 [241-270] 完成
2025-12-23 21:58:29,352 - __main__ - INFO - API批次 [271-300/300] 开始处理...
2025-12-23 21:58:29,352 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-23 21:58:36,679 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-23 21:58:36,679 - __main__ - INFO - 处理批次 [385-512/99842]
2025-12-23 21:58:36,680 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 21:58:36,680 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 21:58:59,087 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 21:58:59,087 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 21:59:05,385 - __main__ - INFO - API批次 [271-300] 完成
2025-12-23 21:59:05,385 - __main__ - INFO - 阶段2完成: 共生成 300 条Chosen结果
2025-12-23 21:59:05,385 - __main__ - INFO - 开始数据质量检查...
2025-12-23 21:59:05,385 - __main__ - INFO - ✅ 数据质量检查通过: 300 条chosen全部非空
2025-12-23 21:59:05,385 - __main__ - INFO - ============================================================
2025-12-23 21:59:05,385 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-23 21:59:05,385 - __main__ - INFO - ============================================================
2025-12-23 21:59:05,385 - __main__ - INFO - 预检查数据完整性...
2025-12-23 21:59:05,386 - __main__ - INFO - Chosen非空率: 300/300 (100.0%)
2025-12-23 21:59:05,386 - __main__ - INFO - Rejected非空率: 300/300 (100.0%)
2025-12-23 21:59:05,386 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-23 21:59:05,395 - __main__ - INFO - 已保存 50/300 条到JSONL
2025-12-23 21:59:05,408 - __main__ - INFO - 已保存 100/300 条到JSONL
2025-12-23 21:59:05,422 - __main__ - INFO - 已保存 150/300 条到JSONL
2025-12-23 21:59:05,433 - __main__ - INFO - 已保存 200/300 条到JSONL
2025-12-23 21:59:05,444 - __main__ - INFO - 已保存 250/300 条到JSONL
2025-12-23 21:59:05,454 - __main__ - INFO - 已保存 300/300 条到JSONL
2025-12-23 21:59:05,466 - __main__ - INFO - DPO数据生成完成: output/dpo_svamp.jsonl
2025-12-23 21:59:05,466 - __main__ - INFO - 共保存 300 条数据到JSONL格式
2025-12-23 21:59:06,344 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 21:59:06,374 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-23 22:01:23,248 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:01:23,248 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:03:06,065 - __main__ - INFO - 批次 [385-512] 本地推理完成
2025-12-23 22:03:06,065 - __main__ - INFO - 处理批次 [513-640/99842]
2025-12-23 22:03:06,066 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:03:06,066 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:03:31,499 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:03:31,499 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:05:55,840 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:05:55,841 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:07:37,633 - __main__ - INFO - 批次 [513-640] 本地推理完成
2025-12-23 22:07:37,633 - __main__ - INFO - 处理批次 [641-768/99842]
2025-12-23 22:07:37,634 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:07:37,634 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:07:59,638 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:07:59,639 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:10:25,101 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:10:25,101 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:12:04,083 - __main__ - INFO - 批次 [641-768] 本地推理完成
2025-12-23 22:12:04,084 - __main__ - INFO - 处理批次 [769-896/99842]
2025-12-23 22:12:04,085 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:12:04,085 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:12:25,756 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:12:25,757 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:14:50,528 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:14:50,528 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:16:31,990 - __main__ - INFO - 批次 [769-896] 本地推理完成
2025-12-23 22:16:31,991 - __main__ - INFO - 处理批次 [897-1024/99842]
2025-12-23 22:16:31,991 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:16:31,991 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:16:54,942 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:16:54,942 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:19:19,847 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:19:19,847 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:20:57,342 - __main__ - INFO - 批次 [897-1024] 本地推理完成
2025-12-23 22:20:57,343 - __main__ - INFO - 处理批次 [1025-1152/99842]
2025-12-23 22:20:57,343 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:20:57,343 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:21:18,254 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:21:18,255 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:23:47,016 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:23:47,016 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:25:25,433 - __main__ - INFO - 批次 [1025-1152] 本地推理完成
2025-12-23 22:25:25,433 - __main__ - INFO - 处理批次 [1153-1280/99842]
2025-12-23 22:25:25,433 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:25:25,433 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:25:40,751 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:25:40,751 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:28:13,186 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:28:13,186 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:29:49,603 - __main__ - INFO - 批次 [1153-1280] 本地推理完成
2025-12-23 22:29:49,603 - __main__ - INFO - 处理批次 [1281-1408/99842]
2025-12-23 22:29:49,603 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:29:49,603 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:30:01,548 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:30:01,548 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:32:34,159 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:32:34,159 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:34:15,100 - __main__ - INFO - 批次 [1281-1408] 本地推理完成
2025-12-23 22:34:15,101 - __main__ - INFO - 处理批次 [1409-1536/99842]
2025-12-23 22:34:15,101 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:34:15,101 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:34:27,799 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:34:27,799 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:37:00,738 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:37:00,738 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:38:36,984 - __main__ - INFO - 批次 [1409-1536] 本地推理完成
2025-12-23 22:38:36,985 - __main__ - INFO - 处理批次 [1537-1664/99842]
2025-12-23 22:38:36,985 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:38:36,986 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:38:49,396 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:38:49,397 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:41:22,991 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-23 22:41:22,992 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-23 22:42:57,153 - __main__ - INFO - 批次 [1537-1664] 本地推理完成
2025-12-23 22:42:57,154 - __main__ - INFO - 处理批次 [1665-1792/99842]
2025-12-23 22:42:57,154 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-23 22:42:57,154 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-23 22:43:57,395 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-23 22:43:57,395 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-23 22:43:57,497 - inference.local_inference - ERROR - 批量推理失败: Prompt length of 4386 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4386 is longer than the maximum model length of 4096.
2025-12-23 22:43:57,499 - __main__ - ERROR - 生成DPO数据时发生错误: Prompt length of 4386 is longer than the maximum model length of 4096.
Traceback (most recent call last):
  File "/home/metanew2/stage_first.py", line 434, in prepare_stage1
    diffs = batch_generate_differences(questions, baseline_answers, labels)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/stage_first.py", line 343, in batch_generate_differences
    return batch_generate_difference_list(questions, preds, labels)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/module/plan_module.py", line 78, in batch_generate_difference_list
    return batch_inference(prompts)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/inference/local_inference.py", line 118, in batch_inference
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/utils.py", line 1072, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 457, in generate
    self._validate_and_add_requests(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1308, in _validate_and_add_requests
    self._add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 1326, in _add_request
    self.llm_engine.add_request(
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py", line 184, in add_request
    request = self.processor.process_inputs(request_id, prompt, params,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 207, in process_inputs
    self._validate_model_inputs(processed_inputs, lora_request)
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/v1/engine/processor.py", line 322, in _validate_model_inputs
    raise ValueError(
ValueError: Prompt length of 4386 is longer than the maximum model length of 4096.
2025-12-23 22:43:58,979 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-23 22:43:58,979 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 00:40:28,658 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,658 - __main__ - INFO - 数据集名称: math
2025-12-24 00:40:28,658 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-24 00:40:28,658 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,658 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-24 00:40:28,658 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,658 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-24 00:40:28,659 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-24 00:40:28,659 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,661 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-24 00:40:28,661 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-24 00:40:28,662 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-24 00:40:28,662 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 00:40:28,662 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,662 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-24 00:40:28,662 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,662 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 00:40:28,662 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,662 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 00:40:28,663 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-24 00:40:28,663 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,663 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 00:40:28,663 - __main__ - INFO - ============================================================
2025-12-24 00:40:28,663 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-24 00:40:28,663 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 00:40:28,663 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 00:40:33,090 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-24 00:40:33,091 - inference.local_inference - INFO - ============================================================
2025-12-24 00:40:33,091 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 00:40:33,091 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 00:40:33,091 - inference.local_inference - INFO - ============================================================
2025-12-24 00:41:27,130 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 00:41:46,106 - __main__ - INFO - ============================================================
2025-12-24 00:41:46,106 - __main__ - INFO - 数据集名称: mmlu
2025-12-24 00:41:46,106 - __main__ - INFO - 数据集路径: dataset/mmlu_json/auxiliary_train.json
2025-12-24 00:41:46,106 - __main__ - INFO - ============================================================
2025-12-24 00:41:46,106 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-24 00:41:46,106 - __main__ - INFO - ============================================================
2025-12-24 00:41:46,106 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-24 00:41:46,106 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu_json/auxiliary_train.json
2025-12-24 00:41:46,107 - __main__ - INFO - ============================================================
2025-12-24 00:41:48,971 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 00:41:48,971 - __main__ - INFO - 预处理 MMLU 数据集: 99842 条
2025-12-24 00:41:49,058 - __main__ - INFO - [数据集适配层] 预处理完成: 99842 条有效数据
2025-12-24 00:41:49,058 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 00:41:49,058 - __main__ - INFO - ============================================================
2025-12-24 00:41:49,084 - __main__ - INFO - 数据集加载成功，共 99842 条数据
2025-12-24 00:41:49,085 - __main__ - INFO - ============================================================
2025-12-24 00:41:49,087 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 00:41:49,088 - __main__ - INFO - ============================================================
2025-12-24 00:41:49,089 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 00:41:49,126 - __main__ - INFO - 共需处理 99842 条数据，批次大小: 64
2025-12-24 00:41:49,127 - __main__ - INFO - ============================================================
2025-12-24 00:41:49,127 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 00:41:49,127 - __main__ - INFO - ============================================================
2025-12-24 00:41:49,127 - __main__ - INFO - 处理批次 [1-128/99842]
2025-12-24 00:41:49,127 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 00:41:49,127 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 00:41:53,788 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-24 00:41:53,788 - inference.local_inference - INFO - ============================================================
2025-12-24 00:41:53,788 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 00:41:53,788 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 00:41:53,788 - inference.local_inference - INFO - ============================================================
2025-12-24 00:42:03,540 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 00:42:03,540 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 00:42:41,317 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,317 - __main__ - INFO - 数据集名称: gsm8k
2025-12-24 00:42:41,317 - __main__ - INFO - 数据集路径: dataset/gsm8k/test.jsonl
2025-12-24 00:42:41,317 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,317 - __main__ - INFO - 使用数据集适配层加载: gsm8k
2025-12-24 00:42:41,317 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,317 - __main__ - INFO - [数据集适配层] 开始加载数据集: gsm8k
2025-12-24 00:42:41,317 - __main__ - INFO - [数据集适配层] 文件路径: dataset/gsm8k/test.jsonl
2025-12-24 00:42:41,317 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,325 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 1319 条
2025-12-24 00:42:41,325 - __main__ - INFO - 预处理 GSM8K 数据集: 1319 条
2025-12-24 00:42:41,325 - __main__ - INFO - [数据集适配层] 预处理完成: 1319 条有效数据
2025-12-24 00:42:41,325 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 00:42:41,325 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,325 - __main__ - INFO - 数据集加载成功，共 1319 条数据
2025-12-24 00:42:41,325 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,325 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 00:42:41,325 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,326 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 00:42:41,326 - __main__ - INFO - 共需处理 1319 条数据，批次大小: 64
2025-12-24 00:42:41,326 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,326 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 00:42:41,326 - __main__ - INFO - ============================================================
2025-12-24 00:42:41,326 - __main__ - INFO - 处理批次 [1-128/1319]
2025-12-24 00:42:41,326 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 00:42:41,326 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 00:42:46,070 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 00:42:46,070 - inference.local_inference - INFO - ============================================================
2025-12-24 00:42:46,071 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 00:42:46,071 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 00:42:46,071 - inference.local_inference - INFO - ============================================================
2025-12-24 00:42:51,303 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 00:43:12,347 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 00:43:12,348 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 00:43:42,340 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 00:43:56,611 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 00:43:56,612 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 00:51:08,521 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 00:51:08,522 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 00:52:45,755 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 00:52:45,755 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 00:53:45,497 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 00:53:45,497 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 00:57:45,634 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 00:57:45,635 - __main__ - INFO - 处理批次 [129-256/500]
2025-12-24 00:57:45,635 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 00:57:45,635 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 00:59:07,501 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 00:59:07,501 - __main__ - INFO - 处理批次 [129-256/1319]
2025-12-24 00:59:07,501 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 00:59:07,501 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 00:59:47,327 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 00:59:47,328 - __main__ - INFO - 处理批次 [129-256/99842]
2025-12-24 00:59:47,328 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 00:59:47,328 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 00:59:51,169 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 00:59:51,170 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 00:59:53,236 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 00:59:53,236 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:00:09,521 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:00:09,522 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:08:30,592 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:08:30,592 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:08:51,459 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:08:51,459 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:10:27,772 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:10:27,772 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:15:09,802 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-24 01:15:09,802 - __main__ - INFO - 处理批次 [257-384/500]
2025-12-24 01:15:09,802 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 01:15:09,802 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 01:15:17,492 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-24 01:15:17,492 - __main__ - INFO - 处理批次 [257-384/1319]
2025-12-24 01:15:17,493 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 01:15:17,493 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 01:15:29,188 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:15:29,188 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:15:49,880 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:15:49,880 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:16:30,517 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-24 01:16:30,517 - __main__ - INFO - 处理批次 [257-384/99842]
2025-12-24 01:16:30,517 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 01:16:30,517 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 01:16:53,145 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:16:53,145 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:24:21,244 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:24:21,244 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:24:36,715 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:24:36,716 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:27:09,714 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:27:09,714 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:30:55,403 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-24 01:30:55,404 - __main__ - INFO - 处理批次 [385-512/1319]
2025-12-24 01:30:55,404 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 01:30:55,404 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 01:31:08,815 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:31:08,816 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:31:19,103 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-24 01:31:19,103 - __main__ - INFO - 处理批次 [385-500/500]
2025-12-24 01:31:19,104 - __main__ - INFO -   → 生成Baseline答案 (116 条)...
2025-12-24 01:31:19,104 - __main__ - INFO - 批量生成Baseline答案: 116 条
2025-12-24 01:31:57,601 - __main__ - INFO -   → 生成差异分析 (116 条)...
2025-12-24 01:31:57,602 - __main__ - INFO - 批量生成差异分析: 116 条
2025-12-24 01:33:16,861 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-24 01:33:16,861 - __main__ - INFO - 处理批次 [385-512/99842]
2025-12-24 01:33:16,861 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 01:33:16,861 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 01:33:39,891 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:33:39,891 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:39:32,460 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:39:32,460 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:39:58,642 - __main__ - INFO -   → 生成Rejected原则 (116 条)...
2025-12-24 01:39:58,642 - __main__ - INFO - 批量生成原则（弱模型）: 116 条
2025-12-24 01:44:08,441 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:44:08,441 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:46:12,918 - __main__ - INFO - 批次 [385-500] 本地推理完成
2025-12-24 01:46:12,918 - __main__ - INFO - 阶段1完成: 共生成 500 条本地推理结果
2025-12-24 01:46:12,918 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 01:46:13,065 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 01:46:13,065 - __main__ - INFO - ============================================================
2025-12-24 01:46:13,065 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 01:46:13,065 - __main__ - INFO - ============================================================
2025-12-24 01:46:13,065 - __main__ - INFO - API分批处理: 每批 30 条，共 17 批
2025-12-24 01:46:13,065 - __main__ - INFO - API批次 [1-30/500] 开始处理...
2025-12-24 01:46:13,065 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:46:28,295 - __main__ - INFO - 批次 [385-512] 本地推理完成
2025-12-24 01:46:28,296 - __main__ - INFO - 处理批次 [513-640/1319]
2025-12-24 01:46:28,296 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 01:46:28,296 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 01:46:40,655 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:46:40,655 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:46:49,846 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 01:46:49,847 - __main__ - INFO - API批次 [31-60/500] 开始处理...
2025-12-24 01:46:49,847 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:47:47,314 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 01:47:47,315 - __main__ - INFO - API批次 [61-90/500] 开始处理...
2025-12-24 01:47:47,315 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:49:08,333 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 01:49:08,334 - __main__ - INFO - API批次 [91-120/500] 开始处理...
2025-12-24 01:49:08,334 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:50:11,130 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 01:50:11,131 - __main__ - INFO - API批次 [121-150/500] 开始处理...
2025-12-24 01:50:11,131 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:50:22,045 - __main__ - INFO - 批次 [385-512] 本地推理完成
2025-12-24 01:50:22,046 - __main__ - INFO - 处理批次 [513-640/99842]
2025-12-24 01:50:22,046 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 01:50:22,046 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 01:50:44,178 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 01:50:44,178 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 01:51:02,587 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 01:51:02,588 - __main__ - INFO - API批次 [151-180/500] 开始处理...
2025-12-24 01:51:02,588 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:52:13,800 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 01:52:13,801 - __main__ - INFO - API批次 [181-210/500] 开始处理...
2025-12-24 01:52:13,801 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:52:43,049 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 01:52:43,049 - __main__ - INFO - API批次 [211-240/500] 开始处理...
2025-12-24 01:52:43,050 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:53:13,076 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 01:53:13,076 - __main__ - INFO - API批次 [241-270/500] 开始处理...
2025-12-24 01:53:13,077 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:54:41,600 - __main__ - INFO - API批次 [241-270] 完成
2025-12-24 01:54:41,601 - __main__ - INFO - API批次 [271-300/500] 开始处理...
2025-12-24 01:54:41,601 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:55:09,980 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 01:55:09,980 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 01:55:15,783 - __main__ - INFO - API批次 [271-300] 完成
2025-12-24 01:55:15,784 - __main__ - INFO - API批次 [301-330/500] 开始处理...
2025-12-24 01:55:15,784 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:58:51,350 - __main__ - INFO - API批次 [301-330] 完成
2025-12-24 01:58:51,351 - __main__ - INFO - API批次 [331-360/500] 开始处理...
2025-12-24 01:58:51,351 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 01:59:25,572 - __main__ - INFO - API批次 [331-360] 完成
2025-12-24 01:59:25,573 - __main__ - INFO - API批次 [361-390/500] 开始处理...
2025-12-24 01:59:25,573 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 02:01:00,619 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:01:00,620 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:01:43,622 - __main__ - INFO - 批次 [513-640] 本地推理完成
2025-12-24 02:01:43,623 - __main__ - INFO - 处理批次 [641-768/1319]
2025-12-24 02:01:43,623 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:01:43,623 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:01:57,467 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:01:57,468 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 02:03:10,046 - __main__ - WARNING - ⚠️  批次中有 1/30 个空响应
2025-12-24 02:03:10,047 - __main__ - INFO - API批次 [361-390] 完成
2025-12-24 02:03:10,047 - __main__ - INFO - API批次 [391-420/500] 开始处理...
2025-12-24 02:03:10,047 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 02:04:21,971 - __main__ - INFO - API批次 [391-420] 完成
2025-12-24 02:04:21,972 - __main__ - INFO - API批次 [421-450/500] 开始处理...
2025-12-24 02:04:21,972 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 02:04:53,965 - __main__ - INFO - API批次 [421-450] 完成
2025-12-24 02:04:53,965 - __main__ - INFO - API批次 [451-480/500] 开始处理...
2025-12-24 02:04:53,965 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 02:05:29,952 - __main__ - INFO - API批次 [451-480] 完成
2025-12-24 02:05:29,952 - __main__ - INFO - API批次 [481-500/500] 开始处理...
2025-12-24 02:05:29,952 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 02:07:02,298 - __main__ - INFO - API批次 [481-500] 完成
2025-12-24 02:07:02,298 - __main__ - INFO - 阶段2完成: 共生成 500 条Chosen结果
2025-12-24 02:07:02,298 - __main__ - INFO - 开始数据质量检查...
2025-12-24 02:07:02,299 - __main__ - ERROR - ❌ 发现 1 个空chosen值
2025-12-24 02:07:02,299 - __main__ - ERROR -    空值索引（前10个）: [372]
2025-12-24 02:07:03,367 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 02:07:03,397 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 02:07:06,046 - __main__ - INFO - 批次 [513-640] 本地推理完成
2025-12-24 02:07:06,046 - __main__ - INFO - 处理批次 [641-768/99842]
2025-12-24 02:07:06,046 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:07:06,046 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:07:28,995 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:07:28,995 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 02:10:15,396 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:10:15,396 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:16:54,188 - __main__ - INFO - 批次 [641-768] 本地推理完成
2025-12-24 02:16:54,189 - __main__ - INFO - 处理批次 [769-896/1319]
2025-12-24 02:16:54,189 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:16:54,189 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:17:08,682 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:17:08,682 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 02:17:28,440 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:17:28,440 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:23:53,212 - __main__ - INFO - 批次 [641-768] 本地推理完成
2025-12-24 02:23:53,213 - __main__ - INFO - 处理批次 [769-896/99842]
2025-12-24 02:23:53,213 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:23:53,213 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:24:14,409 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:24:14,410 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 02:25:23,639 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:25:23,639 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:31:59,401 - __main__ - INFO - 批次 [769-896] 本地推理完成
2025-12-24 02:31:59,401 - __main__ - INFO - 处理批次 [897-1024/1319]
2025-12-24 02:31:59,401 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:31:59,401 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:32:13,176 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:32:13,176 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 02:34:36,977 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:34:36,977 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:40:21,616 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:40:21,616 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:40:59,982 - __main__ - INFO - 批次 [769-896] 本地推理完成
2025-12-24 02:40:59,982 - __main__ - INFO - 处理批次 [897-1024/99842]
2025-12-24 02:40:59,982 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:40:59,982 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:41:22,723 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:41:22,724 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 02:46:50,521 - __main__ - INFO - 批次 [897-1024] 本地推理完成
2025-12-24 02:46:50,522 - __main__ - INFO - 处理批次 [1025-1152/1319]
2025-12-24 02:46:50,522 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:46:50,522 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:47:04,104 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:47:04,105 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 02:51:49,360 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:51:49,360 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:55:28,868 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 02:55:28,868 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 02:57:47,061 - __main__ - INFO - 批次 [897-1024] 本地推理完成
2025-12-24 02:57:47,062 - __main__ - INFO - 处理批次 [1025-1152/99842]
2025-12-24 02:57:47,062 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 02:57:47,062 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 02:58:07,707 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 02:58:07,707 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 03:01:56,360 - __main__ - INFO - 批次 [1025-1152] 本地推理完成
2025-12-24 03:01:56,361 - __main__ - INFO - 处理批次 [1153-1280/1319]
2025-12-24 03:01:56,361 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 03:01:56,361 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 03:03:55,872 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 03:03:55,873 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 03:08:04,518 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 03:08:04,519 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 03:12:01,632 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 03:12:01,633 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 03:14:29,811 - __main__ - INFO - 批次 [1025-1152] 本地推理完成
2025-12-24 03:14:29,811 - __main__ - INFO - 处理批次 [1153-1280/99842]
2025-12-24 03:14:29,811 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 03:14:29,811 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 03:16:29,053 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 03:16:29,053 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 03:18:46,609 - __main__ - INFO - 批次 [1153-1280] 本地推理完成
2025-12-24 03:18:46,609 - __main__ - INFO - 处理批次 [1281-1319/1319]
2025-12-24 03:18:46,609 - __main__ - INFO -   → 生成Baseline答案 (39 条)...
2025-12-24 03:18:46,609 - __main__ - INFO - 批量生成Baseline答案: 39 条
2025-12-24 03:18:54,224 - __main__ - INFO -   → 生成差异分析 (39 条)...
2025-12-24 03:18:54,225 - __main__ - INFO - 批量生成差异分析: 39 条
2025-12-24 03:22:26,200 - __main__ - INFO -   → 生成Rejected原则 (39 条)...
2025-12-24 03:22:26,201 - __main__ - INFO - 批量生成原则（弱模型）: 39 条
2025-12-24 03:25:43,142 - __main__ - INFO - 批次 [1281-1319] 本地推理完成
2025-12-24 03:25:43,142 - __main__ - INFO - 阶段1完成: 共生成 1319 条本地推理结果
2025-12-24 03:25:43,142 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 03:25:43,504 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 03:25:43,505 - __main__ - INFO - ============================================================
2025-12-24 03:25:43,505 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 03:25:43,505 - __main__ - INFO - ============================================================
2025-12-24 03:25:43,505 - __main__ - INFO - API分批处理: 每批 30 条，共 44 批
2025-12-24 03:25:43,505 - __main__ - INFO - API批次 [1-30/1319] 开始处理...
2025-12-24 03:25:43,505 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:26:00,537 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 03:26:00,537 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 03:26:06,157 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 03:26:06,158 - __main__ - INFO - API批次 [31-60/1319] 开始处理...
2025-12-24 03:26:06,158 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:26:36,349 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 03:26:36,350 - __main__ - INFO - API批次 [61-90/1319] 开始处理...
2025-12-24 03:26:36,350 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:28:03,386 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 03:28:03,387 - __main__ - INFO - API批次 [91-120/1319] 开始处理...
2025-12-24 03:28:03,388 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:28:29,645 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 03:28:29,646 - __main__ - INFO - API批次 [121-150/1319] 开始处理...
2025-12-24 03:28:29,646 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:28:51,058 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 03:28:51,058 - __main__ - INFO - API批次 [151-180/1319] 开始处理...
2025-12-24 03:28:51,058 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:29:20,218 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 03:29:20,219 - __main__ - INFO - API批次 [181-210/1319] 开始处理...
2025-12-24 03:29:20,219 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:29:48,231 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 03:29:48,231 - __main__ - INFO - API批次 [211-240/1319] 开始处理...
2025-12-24 03:29:48,231 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:30:44,417 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 03:30:44,417 - __main__ - INFO - API批次 [241-270/1319] 开始处理...
2025-12-24 03:30:44,418 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:31:26,438 - __main__ - INFO - API批次 [241-270] 完成
2025-12-24 03:31:26,438 - __main__ - INFO - API批次 [271-300/1319] 开始处理...
2025-12-24 03:31:26,438 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:32:02,958 - __main__ - INFO - API批次 [271-300] 完成
2025-12-24 03:32:02,959 - __main__ - INFO - API批次 [301-330/1319] 开始处理...
2025-12-24 03:32:02,959 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:32:21,661 - __main__ - INFO - 批次 [1153-1280] 本地推理完成
2025-12-24 03:32:21,661 - __main__ - INFO - 处理批次 [1281-1408/99842]
2025-12-24 03:32:21,662 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 03:32:21,662 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 03:32:33,445 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 03:32:33,445 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 03:32:40,762 - __main__ - INFO - API批次 [301-330] 完成
2025-12-24 03:32:40,762 - __main__ - INFO - API批次 [331-360/1319] 开始处理...
2025-12-24 03:32:40,762 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:33:16,466 - __main__ - INFO - API批次 [331-360] 完成
2025-12-24 03:33:16,467 - __main__ - INFO - API批次 [361-390/1319] 开始处理...
2025-12-24 03:33:16,467 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:33:40,033 - __main__ - INFO - API批次 [361-390] 完成
2025-12-24 03:33:40,033 - __main__ - INFO - API批次 [391-420/1319] 开始处理...
2025-12-24 03:33:40,033 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:34:16,627 - __main__ - INFO - API批次 [391-420] 完成
2025-12-24 03:34:16,628 - __main__ - INFO - API批次 [421-450/1319] 开始处理...
2025-12-24 03:34:16,628 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:34:57,336 - __main__ - INFO - API批次 [421-450] 完成
2025-12-24 03:34:57,337 - __main__ - INFO - API批次 [451-480/1319] 开始处理...
2025-12-24 03:34:57,337 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:35:23,009 - __main__ - INFO - API批次 [451-480] 完成
2025-12-24 03:35:23,010 - __main__ - INFO - API批次 [481-510/1319] 开始处理...
2025-12-24 03:35:23,010 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:35:52,791 - __main__ - INFO - API批次 [481-510] 完成
2025-12-24 03:35:52,792 - __main__ - INFO - API批次 [511-540/1319] 开始处理...
2025-12-24 03:35:52,792 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:36:17,098 - __main__ - INFO - API批次 [511-540] 完成
2025-12-24 03:36:17,098 - __main__ - INFO - API批次 [541-570/1319] 开始处理...
2025-12-24 03:36:17,098 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:36:39,395 - __main__ - INFO - API批次 [541-570] 完成
2025-12-24 03:36:39,396 - __main__ - INFO - API批次 [571-600/1319] 开始处理...
2025-12-24 03:36:39,396 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:37:18,763 - __main__ - INFO - API批次 [571-600] 完成
2025-12-24 03:37:18,764 - __main__ - INFO - API批次 [601-630/1319] 开始处理...
2025-12-24 03:37:18,764 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:37:43,164 - __main__ - INFO - API批次 [601-630] 完成
2025-12-24 03:37:43,164 - __main__ - INFO - API批次 [631-660/1319] 开始处理...
2025-12-24 03:37:43,164 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:38:39,425 - __main__ - INFO - API批次 [631-660] 完成
2025-12-24 03:38:39,426 - __main__ - INFO - API批次 [661-690/1319] 开始处理...
2025-12-24 03:38:39,426 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:39:02,930 - __main__ - INFO - API批次 [661-690] 完成
2025-12-24 03:39:02,931 - __main__ - INFO - API批次 [691-720/1319] 开始处理...
2025-12-24 03:39:02,931 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:39:44,731 - __main__ - INFO - API批次 [691-720] 完成
2025-12-24 03:39:44,732 - __main__ - INFO - API批次 [721-750/1319] 开始处理...
2025-12-24 03:39:44,732 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:40:29,387 - __main__ - INFO - API批次 [721-750] 完成
2025-12-24 03:40:29,388 - __main__ - INFO - API批次 [751-780/1319] 开始处理...
2025-12-24 03:40:29,388 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:41:04,402 - __main__ - INFO - API批次 [751-780] 完成
2025-12-24 03:41:04,403 - __main__ - INFO - API批次 [781-810/1319] 开始处理...
2025-12-24 03:41:04,403 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:41:31,963 - __main__ - INFO - API批次 [781-810] 完成
2025-12-24 03:41:31,963 - __main__ - INFO - API批次 [811-840/1319] 开始处理...
2025-12-24 03:41:31,963 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:42:19,751 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 03:42:19,752 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 03:42:33,426 - __main__ - INFO - API批次 [811-840] 完成
2025-12-24 03:42:33,427 - __main__ - INFO - API批次 [841-870/1319] 开始处理...
2025-12-24 03:42:33,427 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:43:08,811 - __main__ - INFO - API批次 [841-870] 完成
2025-12-24 03:43:08,812 - __main__ - INFO - API批次 [871-900/1319] 开始处理...
2025-12-24 03:43:08,812 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:43:53,430 - __main__ - INFO - API批次 [871-900] 完成
2025-12-24 03:43:53,430 - __main__ - INFO - API批次 [901-930/1319] 开始处理...
2025-12-24 03:43:53,430 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:44:16,634 - __main__ - INFO - API批次 [901-930] 完成
2025-12-24 03:44:16,635 - __main__ - INFO - API批次 [931-960/1319] 开始处理...
2025-12-24 03:44:16,635 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:45:16,863 - __main__ - INFO - API批次 [931-960] 完成
2025-12-24 03:45:16,864 - __main__ - INFO - API批次 [961-990/1319] 开始处理...
2025-12-24 03:45:16,864 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:45:52,939 - __main__ - INFO - API批次 [961-990] 完成
2025-12-24 03:45:52,940 - __main__ - INFO - API批次 [991-1020/1319] 开始处理...
2025-12-24 03:45:52,940 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:46:34,536 - __main__ - INFO - API批次 [991-1020] 完成
2025-12-24 03:46:34,537 - __main__ - INFO - API批次 [1021-1050/1319] 开始处理...
2025-12-24 03:46:34,537 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:47:24,223 - __main__ - INFO - API批次 [1021-1050] 完成
2025-12-24 03:47:24,224 - __main__ - INFO - API批次 [1051-1080/1319] 开始处理...
2025-12-24 03:47:24,224 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:48:34,669 - __main__ - INFO - API批次 [1051-1080] 完成
2025-12-24 03:48:34,670 - __main__ - INFO - API批次 [1081-1110/1319] 开始处理...
2025-12-24 03:48:34,670 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:48:48,202 - __main__ - INFO - 批次 [1281-1408] 本地推理完成
2025-12-24 03:48:48,202 - __main__ - INFO - 处理批次 [1409-1536/99842]
2025-12-24 03:48:48,202 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 03:48:48,202 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 03:49:02,933 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 03:49:02,933 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 03:49:11,789 - __main__ - INFO - API批次 [1081-1110] 完成
2025-12-24 03:49:11,790 - __main__ - INFO - API批次 [1111-1140/1319] 开始处理...
2025-12-24 03:49:11,790 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:49:49,421 - __main__ - INFO - API批次 [1111-1140] 完成
2025-12-24 03:49:49,422 - __main__ - INFO - API批次 [1141-1170/1319] 开始处理...
2025-12-24 03:49:49,422 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:50:27,412 - __main__ - INFO - API批次 [1141-1170] 完成
2025-12-24 03:50:27,413 - __main__ - INFO - API批次 [1171-1200/1319] 开始处理...
2025-12-24 03:50:27,413 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:51:02,362 - __main__ - INFO - API批次 [1171-1200] 完成
2025-12-24 03:51:02,362 - __main__ - INFO - API批次 [1201-1230/1319] 开始处理...
2025-12-24 03:51:02,362 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:51:42,279 - __main__ - INFO - API批次 [1201-1230] 完成
2025-12-24 03:51:42,280 - __main__ - INFO - API批次 [1231-1260/1319] 开始处理...
2025-12-24 03:51:42,280 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:52:23,126 - __main__ - INFO - API批次 [1231-1260] 完成
2025-12-24 03:52:23,127 - __main__ - INFO - API批次 [1261-1290/1319] 开始处理...
2025-12-24 03:52:23,127 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:52:55,533 - __main__ - INFO - API批次 [1261-1290] 完成
2025-12-24 03:52:55,533 - __main__ - INFO - API批次 [1291-1319/1319] 开始处理...
2025-12-24 03:52:55,534 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 03:53:30,120 - __main__ - INFO - API批次 [1291-1319] 完成
2025-12-24 03:53:30,121 - __main__ - INFO - 阶段2完成: 共生成 1319 条Chosen结果
2025-12-24 03:53:30,121 - __main__ - INFO - 开始数据质量检查...
2025-12-24 03:53:30,122 - __main__ - INFO - ✅ 数据质量检查通过: 1319 条chosen全部非空
2025-12-24 03:53:30,122 - __main__ - INFO - ============================================================
2025-12-24 03:53:30,122 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 03:53:30,122 - __main__ - INFO - ============================================================
2025-12-24 03:53:30,122 - __main__ - INFO - 预检查数据完整性...
2025-12-24 03:53:30,126 - __main__ - INFO - Chosen非空率: 1319/1319 (100.0%)
2025-12-24 03:53:30,126 - __main__ - INFO - Rejected非空率: 1319/1319 (100.0%)
2025-12-24 03:53:30,126 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 03:53:30,146 - __main__ - INFO - 已保存 50/1319 条到JSONL
2025-12-24 03:53:30,165 - __main__ - INFO - 已保存 100/1319 条到JSONL
2025-12-24 03:53:30,195 - __main__ - INFO - 已保存 150/1319 条到JSONL
2025-12-24 03:53:30,213 - __main__ - INFO - 已保存 200/1319 条到JSONL
2025-12-24 03:53:30,231 - __main__ - INFO - 已保存 250/1319 条到JSONL
2025-12-24 03:53:30,251 - __main__ - INFO - 已保存 300/1319 条到JSONL
2025-12-24 03:53:30,277 - __main__ - INFO - 已保存 350/1319 条到JSONL
2025-12-24 03:53:30,294 - __main__ - INFO - 已保存 400/1319 条到JSONL
2025-12-24 03:53:30,311 - __main__ - INFO - 已保存 450/1319 条到JSONL
2025-12-24 03:53:30,329 - __main__ - INFO - 已保存 500/1319 条到JSONL
2025-12-24 03:53:30,347 - __main__ - INFO - 已保存 550/1319 条到JSONL
2025-12-24 03:53:30,363 - __main__ - INFO - 已保存 600/1319 条到JSONL
2025-12-24 03:53:30,381 - __main__ - INFO - 已保存 650/1319 条到JSONL
2025-12-24 03:53:30,398 - __main__ - INFO - 已保存 700/1319 条到JSONL
2025-12-24 03:53:30,416 - __main__ - INFO - 已保存 750/1319 条到JSONL
2025-12-24 03:53:30,432 - __main__ - INFO - 已保存 800/1319 条到JSONL
2025-12-24 03:53:30,448 - __main__ - INFO - 已保存 850/1319 条到JSONL
2025-12-24 03:53:30,467 - __main__ - INFO - 已保存 900/1319 条到JSONL
2025-12-24 03:53:30,482 - __main__ - INFO - 已保存 950/1319 条到JSONL
2025-12-24 03:53:30,501 - __main__ - INFO - 已保存 1000/1319 条到JSONL
2025-12-24 03:53:30,518 - __main__ - INFO - 已保存 1050/1319 条到JSONL
2025-12-24 03:53:30,536 - __main__ - INFO - 已保存 1100/1319 条到JSONL
2025-12-24 03:53:30,552 - __main__ - INFO - 已保存 1150/1319 条到JSONL
2025-12-24 03:53:30,571 - __main__ - INFO - 已保存 1200/1319 条到JSONL
2025-12-24 03:53:30,589 - __main__ - INFO - 已保存 1250/1319 条到JSONL
2025-12-24 03:53:30,606 - __main__ - INFO - 已保存 1300/1319 条到JSONL
2025-12-24 03:53:30,658 - __main__ - INFO - DPO数据生成完成: output/dpo_gsm8k.jsonl
2025-12-24 03:53:30,658 - __main__ - INFO - 共保存 1319 条数据到JSONL格式
2025-12-24 03:53:31,752 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 03:53:31,782 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 03:58:50,403 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 03:58:50,404 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 04:05:14,928 - __main__ - INFO - 批次 [1409-1536] 本地推理完成
2025-12-24 04:05:14,929 - __main__ - INFO - 处理批次 [1537-1664/99842]
2025-12-24 04:05:14,929 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 04:05:14,929 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 04:05:28,085 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 04:05:28,085 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 04:15:08,039 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 04:15:08,039 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 04:21:25,199 - __main__ - INFO - 批次 [1537-1664] 本地推理完成
2025-12-24 04:21:25,199 - __main__ - INFO - 处理批次 [1665-1792/99842]
2025-12-24 04:21:25,200 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 04:21:25,200 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 04:21:38,095 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 04:21:38,095 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 04:31:26,092 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 04:31:26,093 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 04:37:59,332 - __main__ - INFO - 批次 [1665-1792] 本地推理完成
2025-12-24 04:37:59,333 - __main__ - INFO - 处理批次 [1793-1920/99842]
2025-12-24 04:37:59,333 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 04:37:59,333 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 04:38:15,375 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 04:38:15,375 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 04:48:06,973 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 04:48:06,973 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 04:54:29,666 - __main__ - INFO - 批次 [1793-1920] 本地推理完成
2025-12-24 04:54:29,666 - __main__ - INFO - 处理批次 [1921-2048/99842]
2025-12-24 04:54:29,666 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 04:54:29,667 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 04:54:44,083 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 04:54:44,083 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 05:04:18,511 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 05:04:18,511 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 05:10:42,503 - __main__ - INFO - 批次 [1921-2048] 本地推理完成
2025-12-24 05:10:42,504 - __main__ - INFO - 处理批次 [2049-2176/99842]
2025-12-24 05:10:42,504 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 05:10:42,504 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 05:10:54,441 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 05:10:54,441 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 05:20:35,339 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 05:20:35,339 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 05:26:52,643 - __main__ - INFO - 批次 [2049-2176] 本地推理完成
2025-12-24 05:26:52,643 - __main__ - INFO - 处理批次 [2177-2304/99842]
2025-12-24 05:26:52,643 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 05:26:52,643 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 05:27:11,009 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 05:27:11,010 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 05:36:36,187 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 05:36:36,188 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 05:43:16,052 - __main__ - INFO - 批次 [2177-2304] 本地推理完成
2025-12-24 05:43:16,053 - __main__ - INFO - 处理批次 [2305-2432/99842]
2025-12-24 05:43:16,053 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 05:43:16,053 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 05:43:28,444 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 05:43:28,444 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 05:53:03,032 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 05:53:03,032 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 05:59:35,615 - __main__ - INFO - 批次 [2305-2432] 本地推理完成
2025-12-24 05:59:35,615 - __main__ - INFO - 处理批次 [2433-2560/99842]
2025-12-24 05:59:35,615 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 05:59:35,616 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 05:59:50,395 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 05:59:50,395 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 06:09:32,917 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 06:09:32,918 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 06:15:57,384 - __main__ - INFO - 批次 [2433-2560] 本地推理完成
2025-12-24 06:15:57,385 - __main__ - INFO - 处理批次 [2561-2688/99842]
2025-12-24 06:15:57,385 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 06:15:57,385 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 06:16:13,120 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 06:16:13,121 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 06:25:48,978 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 06:25:48,978 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 06:32:22,101 - __main__ - INFO - 批次 [2561-2688] 本地推理完成
2025-12-24 06:32:22,102 - __main__ - INFO - 处理批次 [2689-2816/99842]
2025-12-24 06:32:22,102 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 06:32:22,102 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 06:32:34,243 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 06:32:34,244 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 06:42:17,138 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 06:42:17,138 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 06:48:45,277 - __main__ - INFO - 批次 [2689-2816] 本地推理完成
2025-12-24 06:48:45,277 - __main__ - INFO - 处理批次 [2817-2944/99842]
2025-12-24 06:48:45,278 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 06:48:45,278 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 06:48:55,771 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 06:48:55,771 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 06:58:56,675 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 06:58:56,676 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 07:04:23,211 - __main__ - INFO - 批次 [2817-2944] 本地推理完成
2025-12-24 07:04:23,212 - __main__ - INFO - 处理批次 [2945-3072/99842]
2025-12-24 07:04:23,212 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 07:04:23,213 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 07:04:32,052 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 07:04:32,052 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 07:14:28,054 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 07:14:28,055 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 07:20:09,804 - __main__ - INFO - 批次 [2945-3072] 本地推理完成
2025-12-24 07:20:09,804 - __main__ - INFO - 处理批次 [3073-3200/99842]
2025-12-24 07:20:09,805 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 07:20:09,805 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 07:20:19,505 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 07:20:19,505 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 07:30:05,987 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 07:30:05,988 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 07:35:49,138 - __main__ - INFO - 批次 [3073-3200] 本地推理完成
2025-12-24 07:35:49,138 - __main__ - INFO - 处理批次 [3201-3328/99842]
2025-12-24 07:35:49,139 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 07:35:49,139 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 07:35:59,250 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 07:35:59,251 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 07:45:53,653 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 07:45:53,653 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 07:51:46,885 - __main__ - INFO - 批次 [3201-3328] 本地推理完成
2025-12-24 07:51:46,885 - __main__ - INFO - 处理批次 [3329-3456/99842]
2025-12-24 07:51:46,886 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 07:51:46,886 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 07:51:57,159 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 07:51:57,160 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 08:02:00,470 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 08:02:00,471 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 08:07:48,563 - __main__ - INFO - 批次 [3329-3456] 本地推理完成
2025-12-24 08:07:48,564 - __main__ - INFO - 处理批次 [3457-3584/99842]
2025-12-24 08:07:48,564 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 08:07:48,564 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 08:07:59,042 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 08:07:59,043 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 08:17:38,697 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 08:17:38,697 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 08:23:21,277 - __main__ - INFO - 批次 [3457-3584] 本地推理完成
2025-12-24 08:23:21,278 - __main__ - INFO - 处理批次 [3585-3712/99842]
2025-12-24 08:23:21,278 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 08:23:21,278 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 08:23:30,414 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 08:23:30,415 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 08:33:26,996 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 08:33:26,996 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 08:39:29,360 - __main__ - INFO - 批次 [3585-3712] 本地推理完成
2025-12-24 08:39:29,360 - __main__ - INFO - 处理批次 [3713-3840/99842]
2025-12-24 08:39:29,361 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 08:39:29,361 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 08:39:39,963 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 08:39:39,963 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 08:49:33,502 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 08:49:33,503 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 08:55:17,671 - __main__ - INFO - 批次 [3713-3840] 本地推理完成
2025-12-24 08:55:17,671 - __main__ - INFO - 处理批次 [3841-3968/99842]
2025-12-24 08:55:17,672 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 08:55:17,672 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 08:55:26,373 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 08:55:26,373 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 09:05:16,146 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 09:05:16,147 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 09:11:05,527 - __main__ - INFO - 批次 [3841-3968] 本地推理完成
2025-12-24 09:11:05,527 - __main__ - INFO - 处理批次 [3969-4096/99842]
2025-12-24 09:11:05,528 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 09:11:05,528 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 09:11:14,772 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 09:11:14,773 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 09:21:08,545 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 09:21:08,546 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 09:27:08,669 - __main__ - INFO - 批次 [3969-4096] 本地推理完成
2025-12-24 09:27:08,670 - __main__ - INFO - 处理批次 [4097-4224/99842]
2025-12-24 09:27:08,670 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 09:27:08,670 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 09:27:18,880 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 09:27:18,881 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 09:37:10,273 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 09:37:10,274 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 09:43:04,452 - __main__ - INFO - 批次 [4097-4224] 本地推理完成
2025-12-24 09:43:04,453 - __main__ - INFO - 处理批次 [4225-4352/99842]
2025-12-24 09:43:04,453 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 09:43:04,453 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 09:43:15,383 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 09:43:15,384 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 09:53:02,547 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 09:53:02,547 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 09:58:58,127 - __main__ - INFO - 批次 [4225-4352] 本地推理完成
2025-12-24 09:58:58,128 - __main__ - INFO - 处理批次 [4353-4480/99842]
2025-12-24 09:58:58,128 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 09:58:58,128 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 09:59:09,514 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 09:59:09,515 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 10:08:55,115 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 10:08:55,116 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 10:15:13,451 - __main__ - INFO - 批次 [4353-4480] 本地推理完成
2025-12-24 10:15:13,452 - __main__ - INFO - 处理批次 [4481-4608/99842]
2025-12-24 10:15:13,452 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 10:15:13,452 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 10:15:23,841 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 10:15:23,842 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 10:25:17,150 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 10:25:17,151 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 10:31:36,138 - __main__ - INFO - 批次 [4481-4608] 本地推理完成
2025-12-24 10:31:36,138 - __main__ - INFO - 处理批次 [4609-4736/99842]
2025-12-24 10:31:36,138 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 10:31:36,139 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 10:31:45,392 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 10:31:45,392 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 10:41:20,210 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 10:41:20,211 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 10:47:49,904 - __main__ - INFO - 批次 [4609-4736] 本地推理完成
2025-12-24 10:47:49,905 - __main__ - INFO - 处理批次 [4737-4864/99842]
2025-12-24 10:47:49,905 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 10:47:49,905 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 10:48:02,001 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 10:48:02,001 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 10:57:43,309 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 10:57:43,310 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 11:04:18,182 - __main__ - INFO - 批次 [4737-4864] 本地推理完成
2025-12-24 11:04:18,182 - __main__ - INFO - 处理批次 [4865-4992/99842]
2025-12-24 11:04:18,182 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 11:04:18,182 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 11:04:32,661 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 11:04:32,661 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 11:14:28,169 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 11:14:28,170 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 11:20:37,238 - __main__ - INFO - 批次 [4865-4992] 本地推理完成
2025-12-24 11:20:37,238 - __main__ - INFO - 处理批次 [4993-5120/99842]
2025-12-24 11:20:37,239 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 11:20:37,239 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 11:22:38,860 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 11:22:38,861 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 11:33:02,882 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 11:33:02,883 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 11:38:48,987 - __main__ - INFO - 批次 [4993-5120] 本地推理完成
2025-12-24 11:38:48,988 - __main__ - INFO - 处理批次 [5121-5248/99842]
2025-12-24 11:38:48,989 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 11:38:48,989 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 11:39:03,292 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 11:39:03,293 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 18:24:21,540 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,540 - __main__ - INFO - 数据集名称: bbh
2025-12-24 18:24:21,540 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-24 18:24:21,540 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,540 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 18:24:21,540 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,540 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 18:24:21,540 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-24 18:24:21,540 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,541 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 18:24:21,541 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 18:24:21,541 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 18:24:21,541 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 18:24:21,541 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,541 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 18:24:21,541 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,541 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 18:24:21,541 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,542 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 18:24:21,544 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 18:24:21,544 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,544 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 18:24:21,544 - __main__ - INFO - ============================================================
2025-12-24 18:24:21,544 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 18:24:21,544 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 18:24:21,544 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 18:24:25,934 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 18:24:25,935 - inference.local_inference - INFO - ============================================================
2025-12-24 18:24:25,935 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 18:24:25,935 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 18:24:25,935 - inference.local_inference - INFO - ============================================================
2025-12-24 18:24:39,187 - __main__ - INFO - ============================================================
2025-12-24 18:24:39,188 - __main__ - INFO - 数据集名称: mmlu
2025-12-24 18:24:39,188 - __main__ - INFO - 数据集路径: dataset/mmlu/auxiliary_train.json
2025-12-24 18:24:39,188 - __main__ - INFO - ============================================================
2025-12-24 18:24:39,188 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-24 18:24:39,188 - __main__ - INFO - ============================================================
2025-12-24 18:24:39,188 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-24 18:24:39,188 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/auxiliary_train.json
2025-12-24 18:24:39,188 - __main__ - INFO - ============================================================
2025-12-24 18:24:42,011 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 18:24:42,012 - __main__ - INFO - 预处理 MMLU 数据集: 99842 条
2025-12-24 18:24:42,097 - __main__ - INFO - [数据集适配层] 预处理完成: 99842 条有效数据
2025-12-24 18:24:42,097 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 18:24:42,097 - __main__ - INFO - ============================================================
2025-12-24 18:24:42,122 - __main__ - INFO - 数据集加载成功，共 99842 条数据
2025-12-24 18:24:42,124 - __main__ - INFO - ============================================================
2025-12-24 18:24:42,125 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 18:24:42,126 - __main__ - INFO - ============================================================
2025-12-24 18:24:42,127 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 18:24:42,165 - __main__ - INFO - 共需处理 99842 条数据，批次大小: 64
2025-12-24 18:24:42,165 - __main__ - INFO - ============================================================
2025-12-24 18:24:42,165 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 18:24:42,165 - __main__ - INFO - ============================================================
2025-12-24 18:24:42,165 - __main__ - INFO - 处理批次 [1-128/99842]
2025-12-24 18:24:42,165 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 18:24:42,165 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 18:24:47,116 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-24 18:24:47,116 - inference.local_inference - INFO - ============================================================
2025-12-24 18:24:47,117 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 18:24:47,117 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 18:24:47,117 - inference.local_inference - INFO - ============================================================
2025-12-24 18:25:24,008 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 18:25:32,284 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 18:25:32,284 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 18:26:02,252 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 18:26:23,065 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 18:26:23,066 - __main__ - INFO - 批量生成差异分析: 128 条
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              2025-12-24 18:31:16,457 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,457 - __main__ - INFO - 数据集名称: math
2025-12-24 18:31:16,458 - __main__ - INFO - 数据集路径: dataset/math/test.jsonl
2025-12-24 18:31:16,458 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,458 - __main__ - INFO - 使用数据集适配层加载: math
2025-12-24 18:31:16,458 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,458 - __main__ - INFO - [数据集适配层] 开始加载数据集: math
2025-12-24 18:31:16,458 - __main__ - INFO - [数据集适配层] 文件路径: dataset/math/test.jsonl
2025-12-24 18:31:16,458 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,461 - __main__ - INFO - [数据集适配层] 已加载 JSONL 文件: 500 条
2025-12-24 18:31:16,461 - __main__ - INFO - 预处理 MATH 数据集: 500 条
2025-12-24 18:31:16,461 - __main__ - INFO - [数据集适配层] 预处理完成: 500 条有效数据
2025-12-24 18:31:16,461 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 18:31:16,461 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,461 - __main__ - INFO - 数据集加载成功，共 500 条数据
2025-12-24 18:31:16,461 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,461 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 18:31:16,461 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,461 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 18:31:16,462 - __main__ - INFO - 共需处理 500 条数据，批次大小: 64
2025-12-24 18:31:16,462 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,462 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 18:31:16,462 - __main__ - INFO - ============================================================
2025-12-24 18:31:16,462 - __main__ - INFO - 处理批次 [1-128/500]
2025-12-24 18:31:16,462 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 18:31:16,462 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 18:31:21,018 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 2,3
2025-12-24 18:31:21,018 - inference.local_inference - INFO - ============================================================
2025-12-24 18:31:21,018 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 18:31:21,018 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 18:31:21,019 - inference.local_inference - INFO - ============================================================
2025-12-24 18:32:28,943 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 18:34:00,283 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 18:34:00,284 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 18:35:05,887 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 18:35:05,888 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 18:36:40,153 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 18:36:40,153 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 18:41:30,831 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 18:41:30,831 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 18:41:30,831 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 18:41:30,831 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 18:41:38,955 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 18:41:38,955 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 18:42:46,958 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 18:42:46,959 - __main__ - INFO - 处理批次 [129-256/99842]
2025-12-24 18:42:46,959 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 18:42:46,959 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 18:43:07,986 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 18:43:07,987 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 18:50:28,201 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-24 18:50:28,201 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-24 18:53:19,832 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 18:53:19,833 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 18:53:31,300 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 18:53:31,300 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 18:56:38,251 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-24 18:56:38,251 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-24 18:56:38,252 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 18:56:38,333 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 18:56:38,333 - __main__ - INFO - ============================================================
2025-12-24 18:56:38,333 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 18:56:38,333 - __main__ - INFO - ============================================================
2025-12-24 18:56:38,333 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-24 18:56:38,333 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-24 18:56:38,333 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 18:57:14,991 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 18:57:14,992 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-24 18:57:14,992 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 18:57:40,873 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 18:57:40,873 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-24 18:57:40,874 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 18:58:38,713 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 18:58:38,714 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-24 18:58:38,714 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 18:59:20,579 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 18:59:20,580 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-24 18:59:20,580 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 18:59:38,610 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-24 18:59:38,610 - __main__ - INFO - 处理批次 [257-384/99842]
2025-12-24 18:59:38,611 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 18:59:38,611 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 18:59:59,562 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 18:59:59,562 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:00:14,420 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 19:00:14,421 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-24 19:00:14,421 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:01:04,313 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 19:01:04,314 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-24 19:01:04,314 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:01:48,283 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 19:01:48,284 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-24 19:01:48,284 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:02:16,983 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 19:02:16,984 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-24 19:02:16,984 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:02:52,032 - __main__ - INFO - API批次 [241-250] 完成
2025-12-24 19:02:52,032 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-24 19:02:52,032 - __main__ - INFO - 开始数据质量检查...
2025-12-24 19:02:52,033 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-24 19:02:52,033 - __main__ - INFO - ============================================================
2025-12-24 19:02:52,033 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 19:02:52,033 - __main__ - INFO - ============================================================
2025-12-24 19:02:52,033 - __main__ - INFO - 预检查数据完整性...
2025-12-24 19:02:52,034 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-24 19:02:52,034 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-24 19:02:52,034 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 19:02:52,060 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-24 19:02:52,091 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-24 19:02:52,108 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-24 19:02:52,128 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-24 19:02:52,144 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-24 19:02:52,162 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 19:02:52,163 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-24 19:02:53,439 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 19:02:53,468 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 19:02:54,540 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,540 - __main__ - INFO - 数据集名称: bbh
2025-12-24 19:02:54,540 - __main__ - INFO - 数据集路径: dataset/bbh/causal_judgement.json
2025-12-24 19:02:54,540 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,540 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 19:02:54,540 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,540 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 19:02:54,540 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/causal_judgement.json
2025-12-24 19:02:54,540 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,541 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 19:02:54,541 - __main__ - INFO - 预处理 BBH 数据集: 187 条
2025-12-24 19:02:54,541 - __main__ - INFO - [数据集适配层] 预处理完成: 187 条有效数据
2025-12-24 19:02:54,541 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 19:02:54,541 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,541 - __main__ - INFO - 数据集加载成功，共 187 条数据
2025-12-24 19:02:54,541 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,541 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 19:02:54,541 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,542 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 19:02:54,544 - __main__ - INFO - 共需处理 187 条数据，批次大小: 64
2025-12-24 19:02:54,544 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,544 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 19:02:54,544 - __main__ - INFO - ============================================================
2025-12-24 19:02:54,544 - __main__ - INFO - 处理批次 [1-128/187]
2025-12-24 19:02:54,544 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 19:02:54,544 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 19:02:58,993 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 19:02:58,994 - inference.local_inference - INFO - ============================================================
2025-12-24 19:02:58,994 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 19:02:58,994 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 19:02:58,994 - inference.local_inference - INFO - ============================================================
2025-12-24 19:03:58,213 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 19:04:13,605 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 19:04:13,606 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:07:29,283 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 19:07:29,284 - __main__ - INFO - 处理批次 [129-256/500]
2025-12-24 19:07:29,284 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 19:07:29,284 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 19:10:27,407 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 19:10:27,407 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 19:12:22,939 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 19:12:22,940 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:14:12,232 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 19:14:12,233 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 19:16:28,037 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-24 19:16:28,037 - __main__ - INFO - 处理批次 [385-512/99842]
2025-12-24 19:16:28,038 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 19:16:28,038 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 19:16:49,799 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 19:16:49,799 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:20:12,621 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 19:20:12,621 - __main__ - INFO - 处理批次 [129-187/187]
2025-12-24 19:20:12,621 - __main__ - INFO -   → 生成Baseline答案 (59 条)...
2025-12-24 19:20:12,621 - __main__ - INFO - 批量生成Baseline答案: 59 条
2025-12-24 19:20:22,088 - __main__ - INFO -   → 生成差异分析 (59 条)...
2025-12-24 19:20:22,089 - __main__ - INFO - 批量生成差异分析: 59 条
2025-12-24 19:24:58,810 - __main__ - INFO -   → 生成Rejected原则 (59 条)...
2025-12-24 19:24:58,811 - __main__ - INFO - 批量生成原则（弱模型）: 59 条
2025-12-24 19:27:39,317 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 19:27:39,318 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 19:28:41,178 - __main__ - INFO - 批次 [129-187] 本地推理完成
2025-12-24 19:28:41,178 - __main__ - INFO - 阶段1完成: 共生成 187 条本地推理结果
2025-12-24 19:28:41,178 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 19:28:41,249 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 19:28:41,249 - __main__ - INFO - ============================================================
2025-12-24 19:28:41,249 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 19:28:41,249 - __main__ - INFO - ============================================================
2025-12-24 19:28:41,249 - __main__ - INFO - API分批处理: 每批 30 条，共 7 批
2025-12-24 19:28:41,249 - __main__ - INFO - API批次 [1-30/187] 开始处理...
2025-12-24 19:28:41,249 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:29:15,006 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 19:29:15,007 - __main__ - INFO - API批次 [31-60/187] 开始处理...
2025-12-24 19:29:15,007 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:29:57,308 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 19:29:57,309 - __main__ - INFO - API批次 [61-90/187] 开始处理...
2025-12-24 19:29:57,309 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:30:40,197 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 19:30:40,198 - __main__ - INFO - API批次 [91-120/187] 开始处理...
2025-12-24 19:30:40,198 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:31:00,067 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 19:31:00,067 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 19:31:23,219 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 19:31:23,220 - __main__ - INFO - API批次 [121-150/187] 开始处理...
2025-12-24 19:31:23,220 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:31:49,667 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 19:31:49,671 - __main__ - INFO - API批次 [151-180/187] 开始处理...
2025-12-24 19:31:49,671 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:32:15,106 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 19:32:15,106 - __main__ - INFO - API批次 [181-187/187] 开始处理...
2025-12-24 19:32:15,106 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 19:33:31,578 - __main__ - INFO - API批次 [181-187] 完成
2025-12-24 19:33:31,579 - __main__ - INFO - 阶段2完成: 共生成 187 条Chosen结果
2025-12-24 19:33:31,579 - __main__ - INFO - 开始数据质量检查...
2025-12-24 19:33:31,583 - __main__ - INFO - ✅ 数据质量检查通过: 187 条chosen全部非空
2025-12-24 19:33:31,583 - __main__ - INFO - ============================================================
2025-12-24 19:33:31,583 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 19:33:31,583 - __main__ - INFO - ============================================================
2025-12-24 19:33:31,583 - __main__ - INFO - 预检查数据完整性...
2025-12-24 19:33:31,584 - __main__ - INFO - Chosen非空率: 187/187 (100.0%)
2025-12-24 19:33:31,584 - __main__ - INFO - Rejected非空率: 187/187 (100.0%)
2025-12-24 19:33:31,584 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 19:33:31,606 - __main__ - INFO - 已保存 50/187 条到JSONL
2025-12-24 19:33:31,627 - __main__ - INFO - 已保存 100/187 条到JSONL
2025-12-24 19:33:31,648 - __main__ - INFO - 已保存 150/187 条到JSONL
2025-12-24 19:33:31,678 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 19:33:31,678 - __main__ - INFO - 共保存 187 条数据到JSONL格式
2025-12-24 19:33:33,052 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 19:33:33,091 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 19:33:34,169 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,169 - __main__ - INFO - 数据集名称: bbh
2025-12-24 19:33:34,169 - __main__ - INFO - 数据集路径: dataset/bbh/date_understanding.json
2025-12-24 19:33:34,169 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,169 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 19:33:34,169 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,169 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 19:33:34,169 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/date_understanding.json
2025-12-24 19:33:34,169 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,170 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 19:33:34,170 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 19:33:34,170 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 19:33:34,170 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 19:33:34,170 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,170 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 19:33:34,170 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,170 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 19:33:34,170 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,171 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 19:33:34,174 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 19:33:34,174 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,174 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 19:33:34,174 - __main__ - INFO - ============================================================
2025-12-24 19:33:34,174 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 19:33:34,174 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 19:33:34,174 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 19:33:38,496 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 19:33:38,496 - inference.local_inference - INFO - ============================================================
2025-12-24 19:33:38,496 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 19:33:38,496 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 19:33:38,496 - inference.local_inference - INFO - ============================================================
2025-12-24 19:33:44,904 - __main__ - INFO - 批次 [385-512] 本地推理完成
2025-12-24 19:33:44,905 - __main__ - INFO - 处理批次 [513-640/99842]
2025-12-24 19:33:44,905 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 19:33:44,905 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 19:34:07,576 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 19:34:07,577 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:34:37,510 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 19:34:56,245 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 19:34:56,246 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:43:55,428 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 19:43:55,428 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 19:44:17,144 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 19:44:17,144 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 19:46:01,822 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-24 19:46:01,822 - __main__ - INFO - 处理批次 [257-384/500]
2025-12-24 19:46:01,822 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 19:46:01,822 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 19:47:43,721 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 19:47:43,722 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:50:30,210 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 19:50:30,210 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 19:50:30,210 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 19:50:30,210 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 19:50:43,598 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 19:50:43,599 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 19:50:46,890 - __main__ - INFO - 批次 [513-640] 本地推理完成
2025-12-24 19:50:46,890 - __main__ - INFO - 处理批次 [641-768/99842]
2025-12-24 19:50:46,891 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 19:50:46,891 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 19:51:09,318 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 19:51:09,318 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 19:59:24,489 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-24 19:59:24,489 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-24 20:01:18,271 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 20:01:18,271 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 20:05:37,123 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-24 20:05:37,124 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-24 20:05:37,124 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 20:05:37,198 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 20:05:37,198 - __main__ - INFO - ============================================================
2025-12-24 20:05:37,198 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 20:05:37,198 - __main__ - INFO - ============================================================
2025-12-24 20:05:37,198 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-24 20:05:37,198 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-24 20:05:37,198 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:06:22,892 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 20:06:22,893 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-24 20:06:22,893 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:07:19,186 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 20:07:19,187 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-24 20:07:19,187 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:07:40,603 - __main__ - INFO - 批次 [641-768] 本地推理完成
2025-12-24 20:07:40,603 - __main__ - INFO - 处理批次 [769-896/99842]
2025-12-24 20:07:40,604 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 20:07:40,604 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 20:07:51,979 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 20:07:51,979 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 20:07:52,685 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 20:07:52,686 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-24 20:07:52,686 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:08:03,010 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 20:08:03,010 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 20:08:28,344 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 20:08:28,345 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-24 20:08:28,345 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:09:12,942 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 20:09:12,942 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-24 20:09:12,942 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:09:56,428 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 20:09:56,428 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-24 20:09:56,428 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:10:27,659 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 20:10:27,660 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-24 20:10:27,660 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:11:13,715 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 20:11:13,716 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-24 20:11:13,716 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:11:54,842 - __main__ - INFO - API批次 [241-250] 完成
2025-12-24 20:11:54,842 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-24 20:11:54,842 - __main__ - INFO - 开始数据质量检查...
2025-12-24 20:11:54,842 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-24 20:11:54,842 - __main__ - INFO - ============================================================
2025-12-24 20:11:54,842 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 20:11:54,842 - __main__ - INFO - ============================================================
2025-12-24 20:11:54,842 - __main__ - INFO - 预检查数据完整性...
2025-12-24 20:11:54,843 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-24 20:11:54,843 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-24 20:11:54,843 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 20:11:54,870 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-24 20:11:54,894 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-24 20:11:54,917 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-24 20:11:54,938 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-24 20:11:54,959 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-24 20:11:54,975 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 20:11:54,975 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-24 20:11:56,250 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 20:11:56,281 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 20:11:57,343 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,343 - __main__ - INFO - 数据集名称: bbh
2025-12-24 20:11:57,343 - __main__ - INFO - 数据集路径: dataset/bbh/disambiguation_qa.json
2025-12-24 20:11:57,343 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,343 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 20:11:57,343 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,344 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 20:11:57,344 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/disambiguation_qa.json
2025-12-24 20:11:57,344 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,344 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 20:11:57,344 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 20:11:57,344 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 20:11:57,344 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 20:11:57,344 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,344 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 20:11:57,344 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,344 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 20:11:57,344 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,345 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 20:11:57,347 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 20:11:57,347 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,347 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 20:11:57,347 - __main__ - INFO - ============================================================
2025-12-24 20:11:57,347 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 20:11:57,347 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 20:11:57,347 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 20:12:01,789 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 20:12:01,789 - inference.local_inference - INFO - ============================================================
2025-12-24 20:12:01,789 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 20:12:01,789 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 20:12:01,789 - inference.local_inference - INFO - ============================================================
2025-12-24 20:13:00,462 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 20:13:10,941 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 20:13:10,942 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 20:18:09,261 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 20:18:09,261 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 20:22:16,436 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-24 20:22:16,437 - __main__ - INFO - 处理批次 [385-500/500]
2025-12-24 20:22:16,437 - __main__ - INFO -   → 生成Baseline答案 (116 条)...
2025-12-24 20:22:16,437 - __main__ - INFO - 批量生成Baseline答案: 116 条
2025-12-24 20:23:17,144 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 20:23:17,144 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 20:24:27,775 - __main__ - INFO - 批次 [769-896] 本地推理完成
2025-12-24 20:24:27,775 - __main__ - INFO - 处理批次 [897-1024/99842]
2025-12-24 20:24:27,776 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 20:24:27,776 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 20:24:50,260 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 20:24:50,261 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 20:26:28,993 - __main__ - INFO -   → 生成差异分析 (116 条)...
2025-12-24 20:26:28,993 - __main__ - INFO - 批量生成差异分析: 116 条
2025-12-24 20:29:23,049 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 20:29:23,050 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 20:29:23,050 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 20:29:23,050 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 20:29:33,376 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 20:29:33,376 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 20:35:20,447 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 20:35:20,447 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 20:39:06,747 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-24 20:39:06,747 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-24 20:41:33,673 - __main__ - INFO - 批次 [897-1024] 本地推理完成
2025-12-24 20:41:33,674 - __main__ - INFO - 处理批次 [1025-1152/99842]
2025-12-24 20:41:33,674 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 20:41:33,674 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 20:41:54,744 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 20:41:54,744 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 20:42:15,654 - __main__ - INFO -   → 生成Rejected原则 (116 条)...
2025-12-24 20:42:15,654 - __main__ - INFO - 批量生成原则（弱模型）: 116 条
2025-12-24 20:45:01,277 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-24 20:45:01,277 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-24 20:45:01,277 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 20:45:01,364 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 20:45:01,365 - __main__ - INFO - ============================================================
2025-12-24 20:45:01,365 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 20:45:01,365 - __main__ - INFO - ============================================================
2025-12-24 20:45:01,365 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-24 20:45:01,365 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-24 20:45:01,365 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:45:31,951 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 20:45:31,952 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-24 20:45:31,952 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:46:39,771 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 20:46:39,772 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-24 20:46:39,772 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:47:12,512 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 20:47:12,513 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-24 20:47:12,513 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:47:44,165 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 20:47:44,166 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-24 20:47:44,166 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:48:19,343 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 20:48:19,344 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-24 20:48:19,344 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:49:22,437 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 20:49:22,438 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-24 20:49:22,438 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:50:07,821 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 20:50:07,822 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-24 20:50:07,822 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:50:30,996 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 20:50:30,997 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-24 20:50:30,997 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:50:54,370 - __main__ - INFO - API批次 [241-250] 完成
2025-12-24 20:50:54,371 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-24 20:50:54,371 - __main__ - INFO - 开始数据质量检查...
2025-12-24 20:50:54,371 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-24 20:50:54,371 - __main__ - INFO - ============================================================
2025-12-24 20:50:54,371 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 20:50:54,371 - __main__ - INFO - ============================================================
2025-12-24 20:50:54,371 - __main__ - INFO - 预检查数据完整性...
2025-12-24 20:50:54,372 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-24 20:50:54,372 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-24 20:50:54,372 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 20:50:54,396 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-24 20:50:54,417 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-24 20:50:54,438 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-24 20:50:54,463 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-24 20:50:54,481 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-24 20:50:54,491 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 20:50:54,492 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-24 20:50:55,765 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 20:50:55,795 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 20:50:56,853 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,853 - __main__ - INFO - 数据集名称: bbh
2025-12-24 20:50:56,853 - __main__ - INFO - 数据集路径: dataset/bbh/dyck_languages.json
2025-12-24 20:50:56,853 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,854 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 20:50:56,854 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,854 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 20:50:56,854 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/dyck_languages.json
2025-12-24 20:50:56,854 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,854 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 20:50:56,854 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 20:50:56,854 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 20:50:56,854 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 20:50:56,854 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,854 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 20:50:56,854 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,854 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 20:50:56,854 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,855 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 20:50:56,857 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 20:50:56,857 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,857 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 20:50:56,857 - __main__ - INFO - ============================================================
2025-12-24 20:50:56,857 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 20:50:56,857 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 20:50:56,857 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 20:51:01,203 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 20:51:01,203 - inference.local_inference - INFO - ============================================================
2025-12-24 20:51:01,203 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 20:51:01,203 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 20:51:01,203 - inference.local_inference - INFO - ============================================================
2025-12-24 20:52:01,017 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 20:52:09,660 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 20:52:09,660 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 20:54:11,819 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 20:54:11,820 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 20:56:15,611 - __main__ - INFO - 批次 [385-500] 本地推理完成
2025-12-24 20:56:15,611 - __main__ - INFO - 阶段1完成: 共生成 500 条本地推理结果
2025-12-24 20:56:15,611 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 20:56:15,761 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 20:56:15,761 - __main__ - INFO - ============================================================
2025-12-24 20:56:15,761 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 20:56:15,761 - __main__ - INFO - ============================================================
2025-12-24 20:56:15,761 - __main__ - INFO - API分批处理: 每批 30 条，共 17 批
2025-12-24 20:56:15,761 - __main__ - INFO - API批次 [1-30/500] 开始处理...
2025-12-24 20:56:15,761 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:56:44,711 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 20:56:44,711 - __main__ - INFO - API批次 [31-60/500] 开始处理...
2025-12-24 20:56:44,712 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:57:15,746 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 20:57:15,746 - __main__ - INFO - API批次 [61-90/500] 开始处理...
2025-12-24 20:57:15,746 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:57:53,353 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 20:57:53,354 - __main__ - INFO - API批次 [91-120/500] 开始处理...
2025-12-24 20:57:53,354 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:58:29,571 - __main__ - INFO - 批次 [1025-1152] 本地推理完成
2025-12-24 20:58:29,572 - __main__ - INFO - 处理批次 [1153-1280/99842]
2025-12-24 20:58:29,573 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 20:58:29,573 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 20:58:42,649 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 20:58:42,650 - __main__ - INFO - API批次 [121-150/500] 开始处理...
2025-12-24 20:58:42,650 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 20:58:44,778 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 20:58:44,779 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 20:59:46,982 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 20:59:46,982 - __main__ - INFO - API批次 [151-180/500] 开始处理...
2025-12-24 20:59:46,982 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:00:16,540 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 21:00:16,541 - __main__ - INFO - API批次 [181-210/500] 开始处理...
2025-12-24 21:00:16,541 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:01:16,002 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 21:01:16,002 - __main__ - INFO - API批次 [211-240/500] 开始处理...
2025-12-24 21:01:16,002 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:02:17,918 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 21:02:17,919 - __main__ - INFO - API批次 [241-270/500] 开始处理...
2025-12-24 21:02:17,919 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:03:17,618 - __main__ - INFO - API批次 [241-270] 完成
2025-12-24 21:03:17,618 - __main__ - INFO - API批次 [271-300/500] 开始处理...
2025-12-24 21:03:17,618 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:04:15,991 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 21:04:15,991 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 21:07:07,983 - __main__ - WARNING - ⚠️  批次中有 1/30 个空响应
2025-12-24 21:07:07,984 - __main__ - INFO - API批次 [271-300] 完成
2025-12-24 21:07:07,984 - __main__ - INFO - API批次 [301-330/500] 开始处理...
2025-12-24 21:07:07,984 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:07:59,477 - __main__ - INFO - API批次 [301-330] 完成
2025-12-24 21:07:59,477 - __main__ - INFO - API批次 [331-360/500] 开始处理...
2025-12-24 21:07:59,478 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:08:19,923 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 21:08:19,924 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 21:10:42,791 - __main__ - INFO - API批次 [331-360] 完成
2025-12-24 21:10:42,792 - __main__ - INFO - API批次 [361-390/500] 开始处理...
2025-12-24 21:10:42,793 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:10:43,323 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 21:10:43,324 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 21:10:43,324 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 21:10:43,324 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 21:11:29,517 - __main__ - INFO - API批次 [361-390] 完成
2025-12-24 21:11:29,518 - __main__ - INFO - API批次 [391-420/500] 开始处理...
2025-12-24 21:11:29,518 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:12:05,068 - __main__ - INFO - API批次 [391-420] 完成
2025-12-24 21:12:05,069 - __main__ - INFO - API批次 [421-450/500] 开始处理...
2025-12-24 21:12:05,069 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:12:50,017 - __main__ - INFO - API批次 [421-450] 完成
2025-12-24 21:12:50,018 - __main__ - INFO - API批次 [451-480/500] 开始处理...
2025-12-24 21:12:50,018 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:12:51,540 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 21:12:51,540 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 21:13:57,261 - __main__ - INFO - API批次 [451-480] 完成
2025-12-24 21:13:57,261 - __main__ - INFO - API批次 [481-500/500] 开始处理...
2025-12-24 21:13:57,262 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:14:40,989 - __main__ - INFO - API批次 [481-500] 完成
2025-12-24 21:14:40,990 - __main__ - INFO - 阶段2完成: 共生成 500 条Chosen结果
2025-12-24 21:14:40,990 - __main__ - INFO - 开始数据质量检查...
2025-12-24 21:14:40,990 - __main__ - WARNING - ⚠️  发现 1 个空chosen值 (0.2%)
2025-12-24 21:14:40,990 - __main__ - WARNING -    空值索引（前10个）: [286]
2025-12-24 21:14:40,990 - __main__ - INFO - ✅ 空值率在可接受范围内 (0.2% < 5%)，将过滤空值后继续
2025-12-24 21:14:40,994 - __main__ - INFO - 过滤后剩余 499 条有效数据
2025-12-24 21:14:40,994 - __main__ - INFO - ============================================================
2025-12-24 21:14:40,994 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 21:14:40,994 - __main__ - INFO - ============================================================
2025-12-24 21:14:40,994 - __main__ - INFO - 预检查数据完整性...
2025-12-24 21:14:40,994 - __main__ - INFO - Chosen非空率: 499/499 (100.0%)
2025-12-24 21:14:40,994 - __main__ - INFO - Rejected非空率: 499/499 (100.0%)
2025-12-24 21:14:40,995 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 21:14:41,013 - __main__ - INFO - 已保存 50/500 条到JSONL
2025-12-24 21:14:41,032 - __main__ - INFO - 已保存 100/500 条到JSONL
2025-12-24 21:14:41,050 - __main__ - INFO - 已保存 150/500 条到JSONL
2025-12-24 21:14:41,069 - __main__ - INFO - 已保存 200/500 条到JSONL
2025-12-24 21:14:41,087 - __main__ - INFO - 已保存 250/500 条到JSONL
2025-12-24 21:14:41,106 - __main__ - INFO - 已保存 300/500 条到JSONL
2025-12-24 21:14:41,125 - __main__ - INFO - 已保存 350/500 条到JSONL
2025-12-24 21:14:41,145 - __main__ - INFO - 已保存 400/500 条到JSONL
2025-12-24 21:14:41,164 - __main__ - INFO - 已保存 450/500 条到JSONL
2025-12-24 21:14:41,208 - __main__ - INFO - DPO数据生成完成: output/dpo_math.jsonl
2025-12-24 21:14:41,208 - __main__ - INFO - 共保存 499 条数据到JSONL格式
2025-12-24 21:14:42,286 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 21:14:42,319 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 21:14:50,806 - __main__ - INFO - 批次 [1153-1280] 本地推理完成
2025-12-24 21:14:50,807 - __main__ - INFO - 处理批次 [1281-1408/99842]
2025-12-24 21:14:50,807 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 21:14:50,807 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 21:15:01,851 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 21:15:01,851 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 21:22:29,616 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-24 21:22:29,617 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-24 21:24:22,774 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 21:24:22,774 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 21:28:38,194 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-24 21:28:38,194 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-24 21:28:38,194 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 21:28:38,275 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 21:28:38,275 - __main__ - INFO - ============================================================
2025-12-24 21:28:38,275 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 21:28:38,275 - __main__ - INFO - ============================================================
2025-12-24 21:28:38,275 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-24 21:28:38,275 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-24 21:28:38,275 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:29:00,391 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 21:29:00,391 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-24 21:29:00,392 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:29:50,043 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 21:29:50,044 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-24 21:29:50,044 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:30:17,218 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 21:30:17,219 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-24 21:30:17,220 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:30:59,662 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 21:30:59,663 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-24 21:30:59,663 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:31:03,878 - __main__ - INFO - 批次 [1281-1408] 本地推理完成
2025-12-24 21:31:03,879 - __main__ - INFO - 处理批次 [1409-1536/99842]
2025-12-24 21:31:03,879 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 21:31:03,879 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 21:31:25,208 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 21:31:25,208 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 21:31:38,904 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 21:31:38,905 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-24 21:31:38,905 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:32:16,669 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 21:32:16,670 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-24 21:32:16,670 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:33:00,381 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 21:33:00,382 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-24 21:33:00,382 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:34:29,561 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 21:34:29,563 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-24 21:34:29,563 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 21:35:24,144 - __main__ - INFO - API批次 [241-250] 完成
2025-12-24 21:35:24,144 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-24 21:35:24,144 - __main__ - INFO - 开始数据质量检查...
2025-12-24 21:35:24,144 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-24 21:35:24,144 - __main__ - INFO - ============================================================
2025-12-24 21:35:24,144 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 21:35:24,144 - __main__ - INFO - ============================================================
2025-12-24 21:35:24,144 - __main__ - INFO - 预检查数据完整性...
2025-12-24 21:35:24,145 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-24 21:35:24,145 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-24 21:35:24,145 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 21:35:24,175 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-24 21:35:24,201 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-24 21:35:24,226 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-24 21:35:24,250 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-24 21:35:24,274 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-24 21:35:24,293 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 21:35:24,293 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-24 21:35:25,770 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 21:35:25,800 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 21:35:26,860 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,860 - __main__ - INFO - 数据集名称: bbh
2025-12-24 21:35:26,860 - __main__ - INFO - 数据集路径: dataset/bbh/formal_fallacies.json
2025-12-24 21:35:26,860 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,860 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 21:35:26,860 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,860 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 21:35:26,860 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/formal_fallacies.json
2025-12-24 21:35:26,860 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,861 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 21:35:26,861 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 21:35:26,861 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 21:35:26,861 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 21:35:26,861 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,861 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 21:35:26,861 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,861 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 21:35:26,861 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,862 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 21:35:26,864 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 21:35:26,864 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,864 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 21:35:26,865 - __main__ - INFO - ============================================================
2025-12-24 21:35:26,865 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 21:35:26,865 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 21:35:26,865 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 21:35:31,315 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 21:35:31,315 - inference.local_inference - INFO - ============================================================
2025-12-24 21:35:31,315 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 21:35:31,315 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 21:35:31,315 - inference.local_inference - INFO - ============================================================
2025-12-24 21:36:29,970 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 21:36:55,146 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 21:36:55,147 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 21:41:08,224 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 21:41:08,224 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 21:47:32,591 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 21:47:32,592 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 21:47:42,484 - __main__ - INFO - 批次 [1409-1536] 本地推理完成
2025-12-24 21:47:42,484 - __main__ - INFO - 处理批次 [1537-1664/99842]
2025-12-24 21:47:42,484 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 21:47:42,484 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 21:47:55,756 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 21:47:55,756 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 21:53:31,914 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 21:53:31,914 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 21:53:31,914 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 21:53:31,914 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 21:53:58,261 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 21:53:58,262 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 21:57:35,419 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 21:57:35,419 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 22:04:00,816 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-24 22:04:00,816 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-24 22:04:10,588 - __main__ - INFO - 批次 [1537-1664] 本地推理完成
2025-12-24 22:04:10,588 - __main__ - INFO - 处理批次 [1665-1792/99842]
2025-12-24 22:04:10,588 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 22:04:10,588 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 22:05:59,914 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 22:05:59,915 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 22:09:29,242 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-24 22:09:29,242 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-24 22:09:29,242 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 22:09:29,336 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 22:09:29,336 - __main__ - INFO - ============================================================
2025-12-24 22:09:29,336 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 22:09:29,336 - __main__ - INFO - ============================================================
2025-12-24 22:09:29,336 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-24 22:09:29,336 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-24 22:09:29,336 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:09:56,277 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 22:09:56,278 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-24 22:09:56,278 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:10:42,400 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 22:10:42,400 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-24 22:10:42,400 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:11:27,020 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 22:11:27,021 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-24 22:11:27,021 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:11:59,103 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 22:11:59,104 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-24 22:11:59,104 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:12:41,892 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 22:12:41,892 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-24 22:12:41,893 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:13:13,269 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 22:13:13,269 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-24 22:13:13,269 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:13:42,565 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 22:13:42,566 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-24 22:13:42,566 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:14:15,300 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 22:14:15,301 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-24 22:14:15,301 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:14:41,838 - __main__ - INFO - API批次 [241-250] 完成
2025-12-24 22:14:41,838 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-24 22:14:41,838 - __main__ - INFO - 开始数据质量检查...
2025-12-24 22:14:41,839 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-24 22:14:41,839 - __main__ - INFO - ============================================================
2025-12-24 22:14:41,839 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 22:14:41,839 - __main__ - INFO - ============================================================
2025-12-24 22:14:41,839 - __main__ - INFO - 预检查数据完整性...
2025-12-24 22:14:41,840 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-24 22:14:41,840 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-24 22:14:41,840 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 22:14:41,865 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-24 22:14:41,886 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-24 22:14:41,908 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-24 22:14:41,928 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-24 22:14:41,948 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-24 22:14:41,967 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 22:14:41,968 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-24 22:14:43,151 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 22:14:43,180 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 22:14:44,264 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,264 - __main__ - INFO - 数据集名称: bbh
2025-12-24 22:14:44,264 - __main__ - INFO - 数据集路径: dataset/bbh/geometric_shapes.json
2025-12-24 22:14:44,264 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,264 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 22:14:44,264 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,264 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 22:14:44,264 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/geometric_shapes.json
2025-12-24 22:14:44,264 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,264 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 22:14:44,264 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 22:14:44,265 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 22:14:44,265 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 22:14:44,265 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,265 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 22:14:44,265 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,265 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 22:14:44,265 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,265 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 22:14:44,268 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 22:14:44,268 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,268 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 22:14:44,268 - __main__ - INFO - ============================================================
2025-12-24 22:14:44,268 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 22:14:44,268 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 22:14:44,268 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 22:14:48,858 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 22:14:48,858 - inference.local_inference - INFO - ============================================================
2025-12-24 22:14:48,858 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 22:14:48,858 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 22:14:48,858 - inference.local_inference - INFO - ============================================================
2025-12-24 22:15:47,559 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 22:15:57,172 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 22:15:57,173 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 22:16:05,461 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 22:16:05,462 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 22:22:30,636 - __main__ - INFO - 批次 [1665-1792] 本地推理完成
2025-12-24 22:22:30,637 - __main__ - INFO - 处理批次 [1793-1920/99842]
2025-12-24 22:22:30,637 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 22:22:30,637 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 22:22:47,619 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 22:22:47,619 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 22:25:40,856 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 22:25:40,856 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 22:31:39,747 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 22:31:39,748 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 22:31:39,748 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 22:31:39,748 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 22:31:58,361 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 22:31:58,361 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 22:32:06,083 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 22:32:06,083 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 22:38:51,959 - __main__ - INFO - 批次 [1793-1920] 本地推理完成
2025-12-24 22:38:51,960 - __main__ - INFO - 处理批次 [1921-2048/99842]
2025-12-24 22:38:51,960 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 22:38:51,960 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 22:39:04,201 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 22:39:04,201 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 22:40:59,702 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-24 22:40:59,702 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-24 22:47:05,048 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-24 22:47:05,049 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-24 22:47:05,049 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 22:47:05,153 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 22:47:05,154 - __main__ - INFO - ============================================================
2025-12-24 22:47:05,154 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 22:47:05,154 - __main__ - INFO - ============================================================
2025-12-24 22:47:05,154 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-24 22:47:05,154 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-24 22:47:05,154 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:47:58,839 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 22:47:58,840 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-24 22:47:58,840 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:48:44,711 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 22:48:44,712 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-24 22:48:44,712 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:48:49,889 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 22:48:49,889 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 22:49:27,926 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 22:49:27,927 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-24 22:49:27,927 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:49:55,558 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 22:49:55,559 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-24 22:49:55,559 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:50:24,420 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 22:50:24,421 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-24 22:50:24,421 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:51:47,941 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 22:51:47,941 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-24 22:51:47,941 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:52:25,852 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 22:52:25,853 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-24 22:52:25,853 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:53:38,772 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 22:53:38,772 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-24 22:53:38,772 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 22:54:21,246 - __main__ - INFO - API批次 [241-250] 完成
2025-12-24 22:54:21,246 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-24 22:54:21,246 - __main__ - INFO - 开始数据质量检查...
2025-12-24 22:54:21,247 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-24 22:54:21,247 - __main__ - INFO - ============================================================
2025-12-24 22:54:21,247 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 22:54:21,247 - __main__ - INFO - ============================================================
2025-12-24 22:54:21,247 - __main__ - INFO - 预检查数据完整性...
2025-12-24 22:54:21,248 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-24 22:54:21,248 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-24 22:54:21,248 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 22:54:21,269 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-24 22:54:21,288 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-24 22:54:21,317 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-24 22:54:21,336 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-24 22:54:21,353 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-24 22:54:21,371 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 22:54:21,371 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-24 22:54:22,651 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 22:54:22,686 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 22:54:23,831 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,831 - __main__ - INFO - 数据集名称: bbh
2025-12-24 22:54:23,831 - __main__ - INFO - 数据集路径: dataset/bbh/hyperbaton.json
2025-12-24 22:54:23,831 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,831 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 22:54:23,831 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,831 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 22:54:23,831 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/hyperbaton.json
2025-12-24 22:54:23,831 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,832 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 22:54:23,832 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 22:54:23,832 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 22:54:23,832 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 22:54:23,832 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,832 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 22:54:23,832 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,832 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 22:54:23,832 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,833 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 22:54:23,835 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 22:54:23,835 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,835 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 22:54:23,835 - __main__ - INFO - ============================================================
2025-12-24 22:54:23,835 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 22:54:23,835 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 22:54:23,835 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 22:54:28,389 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 22:54:28,389 - inference.local_inference - INFO - ============================================================
2025-12-24 22:54:28,389 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 22:54:28,389 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 22:54:28,389 - inference.local_inference - INFO - ============================================================
2025-12-24 22:55:13,915 - __main__ - INFO - 批次 [1921-2048] 本地推理完成
2025-12-24 22:55:13,915 - __main__ - INFO - 处理批次 [2049-2176/99842]
2025-12-24 22:55:13,916 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 22:55:13,916 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 22:55:27,059 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 22:55:27,060 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 22:55:27,203 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 22:55:39,182 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 22:55:39,183 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 23:05:03,265 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 23:05:03,266 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 23:05:25,853 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 23:05:25,854 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 23:11:23,646 - __main__ - INFO - 批次 [2049-2176] 本地推理完成
2025-12-24 23:11:23,646 - __main__ - INFO - 处理批次 [2177-2304/99842]
2025-12-24 23:11:23,647 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 23:11:23,647 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 23:11:39,703 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 23:11:39,703 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 23:11:46,241 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 23:11:46,241 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 23:11:46,242 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 23:11:46,242 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 23:11:57,203 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 23:11:57,203 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 23:21:31,264 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-24 23:21:31,264 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-24 23:21:33,558 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 23:21:33,559 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 23:27:38,925 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-24 23:27:38,925 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-24 23:27:38,925 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-24 23:27:39,011 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-24 23:27:39,011 - __main__ - INFO - ============================================================
2025-12-24 23:27:39,011 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-24 23:27:39,011 - __main__ - INFO - ============================================================
2025-12-24 23:27:39,011 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-24 23:27:39,011 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-24 23:27:39,011 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:28:00,042 - __main__ - INFO - 批次 [2177-2304] 本地推理完成
2025-12-24 23:28:00,043 - __main__ - INFO - 处理批次 [2305-2432/99842]
2025-12-24 23:28:00,043 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 23:28:00,043 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 23:28:12,854 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 23:28:12,854 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 23:28:16,224 - __main__ - INFO - API批次 [1-30] 完成
2025-12-24 23:28:16,225 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-24 23:28:16,225 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:29:06,258 - __main__ - INFO - API批次 [31-60] 完成
2025-12-24 23:29:06,258 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-24 23:29:06,258 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:29:45,268 - __main__ - INFO - API批次 [61-90] 完成
2025-12-24 23:29:45,269 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-24 23:29:45,269 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:30:11,748 - __main__ - INFO - API批次 [91-120] 完成
2025-12-24 23:30:11,748 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-24 23:30:11,749 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:30:50,037 - __main__ - INFO - API批次 [121-150] 完成
2025-12-24 23:30:50,038 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-24 23:30:50,038 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:31:26,160 - __main__ - INFO - API批次 [151-180] 完成
2025-12-24 23:31:26,160 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-24 23:31:26,160 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:32:12,428 - __main__ - INFO - API批次 [181-210] 完成
2025-12-24 23:32:12,429 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-24 23:32:12,429 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:32:39,019 - __main__ - INFO - API批次 [211-240] 完成
2025-12-24 23:32:39,019 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-24 23:32:39,019 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-24 23:33:11,622 - __main__ - INFO - API批次 [241-250] 完成
2025-12-24 23:33:11,622 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-24 23:33:11,623 - __main__ - INFO - 开始数据质量检查...
2025-12-24 23:33:11,623 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-24 23:33:11,623 - __main__ - INFO - ============================================================
2025-12-24 23:33:11,623 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-24 23:33:11,624 - __main__ - INFO - ============================================================
2025-12-24 23:33:11,624 - __main__ - INFO - 预检查数据完整性...
2025-12-24 23:33:11,625 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-24 23:33:11,625 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-24 23:33:11,625 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-24 23:33:11,648 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-24 23:33:11,667 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-24 23:33:11,687 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-24 23:33:11,707 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-24 23:33:11,727 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-24 23:33:11,746 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-24 23:33:11,746 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-24 23:33:12,926 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-24 23:33:12,956 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-24 23:33:14,047 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,047 - __main__ - INFO - 数据集名称: bbh
2025-12-24 23:33:14,047 - __main__ - INFO - 数据集路径: dataset/bbh/logical_deduction_five_objects.json
2025-12-24 23:33:14,047 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,047 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-24 23:33:14,047 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,047 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-24 23:33:14,047 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/logical_deduction_five_objects.json
2025-12-24 23:33:14,047 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,047 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-24 23:33:14,048 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-24 23:33:14,048 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-24 23:33:14,048 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-24 23:33:14,048 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,048 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-24 23:33:14,048 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,048 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-24 23:33:14,048 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,048 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-24 23:33:14,051 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-24 23:33:14,051 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,051 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-24 23:33:14,051 - __main__ - INFO - ============================================================
2025-12-24 23:33:14,051 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-24 23:33:14,051 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 23:33:14,051 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 23:33:18,693 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-24 23:33:18,694 - inference.local_inference - INFO - ============================================================
2025-12-24 23:33:18,694 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-24 23:33:18,694 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-24 23:33:18,694 - inference.local_inference - INFO - ============================================================
2025-12-24 23:34:18,009 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-24 23:34:35,659 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 23:34:35,660 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 23:37:47,025 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 23:37:47,025 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 23:44:21,771 - __main__ - INFO - 批次 [2305-2432] 本地推理完成
2025-12-24 23:44:21,772 - __main__ - INFO - 处理批次 [2433-2560/99842]
2025-12-24 23:44:21,772 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-24 23:44:21,772 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-24 23:44:22,595 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 23:44:22,596 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-24 23:44:35,871 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-24 23:44:35,872 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-24 23:50:36,886 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-24 23:50:36,887 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-24 23:50:36,887 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-24 23:50:36,887 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-24 23:50:52,878 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-24 23:50:52,878 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-24 23:54:32,476 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-24 23:54:32,476 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 00:00:23,554 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 00:00:23,554 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 00:01:03,325 - __main__ - INFO - 批次 [2433-2560] 本地推理完成
2025-12-25 00:01:03,325 - __main__ - INFO - 处理批次 [2561-2688/99842]
2025-12-25 00:01:03,325 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 00:01:03,325 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 00:01:19,498 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 00:01:19,498 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 00:06:23,848 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 00:06:23,849 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 00:06:23,849 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 00:06:23,936 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 00:06:23,937 - __main__ - INFO - ============================================================
2025-12-25 00:06:23,937 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 00:06:23,937 - __main__ - INFO - ============================================================
2025-12-25 00:06:23,937 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 00:06:23,937 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 00:06:23,937 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:06:57,017 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 00:06:57,019 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 00:06:57,019 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:07:24,613 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 00:07:24,613 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 00:07:24,613 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:07:53,803 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 00:07:53,804 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 00:07:53,804 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:08:37,210 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 00:08:37,211 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 00:08:37,211 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:09:48,735 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 00:09:48,735 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 00:09:48,736 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:10:34,062 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 00:10:34,063 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 00:10:34,063 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:10:59,735 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 00:10:59,736 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 00:11:12,886 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 00:11:12,887 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 00:11:12,887 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:12:25,766 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 00:12:25,767 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 00:12:25,767 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:12:48,842 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 00:12:48,842 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 00:12:48,842 - __main__ - INFO - 开始数据质量检查...
2025-12-25 00:12:48,843 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 00:12:48,843 - __main__ - INFO - ============================================================
2025-12-25 00:12:48,843 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 00:12:48,843 - __main__ - INFO - ============================================================
2025-12-25 00:12:48,843 - __main__ - INFO - 预检查数据完整性...
2025-12-25 00:12:48,844 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 00:12:48,844 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 00:12:48,844 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 00:12:48,868 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 00:12:48,887 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 00:12:48,906 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 00:12:48,926 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 00:12:48,945 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 00:12:48,963 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 00:12:48,963 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 00:12:50,139 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 00:12:50,169 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 00:12:51,201 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,201 - __main__ - INFO - 数据集名称: bbh
2025-12-25 00:12:51,201 - __main__ - INFO - 数据集路径: dataset/bbh/logical_deduction_seven_objects.json
2025-12-25 00:12:51,201 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,201 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 00:12:51,201 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,201 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 00:12:51,201 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/logical_deduction_seven_objects.json
2025-12-25 00:12:51,201 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,202 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 00:12:51,202 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 00:12:51,202 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 00:12:51,202 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 00:12:51,202 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,202 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 00:12:51,202 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,202 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 00:12:51,202 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,202 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 00:12:51,205 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 00:12:51,205 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,205 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 00:12:51,205 - __main__ - INFO - ============================================================
2025-12-25 00:12:51,205 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 00:12:51,205 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 00:12:51,205 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 00:12:55,544 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 00:12:55,544 - inference.local_inference - INFO - ============================================================
2025-12-25 00:12:55,544 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 00:12:55,544 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 00:12:55,544 - inference.local_inference - INFO - ============================================================
2025-12-25 00:13:54,020 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 00:14:18,817 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 00:14:18,818 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 00:17:22,484 - __main__ - INFO - 批次 [2561-2688] 本地推理完成
2025-12-25 00:17:22,485 - __main__ - INFO - 处理批次 [2689-2816/99842]
2025-12-25 00:17:22,485 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 00:17:22,485 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 00:17:33,661 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 00:17:33,661 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 00:24:36,100 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 00:24:36,101 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 00:27:09,496 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 00:27:09,496 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 00:30:48,862 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 00:30:48,863 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 00:30:48,863 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 00:30:48,863 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 00:31:11,537 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 00:31:11,537 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 00:33:45,409 - __main__ - INFO - 批次 [2689-2816] 本地推理完成
2025-12-25 00:33:45,409 - __main__ - INFO - 处理批次 [2817-2944/99842]
2025-12-25 00:33:45,410 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 00:33:45,410 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 00:33:55,211 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 00:33:55,212 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 00:40:28,977 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 00:40:28,977 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 00:43:50,451 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 00:43:50,452 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 00:46:44,112 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 00:46:44,112 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 00:46:44,112 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 00:46:44,200 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 00:46:44,201 - __main__ - INFO - ============================================================
2025-12-25 00:46:44,201 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 00:46:44,201 - __main__ - INFO - ============================================================
2025-12-25 00:46:44,201 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 00:46:44,201 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 00:46:44,201 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:47:14,872 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 00:47:14,873 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 00:47:14,873 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:47:40,049 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 00:47:40,049 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 00:47:40,050 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:48:08,032 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 00:48:08,033 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 00:48:08,033 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:48:46,352 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 00:48:46,353 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 00:48:46,353 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:49:32,589 - __main__ - INFO - 批次 [2817-2944] 本地推理完成
2025-12-25 00:49:32,589 - __main__ - INFO - 处理批次 [2945-3072/99842]
2025-12-25 00:49:32,590 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 00:49:32,590 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 00:49:42,220 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 00:49:42,221 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 00:49:57,496 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 00:49:57,497 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 00:49:57,497 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:51:34,269 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 00:51:34,270 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 00:51:34,270 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:52:04,336 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 00:52:04,336 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 00:52:04,336 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:52:38,164 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 00:52:38,165 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 00:52:38,165 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 00:52:55,915 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 00:52:55,915 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 00:52:55,915 - __main__ - INFO - 开始数据质量检查...
2025-12-25 00:52:55,915 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 00:52:55,915 - __main__ - INFO - ============================================================
2025-12-25 00:52:55,915 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 00:52:55,916 - __main__ - INFO - ============================================================
2025-12-25 00:52:55,916 - __main__ - INFO - 预检查数据完整性...
2025-12-25 00:52:55,916 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 00:52:55,916 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 00:52:55,916 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 00:52:55,942 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 00:52:55,963 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 00:52:55,983 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 00:52:56,005 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 00:52:56,026 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 00:52:56,044 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 00:52:56,044 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 00:52:57,322 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 00:52:57,361 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 00:52:58,748 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,748 - __main__ - INFO - 数据集名称: bbh
2025-12-25 00:52:58,748 - __main__ - INFO - 数据集路径: dataset/bbh/logical_deduction_three_objects.json
2025-12-25 00:52:58,748 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,748 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 00:52:58,748 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,748 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 00:52:58,748 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/logical_deduction_three_objects.json
2025-12-25 00:52:58,748 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,749 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 00:52:58,749 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 00:52:58,749 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 00:52:58,749 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 00:52:58,749 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,749 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 00:52:58,749 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,749 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 00:52:58,749 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,750 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 00:52:58,752 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 00:52:58,752 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,752 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 00:52:58,752 - __main__ - INFO - ============================================================
2025-12-25 00:52:58,752 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 00:52:58,752 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 00:52:58,752 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 00:53:04,048 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 00:53:04,049 - inference.local_inference - INFO - ============================================================
2025-12-25 00:53:04,049 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 00:53:04,049 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 00:53:04,049 - inference.local_inference - INFO - ============================================================
2025-12-25 00:54:05,105 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 00:54:14,112 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 00:54:14,112 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 00:59:24,781 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 00:59:24,781 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 01:04:13,042 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 01:04:13,043 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 01:05:25,333 - __main__ - INFO - 批次 [2945-3072] 本地推理完成
2025-12-25 01:05:25,334 - __main__ - INFO - 处理批次 [3073-3200/99842]
2025-12-25 01:05:25,334 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 01:05:25,334 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 01:05:36,001 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 01:05:36,001 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 01:09:57,547 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 01:09:57,547 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 01:09:57,548 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 01:09:57,548 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 01:10:06,879 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 01:10:06,879 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 01:15:25,773 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 01:15:25,773 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 01:19:33,021 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 01:19:33,022 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 01:20:51,523 - __main__ - INFO - 批次 [3073-3200] 本地推理完成
2025-12-25 01:20:51,523 - __main__ - INFO - 处理批次 [3201-3328/99842]
2025-12-25 01:20:51,524 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 01:20:51,524 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 01:21:00,703 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 01:21:00,703 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 01:25:31,639 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 01:25:31,639 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 01:25:31,639 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 01:25:31,723 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 01:25:31,723 - __main__ - INFO - ============================================================
2025-12-25 01:25:31,723 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 01:25:31,723 - __main__ - INFO - ============================================================
2025-12-25 01:25:31,723 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 01:25:31,723 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 01:25:31,723 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:26:04,448 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 01:26:04,449 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 01:26:04,449 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:26:36,941 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 01:26:36,941 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 01:26:36,941 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:27:32,733 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 01:27:32,733 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 01:27:32,733 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:28:06,669 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 01:28:06,669 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 01:28:06,669 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:29:20,907 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 01:29:20,908 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 01:29:20,908 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:29:54,310 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 01:29:54,311 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 01:29:54,311 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:30:41,214 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 01:30:41,215 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 01:30:41,215 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:31:06,785 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 01:31:06,785 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 01:31:28,278 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 01:31:28,279 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 01:31:28,279 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 01:32:08,350 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 01:32:08,350 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 01:32:08,350 - __main__ - INFO - 开始数据质量检查...
2025-12-25 01:32:08,350 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 01:32:08,350 - __main__ - INFO - ============================================================
2025-12-25 01:32:08,350 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 01:32:08,351 - __main__ - INFO - ============================================================
2025-12-25 01:32:08,351 - __main__ - INFO - 预检查数据完整性...
2025-12-25 01:32:08,351 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 01:32:08,351 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 01:32:08,351 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 01:32:08,375 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 01:32:08,397 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 01:32:08,417 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 01:32:08,436 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 01:32:08,454 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 01:32:08,473 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 01:32:08,473 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 01:32:09,959 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 01:32:09,988 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 01:32:11,056 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,056 - __main__ - INFO - 数据集名称: bbh
2025-12-25 01:32:11,056 - __main__ - INFO - 数据集路径: dataset/bbh/movie_recommendation.json
2025-12-25 01:32:11,056 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,056 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 01:32:11,056 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,056 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 01:32:11,056 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/movie_recommendation.json
2025-12-25 01:32:11,056 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,056 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 01:32:11,057 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 01:32:11,057 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 01:32:11,057 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 01:32:11,057 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,057 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 01:32:11,057 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,057 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 01:32:11,057 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,057 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 01:32:11,060 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 01:32:11,060 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,060 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 01:32:11,060 - __main__ - INFO - ============================================================
2025-12-25 01:32:11,060 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 01:32:11,060 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 01:32:11,060 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 01:32:15,443 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 01:32:15,444 - inference.local_inference - INFO - ============================================================
2025-12-25 01:32:15,444 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 01:32:15,444 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 01:32:15,444 - inference.local_inference - INFO - ============================================================
2025-12-25 01:33:13,025 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 01:33:28,699 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 01:33:28,700 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 01:36:57,530 - __main__ - INFO - 批次 [3201-3328] 本地推理完成
2025-12-25 01:36:57,531 - __main__ - INFO - 处理批次 [3329-3456/99842]
2025-12-25 01:36:57,531 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 01:36:57,531 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 01:37:07,484 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 01:37:07,484 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 01:43:34,478 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 01:43:34,479 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 01:46:57,102 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 01:46:57,102 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 01:50:19,837 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 01:50:19,837 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 01:50:19,838 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 01:50:19,838 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 01:50:33,642 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 01:50:33,642 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 01:52:51,920 - __main__ - INFO - 批次 [3329-3456] 本地推理完成
2025-12-25 01:52:51,920 - __main__ - INFO - 处理批次 [3457-3584/99842]
2025-12-25 01:52:51,921 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 01:52:51,921 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 01:53:02,213 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 01:53:02,214 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 02:00:13,492 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 02:00:13,492 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 02:03:02,502 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 02:03:02,503 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 02:06:25,226 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 02:06:25,227 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 02:06:25,227 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 02:06:25,318 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 02:06:25,318 - __main__ - INFO - ============================================================
2025-12-25 02:06:25,318 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 02:06:25,318 - __main__ - INFO - ============================================================
2025-12-25 02:06:25,318 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 02:06:25,318 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 02:06:25,318 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:07:04,455 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 02:07:04,456 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 02:07:04,456 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:07:27,982 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 02:07:27,983 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 02:07:27,983 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:08:11,127 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 02:08:11,128 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 02:08:11,128 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:08:39,130 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 02:08:39,131 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 02:08:39,131 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:08:49,815 - __main__ - INFO - 批次 [3457-3584] 本地推理完成
2025-12-25 02:08:49,816 - __main__ - INFO - 处理批次 [3585-3712/99842]
2025-12-25 02:08:49,816 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 02:08:49,816 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 02:08:59,662 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 02:08:59,662 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 02:09:10,200 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 02:09:10,200 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 02:09:10,201 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:09:36,351 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 02:09:36,352 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 02:09:36,352 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:09:58,807 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 02:09:58,808 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 02:09:58,808 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:10:26,703 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 02:10:26,704 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 02:10:26,704 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:11:40,424 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 02:11:40,425 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 02:11:40,425 - __main__ - INFO - 开始数据质量检查...
2025-12-25 02:11:40,425 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 02:11:40,425 - __main__ - INFO - ============================================================
2025-12-25 02:11:40,426 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 02:11:40,426 - __main__ - INFO - ============================================================
2025-12-25 02:11:40,426 - __main__ - INFO - 预检查数据完整性...
2025-12-25 02:11:40,427 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 02:11:40,427 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 02:11:40,427 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 02:11:40,452 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 02:11:40,473 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 02:11:40,493 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 02:11:40,511 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 02:11:40,532 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 02:11:40,550 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 02:11:40,550 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 02:11:41,528 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 02:11:41,557 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 02:11:42,722 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,722 - __main__ - INFO - 数据集名称: bbh
2025-12-25 02:11:42,722 - __main__ - INFO - 数据集路径: dataset/bbh/multistep_arithmetic_two.json
2025-12-25 02:11:42,723 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,723 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 02:11:42,723 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,723 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 02:11:42,723 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/multistep_arithmetic_two.json
2025-12-25 02:11:42,723 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,723 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 02:11:42,723 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 02:11:42,723 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 02:11:42,723 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 02:11:42,723 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,723 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 02:11:42,723 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,723 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 02:11:42,723 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,724 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 02:11:42,726 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 02:11:42,726 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,726 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 02:11:42,726 - __main__ - INFO - ============================================================
2025-12-25 02:11:42,726 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 02:11:42,726 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 02:11:42,726 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 02:11:47,101 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 02:11:47,102 - inference.local_inference - INFO - ============================================================
2025-12-25 02:11:47,102 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 02:11:47,102 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 02:11:47,102 - inference.local_inference - INFO - ============================================================
2025-12-25 02:12:46,004 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 02:12:59,725 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 02:12:59,726 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 02:18:39,222 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 02:18:39,222 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 02:21:30,661 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 02:21:30,662 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 02:24:26,300 - __main__ - INFO - 批次 [3585-3712] 本地推理完成
2025-12-25 02:24:26,301 - __main__ - INFO - 处理批次 [3713-3840/99842]
2025-12-25 02:24:26,301 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 02:24:26,301 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 02:24:35,447 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 02:24:35,447 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 02:28:24,762 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 02:28:24,763 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 02:28:24,763 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 02:28:24,763 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 02:28:37,341 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 02:28:37,342 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 02:34:29,122 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 02:34:29,123 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 02:36:53,781 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 02:36:53,782 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 02:40:18,751 - __main__ - INFO - 批次 [3713-3840] 本地推理完成
2025-12-25 02:40:18,751 - __main__ - INFO - 处理批次 [3841-3968/99842]
2025-12-25 02:40:18,752 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 02:40:18,752 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 02:40:28,466 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 02:40:28,466 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 02:43:30,246 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 02:43:30,247 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 02:43:30,247 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 02:43:30,333 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 02:43:30,333 - __main__ - INFO - ============================================================
2025-12-25 02:43:30,333 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 02:43:30,333 - __main__ - INFO - ============================================================
2025-12-25 02:43:30,333 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 02:43:30,333 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 02:43:30,333 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:44:20,595 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 02:44:20,595 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 02:44:20,595 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:45:18,763 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 02:45:18,763 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 02:45:18,763 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:45:59,157 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 02:45:59,158 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 02:45:59,158 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:46:42,556 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 02:46:42,556 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 02:46:42,556 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:47:24,737 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 02:47:24,737 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 02:47:24,737 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:47:57,687 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 02:47:57,687 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 02:47:57,687 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:48:32,718 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 02:48:32,718 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 02:48:32,718 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:49:13,468 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 02:49:13,468 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 02:49:13,468 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 02:49:36,138 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 02:49:36,138 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 02:49:36,138 - __main__ - INFO - 开始数据质量检查...
2025-12-25 02:49:36,138 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 02:49:36,138 - __main__ - INFO - ============================================================
2025-12-25 02:49:36,138 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 02:49:36,139 - __main__ - INFO - ============================================================
2025-12-25 02:49:36,139 - __main__ - INFO - 预检查数据完整性...
2025-12-25 02:49:36,139 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 02:49:36,139 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 02:49:36,140 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 02:49:36,163 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 02:49:36,181 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 02:49:36,200 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 02:49:36,216 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 02:49:36,234 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 02:49:36,252 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 02:49:36,252 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 02:49:37,431 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 02:49:37,459 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 02:49:38,516 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,517 - __main__ - INFO - 数据集名称: bbh
2025-12-25 02:49:38,517 - __main__ - INFO - 数据集路径: dataset/bbh/navigate.json
2025-12-25 02:49:38,517 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,517 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 02:49:38,517 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,517 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 02:49:38,517 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/navigate.json
2025-12-25 02:49:38,517 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,517 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 02:49:38,517 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 02:49:38,517 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 02:49:38,517 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 02:49:38,517 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,518 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 02:49:38,518 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,518 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 02:49:38,518 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,518 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 02:49:38,521 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 02:49:38,521 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,521 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 02:49:38,521 - __main__ - INFO - ============================================================
2025-12-25 02:49:38,521 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 02:49:38,521 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 02:49:38,521 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 02:49:42,938 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 02:49:42,939 - inference.local_inference - INFO - ============================================================
2025-12-25 02:49:42,939 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 02:49:42,939 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 02:49:42,939 - inference.local_inference - INFO - ============================================================
2025-12-25 02:50:23,530 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 02:50:23,530 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 02:50:41,560 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 02:50:52,082 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 02:50:52,082 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 02:55:43,006 - __main__ - INFO - 批次 [3841-3968] 本地推理完成
2025-12-25 02:55:43,006 - __main__ - INFO - 处理批次 [3969-4096/99842]
2025-12-25 02:55:43,007 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 02:55:43,007 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 02:55:51,505 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 02:55:51,506 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 02:59:53,002 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 02:59:53,003 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 03:05:50,052 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 03:05:50,052 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 03:06:32,696 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 03:06:32,696 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 03:06:32,697 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 03:06:32,697 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 03:06:43,304 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 03:06:43,305 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 03:11:38,484 - __main__ - INFO - 批次 [3969-4096] 本地推理完成
2025-12-25 03:11:38,484 - __main__ - INFO - 处理批次 [4097-4224/99842]
2025-12-25 03:11:38,485 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 03:11:38,485 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 03:11:47,486 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 03:11:47,486 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 03:14:57,406 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 03:14:57,406 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 03:21:19,643 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 03:21:19,644 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 03:21:19,644 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 03:21:19,725 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 03:21:19,725 - __main__ - INFO - ============================================================
2025-12-25 03:21:19,725 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 03:21:19,725 - __main__ - INFO - ============================================================
2025-12-25 03:21:19,725 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 03:21:19,725 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 03:21:19,725 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:21:47,135 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 03:21:47,135 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 03:21:55,915 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 03:21:55,916 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 03:21:55,916 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:22:31,167 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 03:22:31,168 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 03:22:31,168 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:23:25,006 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 03:23:25,007 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 03:23:25,008 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:24:06,830 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 03:24:06,831 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 03:24:06,831 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:24:36,329 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 03:24:36,330 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 03:24:36,330 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:25:24,210 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 03:25:24,211 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 03:25:24,211 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:26:24,544 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 03:26:24,545 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 03:26:24,545 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:27:14,736 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 03:27:14,737 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 03:27:14,737 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:27:30,416 - __main__ - INFO - 批次 [4097-4224] 本地推理完成
2025-12-25 03:27:30,416 - __main__ - INFO - 处理批次 [4225-4352/99842]
2025-12-25 03:27:30,416 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 03:27:30,416 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 03:27:40,766 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 03:27:40,767 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 03:27:42,750 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 03:27:42,750 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 03:27:42,750 - __main__ - INFO - 开始数据质量检查...
2025-12-25 03:27:42,750 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 03:27:42,750 - __main__ - INFO - ============================================================
2025-12-25 03:27:42,750 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 03:27:42,750 - __main__ - INFO - ============================================================
2025-12-25 03:27:42,750 - __main__ - INFO - 预检查数据完整性...
2025-12-25 03:27:42,751 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 03:27:42,751 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 03:27:42,751 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 03:27:42,777 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 03:27:42,802 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 03:27:42,826 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 03:27:42,849 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 03:27:42,873 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 03:27:42,892 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 03:27:42,892 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 03:27:44,179 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 03:27:44,210 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 03:27:45,275 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,275 - __main__ - INFO - 数据集名称: bbh
2025-12-25 03:27:45,275 - __main__ - INFO - 数据集路径: dataset/bbh/object_counting.json
2025-12-25 03:27:45,275 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,275 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 03:27:45,275 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,275 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 03:27:45,275 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/object_counting.json
2025-12-25 03:27:45,275 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,276 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 03:27:45,276 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 03:27:45,276 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 03:27:45,276 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 03:27:45,276 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,276 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 03:27:45,276 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,276 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 03:27:45,276 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,277 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 03:27:45,279 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 03:27:45,279 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,279 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 03:27:45,279 - __main__ - INFO - ============================================================
2025-12-25 03:27:45,279 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 03:27:45,279 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 03:27:45,279 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 03:27:49,678 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 03:27:49,678 - inference.local_inference - INFO - ============================================================
2025-12-25 03:27:49,678 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 03:27:49,678 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 03:27:49,678 - inference.local_inference - INFO - ============================================================
2025-12-25 03:28:48,026 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 03:28:54,783 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 03:28:54,784 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 03:36:44,134 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 03:36:44,134 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 03:37:35,815 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 03:37:35,815 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 03:43:29,917 - __main__ - INFO - 批次 [4225-4352] 本地推理完成
2025-12-25 03:43:29,918 - __main__ - INFO - 处理批次 [4353-4480/99842]
2025-12-25 03:43:29,918 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 03:43:29,918 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 03:43:40,364 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 03:43:40,365 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 03:43:57,833 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 03:43:57,833 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 03:43:57,833 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 03:43:57,833 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 03:44:04,550 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 03:44:04,551 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 03:51:47,109 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 03:51:47,109 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 03:53:10,728 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 03:53:10,728 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 03:58:27,743 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 03:58:27,743 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 03:58:27,743 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 03:58:27,815 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 03:58:27,815 - __main__ - INFO - ============================================================
2025-12-25 03:58:27,815 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 03:58:27,815 - __main__ - INFO - ============================================================
2025-12-25 03:58:27,815 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 03:58:27,815 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 03:58:27,815 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:59:08,325 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 03:59:08,326 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 03:59:08,326 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:59:39,139 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 03:59:39,139 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 03:59:39,139 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 03:59:47,587 - __main__ - INFO - 批次 [4353-4480] 本地推理完成
2025-12-25 03:59:47,587 - __main__ - INFO - 处理批次 [4481-4608/99842]
2025-12-25 03:59:47,587 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 03:59:47,587 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 03:59:58,975 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 03:59:58,975 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 04:00:00,689 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 04:00:00,690 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 04:00:00,690 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:00:21,876 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 04:00:21,876 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 04:00:21,876 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:00:57,968 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 04:00:57,969 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 04:00:57,969 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:01:22,255 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 04:01:22,255 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 04:01:22,256 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:01:46,846 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 04:01:46,847 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 04:01:46,847 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:02:18,440 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 04:02:18,441 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 04:02:18,441 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:02:33,836 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 04:02:33,837 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 04:02:33,837 - __main__ - INFO - 开始数据质量检查...
2025-12-25 04:02:33,837 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 04:02:33,837 - __main__ - INFO - ============================================================
2025-12-25 04:02:33,837 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 04:02:33,837 - __main__ - INFO - ============================================================
2025-12-25 04:02:33,837 - __main__ - INFO - 预检查数据完整性...
2025-12-25 04:02:33,838 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 04:02:33,838 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 04:02:33,838 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 04:02:33,860 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 04:02:33,878 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 04:02:33,894 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 04:02:33,914 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 04:02:33,929 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 04:02:33,946 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 04:02:33,946 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 04:02:35,224 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 04:02:35,255 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 04:02:36,297 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,297 - __main__ - INFO - 数据集名称: bbh
2025-12-25 04:02:36,297 - __main__ - INFO - 数据集路径: dataset/bbh/penguins_in_a_table.json
2025-12-25 04:02:36,297 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,297 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 04:02:36,297 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,297 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 04:02:36,297 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/penguins_in_a_table.json
2025-12-25 04:02:36,297 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,297 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 04:02:36,298 - __main__ - INFO - 预处理 BBH 数据集: 146 条
2025-12-25 04:02:36,298 - __main__ - INFO - [数据集适配层] 预处理完成: 146 条有效数据
2025-12-25 04:02:36,298 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 04:02:36,298 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,298 - __main__ - INFO - 数据集加载成功，共 146 条数据
2025-12-25 04:02:36,298 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,298 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 04:02:36,298 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,298 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 04:02:36,301 - __main__ - INFO - 共需处理 146 条数据，批次大小: 64
2025-12-25 04:02:36,301 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,301 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 04:02:36,301 - __main__ - INFO - ============================================================
2025-12-25 04:02:36,301 - __main__ - INFO - 处理批次 [1-128/146]
2025-12-25 04:02:36,301 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 04:02:36,301 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 04:02:40,656 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 04:02:40,657 - inference.local_inference - INFO - ============================================================
2025-12-25 04:02:40,657 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 04:02:40,657 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 04:02:40,657 - inference.local_inference - INFO - ============================================================
2025-12-25 04:03:39,241 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 04:05:36,947 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 04:05:36,948 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 04:09:18,365 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 04:09:18,365 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 04:15:29,414 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 04:15:29,414 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 04:15:52,110 - __main__ - INFO - 批次 [4481-4608] 本地推理完成
2025-12-25 04:15:52,110 - __main__ - INFO - 处理批次 [4609-4736/99842]
2025-12-25 04:15:52,110 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 04:15:52,110 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 04:16:00,794 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 04:16:00,794 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 04:21:40,098 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 04:21:40,099 - __main__ - INFO - 处理批次 [129-146/146]
2025-12-25 04:21:40,099 - __main__ - INFO -   → 生成Baseline答案 (18 条)...
2025-12-25 04:21:40,099 - __main__ - INFO - 批量生成Baseline答案: 18 条
2025-12-25 04:21:46,183 - __main__ - INFO -   → 生成差异分析 (18 条)...
2025-12-25 04:21:46,183 - __main__ - INFO - 批量生成差异分析: 18 条
2025-12-25 04:24:31,902 - __main__ - INFO -   → 生成Rejected原则 (18 条)...
2025-12-25 04:24:31,903 - __main__ - INFO - 批量生成原则（弱模型）: 18 条
2025-12-25 04:25:15,315 - __main__ - INFO - 批次 [129-146] 本地推理完成
2025-12-25 04:25:15,315 - __main__ - INFO - 阶段1完成: 共生成 146 条本地推理结果
2025-12-25 04:25:15,315 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 04:25:15,363 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 04:25:15,363 - __main__ - INFO - ============================================================
2025-12-25 04:25:15,363 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 04:25:15,363 - __main__ - INFO - ============================================================
2025-12-25 04:25:15,363 - __main__ - INFO - API分批处理: 每批 30 条，共 5 批
2025-12-25 04:25:15,363 - __main__ - INFO - API批次 [1-30/146] 开始处理...
2025-12-25 04:25:15,363 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:25:33,096 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 04:25:33,097 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 04:25:53,872 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 04:25:53,873 - __main__ - INFO - API批次 [31-60/146] 开始处理...
2025-12-25 04:25:53,873 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:26:18,364 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 04:26:18,364 - __main__ - INFO - API批次 [61-90/146] 开始处理...
2025-12-25 04:26:18,364 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:26:52,351 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 04:26:52,351 - __main__ - INFO - API批次 [91-120/146] 开始处理...
2025-12-25 04:26:52,351 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:27:44,663 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 04:27:44,664 - __main__ - INFO - API批次 [121-146/146] 开始处理...
2025-12-25 04:27:44,664 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 04:28:13,621 - __main__ - INFO - API批次 [121-146] 完成
2025-12-25 04:28:13,622 - __main__ - INFO - 阶段2完成: 共生成 146 条Chosen结果
2025-12-25 04:28:13,622 - __main__ - INFO - 开始数据质量检查...
2025-12-25 04:28:13,622 - __main__ - INFO - ✅ 数据质量检查通过: 146 条chosen全部非空
2025-12-25 04:28:13,622 - __main__ - INFO - ============================================================
2025-12-25 04:28:13,622 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 04:28:13,622 - __main__ - INFO - ============================================================
2025-12-25 04:28:13,622 - __main__ - INFO - 预检查数据完整性...
2025-12-25 04:28:13,623 - __main__ - INFO - Chosen非空率: 146/146 (100.0%)
2025-12-25 04:28:13,623 - __main__ - INFO - Rejected非空率: 146/146 (100.0%)
2025-12-25 04:28:13,623 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 04:28:13,645 - __main__ - INFO - 已保存 50/146 条到JSONL
2025-12-25 04:28:13,663 - __main__ - INFO - 已保存 100/146 条到JSONL
2025-12-25 04:28:13,688 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 04:28:13,689 - __main__ - INFO - 共保存 146 条数据到JSONL格式
2025-12-25 04:28:14,862 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 04:28:14,890 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 04:28:15,900 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,900 - __main__ - INFO - 数据集名称: bbh
2025-12-25 04:28:15,900 - __main__ - INFO - 数据集路径: dataset/bbh/reasoning_about_colored_objects.json
2025-12-25 04:28:15,900 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,901 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 04:28:15,901 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,901 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 04:28:15,901 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/reasoning_about_colored_objects.json
2025-12-25 04:28:15,901 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,901 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 04:28:15,901 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 04:28:15,901 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 04:28:15,901 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 04:28:15,901 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,902 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 04:28:15,902 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,902 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 04:28:15,902 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,902 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 04:28:15,904 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 04:28:15,904 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,904 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 04:28:15,904 - __main__ - INFO - ============================================================
2025-12-25 04:28:15,904 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 04:28:15,904 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 04:28:15,904 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 04:28:20,383 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 04:28:20,384 - inference.local_inference - INFO - ============================================================
2025-12-25 04:28:20,384 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 04:28:20,384 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 04:28:20,384 - inference.local_inference - INFO - ============================================================
2025-12-25 04:29:17,978 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 04:29:32,512 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 04:29:32,513 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 04:32:08,772 - __main__ - INFO - 批次 [4609-4736] 本地推理完成
2025-12-25 04:32:08,772 - __main__ - INFO - 处理批次 [4737-4864/99842]
2025-12-25 04:32:08,772 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 04:32:08,772 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 04:34:08,353 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 04:34:08,353 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 04:39:05,182 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 04:39:05,183 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 04:43:41,968 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 04:43:41,968 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 04:45:20,402 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 04:45:20,403 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 04:45:20,403 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 04:45:20,403 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 04:45:33,415 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 04:45:33,415 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 04:50:11,845 - __main__ - INFO - 批次 [4737-4864] 本地推理完成
2025-12-25 04:50:11,845 - __main__ - INFO - 处理批次 [4865-4992/99842]
2025-12-25 04:50:11,845 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 04:50:11,846 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 04:50:24,796 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 04:50:24,796 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 04:54:52,818 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 04:54:52,819 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 05:00:13,571 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 05:00:13,572 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 05:01:02,220 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 05:01:02,220 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 05:01:02,220 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 05:01:02,305 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 05:01:02,305 - __main__ - INFO - ============================================================
2025-12-25 05:01:02,305 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 05:01:02,305 - __main__ - INFO - ============================================================
2025-12-25 05:01:02,305 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 05:01:02,305 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 05:01:02,305 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:01:30,235 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 05:01:30,236 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 05:01:30,236 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:01:59,200 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 05:01:59,201 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 05:01:59,201 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:02:29,165 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 05:02:29,166 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 05:02:29,166 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:02:53,773 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 05:02:53,774 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 05:02:53,774 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:03:48,147 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 05:03:48,148 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 05:03:48,148 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:04:36,142 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 05:04:36,143 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 05:04:36,143 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:05:14,148 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 05:05:14,148 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 05:05:14,148 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:06:03,918 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 05:06:03,919 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 05:06:03,919 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:06:31,550 - __main__ - INFO - 批次 [4865-4992] 本地推理完成
2025-12-25 05:06:31,550 - __main__ - INFO - 处理批次 [4993-5120/99842]
2025-12-25 05:06:31,551 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 05:06:31,551 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 05:06:35,745 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 05:06:35,746 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 05:06:35,746 - __main__ - INFO - 开始数据质量检查...
2025-12-25 05:06:35,746 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 05:06:35,746 - __main__ - INFO - ============================================================
2025-12-25 05:06:35,747 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 05:06:35,747 - __main__ - INFO - ============================================================
2025-12-25 05:06:35,747 - __main__ - INFO - 预检查数据完整性...
2025-12-25 05:06:35,748 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 05:06:35,748 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 05:06:35,748 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 05:06:35,772 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 05:06:35,790 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 05:06:35,809 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 05:06:35,829 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 05:06:35,848 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 05:06:35,867 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 05:06:35,867 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 05:06:37,045 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 05:06:37,074 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 05:06:38,110 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,110 - __main__ - INFO - 数据集名称: bbh
2025-12-25 05:06:38,110 - __main__ - INFO - 数据集路径: dataset/bbh/ruin_names.json
2025-12-25 05:06:38,110 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,110 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 05:06:38,110 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,111 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 05:06:38,111 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/ruin_names.json
2025-12-25 05:06:38,111 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,111 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 05:06:38,111 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 05:06:38,111 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 05:06:38,111 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 05:06:38,111 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,111 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 05:06:38,111 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,111 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 05:06:38,111 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,112 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 05:06:38,114 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 05:06:38,114 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,114 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 05:06:38,114 - __main__ - INFO - ============================================================
2025-12-25 05:06:38,114 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 05:06:38,114 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 05:06:38,114 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 05:06:42,490 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 05:06:42,490 - inference.local_inference - INFO - ============================================================
2025-12-25 05:06:42,490 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 05:06:42,490 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 05:06:42,490 - inference.local_inference - INFO - ============================================================
2025-12-25 05:07:40,149 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 05:07:49,797 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 05:07:49,798 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 05:08:33,587 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 05:08:33,588 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 05:17:43,253 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 05:17:43,254 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 05:18:36,396 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 05:18:36,396 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 05:24:02,923 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 05:24:02,924 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 05:24:02,924 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 05:24:02,924 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 05:24:12,878 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 05:24:12,878 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 05:24:22,472 - __main__ - INFO - 批次 [4993-5120] 本地推理完成
2025-12-25 05:24:22,472 - __main__ - INFO - 处理批次 [5121-5248/99842]
2025-12-25 05:24:22,473 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 05:24:22,473 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 05:26:24,502 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 05:26:24,503 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 05:33:53,582 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 05:33:53,582 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 05:36:32,646 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 05:36:32,646 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 05:39:40,190 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 05:39:40,190 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 05:39:40,190 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 05:39:40,276 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 05:39:40,276 - __main__ - INFO - ============================================================
2025-12-25 05:39:40,276 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 05:39:40,276 - __main__ - INFO - ============================================================
2025-12-25 05:39:40,276 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 05:39:40,276 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 05:39:40,276 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:40:20,297 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 05:40:20,298 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 05:40:20,298 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:40:52,794 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 05:40:52,794 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 05:40:52,794 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:41:53,545 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 05:41:53,545 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 05:41:53,545 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:42:19,335 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 05:42:19,337 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 05:42:19,337 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:42:22,599 - __main__ - INFO - 批次 [5121-5248] 本地推理完成
2025-12-25 05:42:22,599 - __main__ - INFO - 处理批次 [5249-5376/99842]
2025-12-25 05:42:22,600 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 05:42:22,600 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 05:42:39,396 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 05:42:39,396 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 05:43:15,849 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 05:43:15,850 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 05:43:15,850 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:43:41,307 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 05:43:41,308 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 05:43:41,308 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:44:21,607 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 05:44:21,607 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 05:44:21,608 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:44:53,266 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 05:44:53,267 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 05:44:53,267 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 05:45:21,457 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 05:45:21,457 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 05:45:21,458 - __main__ - INFO - 开始数据质量检查...
2025-12-25 05:45:21,458 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 05:45:21,458 - __main__ - INFO - ============================================================
2025-12-25 05:45:21,458 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 05:45:21,458 - __main__ - INFO - ============================================================
2025-12-25 05:45:21,458 - __main__ - INFO - 预检查数据完整性...
2025-12-25 05:45:21,459 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 05:45:21,459 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 05:45:21,459 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 05:45:21,483 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 05:45:21,502 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 05:45:21,523 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 05:45:21,541 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 05:45:21,558 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 05:45:21,575 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 05:45:21,575 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 05:45:22,954 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 05:45:22,984 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 05:45:24,075 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,075 - __main__ - INFO - 数据集名称: bbh
2025-12-25 05:45:24,075 - __main__ - INFO - 数据集路径: dataset/bbh/salient_translation_error_detection.json
2025-12-25 05:45:24,075 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,075 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 05:45:24,075 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,075 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 05:45:24,075 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/salient_translation_error_detection.json
2025-12-25 05:45:24,075 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,076 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 05:45:24,076 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 05:45:24,076 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 05:45:24,076 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 05:45:24,076 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,076 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 05:45:24,076 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,076 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 05:45:24,076 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,077 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 05:45:24,079 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 05:45:24,079 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,079 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 05:45:24,079 - __main__ - INFO - ============================================================
2025-12-25 05:45:24,079 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 05:45:24,079 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 05:45:24,080 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 05:45:28,368 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 05:45:28,368 - inference.local_inference - INFO - ============================================================
2025-12-25 05:45:28,368 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 05:45:28,368 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 05:45:28,368 - inference.local_inference - INFO - ============================================================
2025-12-25 05:46:27,285 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 05:46:39,682 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 05:46:39,683 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 05:52:49,068 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 05:52:49,069 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 05:56:40,088 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 05:56:40,088 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 05:58:20,085 - __main__ - INFO - 批次 [5249-5376] 本地推理完成
2025-12-25 05:58:20,085 - __main__ - INFO - 处理批次 [5377-5504/99842]
2025-12-25 05:58:20,086 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 05:58:20,086 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 05:58:34,660 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 05:58:34,660 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 06:02:23,108 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 06:02:23,108 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 06:02:23,108 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 06:02:23,108 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 06:02:36,349 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 06:02:36,350 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 06:08:34,985 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 06:08:34,985 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 06:12:10,242 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 06:12:10,243 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 06:14:33,236 - __main__ - INFO - 批次 [5377-5504] 本地推理完成
2025-12-25 06:14:33,236 - __main__ - INFO - 处理批次 [5505-5632/99842]
2025-12-25 06:14:33,237 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 06:14:33,237 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 06:14:47,258 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 06:14:47,259 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 06:18:02,536 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 06:18:02,537 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 06:18:02,537 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 06:18:02,619 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 06:18:02,619 - __main__ - INFO - ============================================================
2025-12-25 06:18:02,619 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 06:18:02,619 - __main__ - INFO - ============================================================
2025-12-25 06:18:02,619 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 06:18:02,619 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 06:18:02,620 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:18:33,974 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 06:18:33,975 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 06:18:33,975 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:19:01,708 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 06:19:01,709 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 06:19:01,709 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:19:28,399 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 06:19:28,400 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 06:19:28,400 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:19:54,141 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 06:19:54,141 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 06:19:54,141 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:20:25,853 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 06:20:25,854 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 06:20:25,854 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:20:57,471 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 06:20:57,472 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 06:20:57,472 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:21:27,238 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 06:21:27,238 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 06:21:27,238 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:22:01,502 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 06:22:01,502 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 06:22:01,503 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:22:25,669 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 06:22:25,669 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 06:22:25,669 - __main__ - INFO - 开始数据质量检查...
2025-12-25 06:22:25,669 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 06:22:25,669 - __main__ - INFO - ============================================================
2025-12-25 06:22:25,669 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 06:22:25,669 - __main__ - INFO - ============================================================
2025-12-25 06:22:25,669 - __main__ - INFO - 预检查数据完整性...
2025-12-25 06:22:25,669 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 06:22:25,669 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 06:22:25,669 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 06:22:25,689 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 06:22:25,708 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 06:22:25,729 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 06:22:25,747 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 06:22:25,768 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 06:22:25,786 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 06:22:25,786 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 06:22:27,265 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 06:22:27,295 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 06:22:28,331 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,331 - __main__ - INFO - 数据集名称: bbh
2025-12-25 06:22:28,331 - __main__ - INFO - 数据集路径: dataset/bbh/snarks.json
2025-12-25 06:22:28,331 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,331 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 06:22:28,332 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,332 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 06:22:28,332 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/snarks.json
2025-12-25 06:22:28,332 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,332 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 06:22:28,332 - __main__ - INFO - 预处理 BBH 数据集: 178 条
2025-12-25 06:22:28,332 - __main__ - INFO - [数据集适配层] 预处理完成: 178 条有效数据
2025-12-25 06:22:28,332 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 06:22:28,332 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,332 - __main__ - INFO - 数据集加载成功，共 178 条数据
2025-12-25 06:22:28,332 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,332 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 06:22:28,332 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,333 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 06:22:28,335 - __main__ - INFO - 共需处理 178 条数据，批次大小: 64
2025-12-25 06:22:28,335 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,335 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 06:22:28,335 - __main__ - INFO - ============================================================
2025-12-25 06:22:28,335 - __main__ - INFO - 处理批次 [1-128/178]
2025-12-25 06:22:28,335 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 06:22:28,335 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 06:22:32,598 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 06:22:32,599 - inference.local_inference - INFO - ============================================================
2025-12-25 06:22:32,599 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 06:22:32,599 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 06:22:32,599 - inference.local_inference - INFO - ============================================================
2025-12-25 06:23:31,290 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 06:23:40,457 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 06:23:40,458 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 06:24:46,322 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 06:24:46,322 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 06:30:24,499 - __main__ - INFO - 批次 [5505-5632] 本地推理完成
2025-12-25 06:30:24,500 - __main__ - INFO - 处理批次 [5633-5760/99842]
2025-12-25 06:30:24,501 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 06:30:24,501 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 06:32:26,385 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 06:32:26,386 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 06:33:23,092 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 06:33:23,092 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 06:39:42,764 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 06:39:42,764 - __main__ - INFO - 处理批次 [129-178/178]
2025-12-25 06:39:42,764 - __main__ - INFO -   → 生成Baseline答案 (50 条)...
2025-12-25 06:39:42,764 - __main__ - INFO - 批量生成Baseline答案: 50 条
2025-12-25 06:39:48,347 - __main__ - INFO -   → 生成差异分析 (50 条)...
2025-12-25 06:39:48,347 - __main__ - INFO - 批量生成差异分析: 50 条
2025-12-25 06:42:42,336 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 06:42:42,337 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 06:43:55,561 - __main__ - INFO -   → 生成Rejected原则 (50 条)...
2025-12-25 06:43:55,562 - __main__ - INFO - 批量生成原则（弱模型）: 50 条
2025-12-25 06:47:16,514 - __main__ - INFO - 批次 [129-178] 本地推理完成
2025-12-25 06:47:16,514 - __main__ - INFO - 阶段1完成: 共生成 178 条本地推理结果
2025-12-25 06:47:16,515 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 06:47:16,578 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 06:47:16,578 - __main__ - INFO - ============================================================
2025-12-25 06:47:16,578 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 06:47:16,578 - __main__ - INFO - ============================================================
2025-12-25 06:47:16,578 - __main__ - INFO - API分批处理: 每批 30 条，共 6 批
2025-12-25 06:47:16,578 - __main__ - INFO - API批次 [1-30/178] 开始处理...
2025-12-25 06:47:16,578 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:47:37,161 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 06:47:37,162 - __main__ - INFO - API批次 [31-60/178] 开始处理...
2025-12-25 06:47:37,163 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:48:05,473 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 06:48:05,474 - __main__ - INFO - API批次 [61-90/178] 开始处理...
2025-12-25 06:48:05,474 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:48:27,896 - __main__ - INFO - 批次 [5633-5760] 本地推理完成
2025-12-25 06:48:27,896 - __main__ - INFO - 处理批次 [5761-5888/99842]
2025-12-25 06:48:27,897 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 06:48:27,897 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 06:48:50,763 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 06:48:50,764 - __main__ - INFO - API批次 [91-120/178] 开始处理...
2025-12-25 06:48:50,764 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:49:27,042 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 06:49:27,043 - __main__ - INFO - API批次 [121-150/178] 开始处理...
2025-12-25 06:49:27,044 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:50:21,448 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 06:50:21,449 - __main__ - INFO - API批次 [151-178/178] 开始处理...
2025-12-25 06:50:21,449 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 06:50:29,964 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 06:50:29,965 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 06:51:22,691 - __main__ - INFO - API批次 [151-178] 完成
2025-12-25 06:51:22,692 - __main__ - INFO - 阶段2完成: 共生成 178 条Chosen结果
2025-12-25 06:51:22,692 - __main__ - INFO - 开始数据质量检查...
2025-12-25 06:51:22,692 - __main__ - INFO - ✅ 数据质量检查通过: 178 条chosen全部非空
2025-12-25 06:51:22,692 - __main__ - INFO - ============================================================
2025-12-25 06:51:22,692 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 06:51:22,692 - __main__ - INFO - ============================================================
2025-12-25 06:51:22,692 - __main__ - INFO - 预检查数据完整性...
2025-12-25 06:51:22,693 - __main__ - INFO - Chosen非空率: 178/178 (100.0%)
2025-12-25 06:51:22,693 - __main__ - INFO - Rejected非空率: 178/178 (100.0%)
2025-12-25 06:51:22,693 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 06:51:22,716 - __main__ - INFO - 已保存 50/178 条到JSONL
2025-12-25 06:51:22,736 - __main__ - INFO - 已保存 100/178 条到JSONL
2025-12-25 06:51:22,756 - __main__ - INFO - 已保存 150/178 条到JSONL
2025-12-25 06:51:22,777 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 06:51:22,777 - __main__ - INFO - 共保存 178 条数据到JSONL格式
2025-12-25 06:51:24,054 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 06:51:24,089 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 06:51:25,150 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,150 - __main__ - INFO - 数据集名称: bbh
2025-12-25 06:51:25,150 - __main__ - INFO - 数据集路径: dataset/bbh/sports_understanding.json
2025-12-25 06:51:25,150 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,150 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 06:51:25,150 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,150 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 06:51:25,150 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/sports_understanding.json
2025-12-25 06:51:25,150 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,150 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 06:51:25,150 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 06:51:25,151 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 06:51:25,151 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 06:51:25,151 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,151 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 06:51:25,151 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,151 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 06:51:25,151 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,151 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 06:51:25,153 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 06:51:25,153 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,153 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 06:51:25,153 - __main__ - INFO - ============================================================
2025-12-25 06:51:25,154 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 06:51:25,154 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 06:51:25,154 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 06:51:29,520 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 06:51:29,520 - inference.local_inference - INFO - ============================================================
2025-12-25 06:51:29,520 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 06:51:29,520 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 06:51:29,520 - inference.local_inference - INFO - ============================================================
2025-12-25 06:52:28,430 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 06:52:40,189 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 06:52:40,190 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 07:01:01,054 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 07:01:01,055 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 07:02:35,367 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 07:02:35,368 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 07:06:45,300 - __main__ - INFO - 批次 [5761-5888] 本地推理完成
2025-12-25 07:06:45,301 - __main__ - INFO - 处理批次 [5889-6016/99842]
2025-12-25 07:06:45,301 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 07:06:45,301 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 07:07:00,594 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 07:07:00,595 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 07:08:53,521 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 07:08:53,522 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 07:08:53,522 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 07:08:53,522 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 07:11:05,162 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 07:11:05,162 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 07:17:22,669 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 07:17:22,669 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 07:20:31,675 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 07:20:31,676 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 07:22:55,542 - __main__ - INFO - 批次 [5889-6016] 本地推理完成
2025-12-25 07:22:55,542 - __main__ - INFO - 处理批次 [6017-6144/99842]
2025-12-25 07:22:55,543 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 07:22:55,543 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 07:23:14,227 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 07:23:14,228 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 07:26:22,791 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 07:26:22,792 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 07:26:22,792 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 07:26:22,878 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 07:26:22,878 - __main__ - INFO - ============================================================
2025-12-25 07:26:22,878 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 07:26:22,878 - __main__ - INFO - ============================================================
2025-12-25 07:26:22,878 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 07:26:22,878 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 07:26:22,878 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:26:53,071 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 07:26:53,072 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 07:26:53,072 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:27:24,017 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 07:27:24,018 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 07:27:24,018 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:28:02,331 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 07:28:02,332 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 07:28:02,332 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:28:38,665 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 07:28:38,665 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 07:28:38,666 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:29:11,320 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 07:29:11,321 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 07:29:11,321 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:29:42,154 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 07:29:42,155 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 07:29:42,155 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:30:19,196 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 07:30:19,197 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 07:30:19,197 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:30:45,751 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 07:30:45,751 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 07:30:45,752 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 07:31:12,570 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 07:31:12,570 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 07:31:12,570 - __main__ - INFO - 开始数据质量检查...
2025-12-25 07:31:12,571 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 07:31:12,571 - __main__ - INFO - ============================================================
2025-12-25 07:31:12,571 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 07:31:12,571 - __main__ - INFO - ============================================================
2025-12-25 07:31:12,571 - __main__ - INFO - 预检查数据完整性...
2025-12-25 07:31:12,572 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 07:31:12,572 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 07:31:12,572 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 07:31:12,596 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 07:31:12,617 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 07:31:12,637 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 07:31:12,653 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 07:31:12,672 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 07:31:12,690 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 07:31:12,690 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 07:31:13,967 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 07:31:13,998 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 07:31:15,040 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,040 - __main__ - INFO - 数据集名称: bbh
2025-12-25 07:31:15,040 - __main__ - INFO - 数据集路径: dataset/bbh/temporal_sequences.json
2025-12-25 07:31:15,040 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,040 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 07:31:15,040 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,040 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 07:31:15,040 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/temporal_sequences.json
2025-12-25 07:31:15,040 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,041 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 07:31:15,041 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 07:31:15,041 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 07:31:15,041 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 07:31:15,041 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,041 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 07:31:15,041 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,041 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 07:31:15,041 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,042 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 07:31:15,044 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 07:31:15,044 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,044 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 07:31:15,044 - __main__ - INFO - ============================================================
2025-12-25 07:31:15,044 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 07:31:15,044 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 07:31:15,044 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 07:31:19,448 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 07:31:19,448 - inference.local_inference - INFO - ============================================================
2025-12-25 07:31:19,448 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 07:31:19,448 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 07:31:19,448 - inference.local_inference - INFO - ============================================================
2025-12-25 07:32:17,862 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 07:32:33,395 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 07:32:33,396 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 07:33:23,452 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 07:33:23,452 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 07:38:58,896 - __main__ - INFO - 批次 [6017-6144] 本地推理完成
2025-12-25 07:38:58,896 - __main__ - INFO - 处理批次 [6145-6272/99842]
2025-12-25 07:38:58,897 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 07:38:58,897 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 07:39:12,373 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 07:39:12,374 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 07:41:42,426 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 07:41:42,427 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 07:48:11,938 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 07:48:11,938 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 07:48:11,938 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 07:48:11,938 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 07:48:25,091 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 07:48:25,091 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 07:49:14,747 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 07:49:14,747 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 07:55:08,144 - __main__ - INFO - 批次 [6145-6272] 本地推理完成
2025-12-25 07:55:08,144 - __main__ - INFO - 处理批次 [6273-6400/99842]
2025-12-25 07:55:08,145 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 07:55:08,145 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 07:56:26,752 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 07:56:26,753 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 07:57:09,804 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 07:57:09,805 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 08:03:02,165 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 08:03:02,166 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 08:03:02,166 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 08:03:02,254 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 08:03:02,254 - __main__ - INFO - ============================================================
2025-12-25 08:03:02,254 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 08:03:02,254 - __main__ - INFO - ============================================================
2025-12-25 08:03:02,254 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 08:03:02,254 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 08:03:02,254 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:03:30,312 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 08:03:30,312 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 08:03:30,312 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:04:05,627 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 08:04:05,628 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 08:04:05,628 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:04:28,699 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 08:04:28,699 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 08:04:28,699 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:04:56,264 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 08:04:56,265 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 08:04:56,265 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:05:40,962 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 08:05:40,963 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 08:05:40,963 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:06:17,302 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 08:06:17,303 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 08:06:17,303 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:06:44,048 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 08:06:44,049 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 08:06:44,049 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:07:12,471 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 08:07:12,472 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 08:07:12,472 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:07:20,896 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 08:07:20,896 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 08:07:30,870 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 08:07:30,871 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 08:07:30,871 - __main__ - INFO - 开始数据质量检查...
2025-12-25 08:07:30,871 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 08:07:30,871 - __main__ - INFO - ============================================================
2025-12-25 08:07:30,871 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 08:07:30,871 - __main__ - INFO - ============================================================
2025-12-25 08:07:30,871 - __main__ - INFO - 预检查数据完整性...
2025-12-25 08:07:30,872 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 08:07:30,872 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 08:07:30,873 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 08:07:30,899 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 08:07:30,920 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 08:07:30,939 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 08:07:30,957 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 08:07:30,975 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 08:07:30,993 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 08:07:30,993 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 08:07:32,170 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 08:07:32,199 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 08:07:33,232 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,232 - __main__ - INFO - 数据集名称: bbh
2025-12-25 08:07:33,232 - __main__ - INFO - 数据集路径: dataset/bbh/tracking_shuffled_objects_five_objects.json
2025-12-25 08:07:33,232 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,232 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 08:07:33,232 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,232 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 08:07:33,232 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/tracking_shuffled_objects_five_objects.json
2025-12-25 08:07:33,232 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,233 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 08:07:33,233 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 08:07:33,233 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 08:07:33,233 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 08:07:33,233 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,233 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 08:07:33,233 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,233 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 08:07:33,233 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,235 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 08:07:33,238 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 08:07:33,238 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,238 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 08:07:33,238 - __main__ - INFO - ============================================================
2025-12-25 08:07:33,238 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 08:07:33,238 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 08:07:33,238 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 08:07:37,583 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 08:07:37,583 - inference.local_inference - INFO - ============================================================
2025-12-25 08:07:37,584 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 08:07:37,584 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 08:07:37,584 - inference.local_inference - INFO - ============================================================
2025-12-25 08:08:35,199 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 08:08:52,192 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 08:08:52,193 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 08:12:58,473 - __main__ - INFO - 批次 [6273-6400] 本地推理完成
2025-12-25 08:12:58,473 - __main__ - INFO - 处理批次 [6401-6528/99842]
2025-12-25 08:12:58,474 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 08:12:58,474 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 08:15:00,052 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 08:15:00,053 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 08:18:58,680 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 08:18:58,681 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 08:25:11,064 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 08:25:11,065 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 08:25:11,065 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 08:25:11,065 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 08:25:12,898 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 08:25:12,898 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 08:25:25,471 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 08:25:25,471 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 08:30:59,033 - __main__ - INFO - 批次 [6401-6528] 本地推理完成
2025-12-25 08:30:59,033 - __main__ - INFO - 处理批次 [6529-6656/99842]
2025-12-25 08:30:59,034 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 08:30:59,034 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 08:31:12,715 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 08:31:12,716 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 08:34:51,658 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 08:34:51,659 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 08:40:55,207 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 08:40:55,208 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 08:40:55,208 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 08:40:55,289 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 08:40:55,289 - __main__ - INFO - ============================================================
2025-12-25 08:40:55,289 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 08:40:55,289 - __main__ - INFO - ============================================================
2025-12-25 08:40:55,289 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 08:40:55,289 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 08:40:55,290 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:41:21,494 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 08:41:21,494 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 08:41:32,257 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 08:41:32,258 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 08:41:32,258 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:42:51,171 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 08:42:51,172 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 08:42:51,173 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:43:45,361 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 08:43:45,362 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 08:43:45,362 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:45:18,700 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 08:45:18,701 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 08:45:18,702 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:46:02,142 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 08:46:02,143 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 08:46:02,143 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:46:47,015 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 08:46:47,016 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 08:46:47,016 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:47:04,121 - __main__ - INFO - 批次 [6529-6656] 本地推理完成
2025-12-25 08:47:04,121 - __main__ - INFO - 处理批次 [6657-6784/99842]
2025-12-25 08:47:04,122 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 08:47:04,122 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 08:47:18,109 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 08:47:18,109 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 08:48:14,746 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 08:48:14,747 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 08:48:14,747 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:48:51,624 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 08:48:51,625 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 08:48:51,625 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 08:50:06,073 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 08:50:06,073 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 08:50:06,073 - __main__ - INFO - 开始数据质量检查...
2025-12-25 08:50:06,073 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 08:50:06,073 - __main__ - INFO - ============================================================
2025-12-25 08:50:06,073 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 08:50:06,073 - __main__ - INFO - ============================================================
2025-12-25 08:50:06,073 - __main__ - INFO - 预检查数据完整性...
2025-12-25 08:50:06,074 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 08:50:06,074 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 08:50:06,074 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 08:50:06,099 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 08:50:06,124 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 08:50:06,150 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 08:50:06,174 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 08:50:06,199 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 08:50:06,219 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 08:50:06,219 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 08:50:07,393 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 08:50:07,431 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 08:50:08,531 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,531 - __main__ - INFO - 数据集名称: bbh
2025-12-25 08:50:08,531 - __main__ - INFO - 数据集路径: dataset/bbh/tracking_shuffled_objects_seven_objects.json
2025-12-25 08:50:08,531 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,531 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 08:50:08,531 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,531 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 08:50:08,531 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/tracking_shuffled_objects_seven_objects.json
2025-12-25 08:50:08,531 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,532 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 08:50:08,532 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 08:50:08,532 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 08:50:08,532 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 08:50:08,532 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,532 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 08:50:08,532 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,532 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 08:50:08,532 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,533 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 08:50:08,535 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 08:50:08,535 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,535 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 08:50:08,535 - __main__ - INFO - ============================================================
2025-12-25 08:50:08,535 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 08:50:08,535 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 08:50:08,535 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 08:50:12,955 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 08:50:12,955 - inference.local_inference - INFO - ============================================================
2025-12-25 08:50:12,955 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 08:50:12,955 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 08:50:12,955 - inference.local_inference - INFO - ============================================================
2025-12-25 08:51:11,597 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 08:51:32,376 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 08:51:32,377 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 08:57:19,880 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 08:57:19,880 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 09:01:26,817 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 09:01:26,818 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 09:03:11,707 - __main__ - INFO - 批次 [6657-6784] 本地推理完成
2025-12-25 09:03:11,708 - __main__ - INFO - 处理批次 [6785-6912/99842]
2025-12-25 09:03:11,708 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 09:03:11,708 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 09:03:28,075 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 09:03:28,076 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 09:07:28,217 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 09:07:28,218 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 09:07:28,218 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 09:07:28,218 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 09:07:47,580 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 09:07:47,581 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 09:13:42,380 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 09:13:42,381 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 09:14:17,546 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,546 - __main__ - INFO - 数据集名称: bbh
2025-12-25 09:14:17,546 - __main__ - INFO - 数据集路径: dataset/bbh/tracking_shuffled_objects_three_objects.json
2025-12-25 09:14:17,546 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,546 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 09:14:17,546 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,546 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 09:14:17,546 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/tracking_shuffled_objects_three_objects.json
2025-12-25 09:14:17,546 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,546 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 09:14:17,547 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 09:14:17,547 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 09:14:17,547 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 09:14:17,547 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,547 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 09:14:17,547 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,547 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 09:14:17,547 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,547 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 09:14:17,548 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 09:14:17,548 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,548 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 09:14:17,548 - __main__ - INFO - ============================================================
2025-12-25 09:14:17,548 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 09:14:17,548 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 09:14:17,548 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 09:14:21,799 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 09:14:21,799 - inference.local_inference - INFO - ============================================================
2025-12-25 09:14:21,799 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 09:14:21,799 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 09:14:21,799 - inference.local_inference - INFO - ============================================================
2025-12-25 09:15:19,584 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 09:15:30,103 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 09:15:30,104 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 09:24:52,736 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 09:24:52,736 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 09:31:15,258 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 09:31:15,259 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 09:31:15,259 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 09:31:15,259 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 09:31:26,428 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 09:31:26,429 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 09:40:44,026 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 09:40:44,026 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 09:46:39,798 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 09:46:39,798 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 09:46:39,799 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 09:46:39,881 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 09:46:39,882 - __main__ - INFO - ============================================================
2025-12-25 09:46:39,882 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 09:46:39,882 - __main__ - INFO - ============================================================
2025-12-25 09:46:39,882 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 09:46:39,882 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 09:46:39,882 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:47:38,725 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 09:47:38,726 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 09:47:38,726 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:48:28,979 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 09:48:28,980 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 09:48:28,980 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:49:04,610 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 09:49:04,611 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 09:49:04,611 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:50:26,172 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 09:50:26,173 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 09:50:26,173 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:52:07,568 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 09:52:07,568 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 09:52:07,568 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:52:40,789 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 09:52:40,789 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 09:52:40,789 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:53:41,099 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 09:53:41,099 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 09:53:41,099 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:54:10,692 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 09:54:10,693 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 09:54:10,693 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 09:54:51,352 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 09:54:51,352 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 09:54:51,352 - __main__ - INFO - 开始数据质量检查...
2025-12-25 09:54:51,353 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 09:54:51,353 - __main__ - INFO - ============================================================
2025-12-25 09:54:51,353 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 09:54:51,353 - __main__ - INFO - ============================================================
2025-12-25 09:54:51,353 - __main__ - INFO - 预检查数据完整性...
2025-12-25 09:54:51,354 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 09:54:51,354 - __main__ - INFO - Rejected非空率: 250/250 (100.0%)
2025-12-25 09:54:51,355 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 09:54:51,376 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 09:54:51,395 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 09:54:51,413 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 09:54:51,433 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 09:54:51,450 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 09:54:51,470 - __main__ - INFO - DPO数据生成完成: output/dpo_bbh_all.jsonl
2025-12-25 09:54:51,470 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 09:54:52,567 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 09:54:52,601 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 10:15:48,742 - __main__ - INFO - ============================================================
2025-12-25 10:15:48,743 - __main__ - INFO - 数据集名称: mmlu
2025-12-25 10:15:48,743 - __main__ - INFO - 数据集路径: dataset/mmlu/auxiliary_train.json
2025-12-25 10:15:48,743 - __main__ - INFO - ============================================================
2025-12-25 10:15:48,743 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-25 10:15:48,743 - __main__ - INFO - ============================================================
2025-12-25 10:15:48,743 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-25 10:15:48,743 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/auxiliary_train.json
2025-12-25 10:15:48,743 - __main__ - INFO - ============================================================
2025-12-25 10:15:51,484 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:15:51,484 - __main__ - INFO - 预处理 MMLU 数据集: 99842 条
2025-12-25 10:15:51,568 - __main__ - INFO - [数据集适配层] 预处理完成: 99842 条有效数据
2025-12-25 10:15:51,568 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:15:51,568 - __main__ - INFO - ============================================================
2025-12-25 10:15:51,592 - __main__ - INFO - 数据集加载成功，共 99842 条数据
2025-12-25 10:15:51,594 - __main__ - INFO - ============================================================
2025-12-25 10:15:51,595 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:15:51,596 - __main__ - INFO - ============================================================
2025-12-25 10:15:51,598 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:15:51,634 - __main__ - INFO - 共需处理 99842 条数据，批次大小: 64
2025-12-25 10:15:51,634 - __main__ - INFO - ============================================================
2025-12-25 10:15:51,634 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:15:51,634 - __main__ - INFO - ============================================================
2025-12-25 10:15:51,634 - __main__ - INFO - 处理批次 [1-128/99842]
2025-12-25 10:15:51,634 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:15:51,634 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:15:56,114 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-25 10:15:56,114 - inference.local_inference - INFO - ============================================================
2025-12-25 10:15:56,114 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:15:56,114 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:15:56,114 - inference.local_inference - INFO - ============================================================
2025-12-25 10:16:07,802 - __main__ - INFO - ============================================================
2025-12-25 10:16:07,802 - __main__ - INFO - 数据集名称: mmlu
2025-12-25 10:16:07,802 - __main__ - INFO - 数据集路径: dataset/mmlu/auxiliary_train.json
2025-12-25 10:16:07,802 - __main__ - INFO - ============================================================
2025-12-25 10:16:07,802 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-25 10:16:07,802 - __main__ - INFO - ============================================================
2025-12-25 10:16:07,802 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-25 10:16:07,802 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/auxiliary_train.json
2025-12-25 10:16:07,802 - __main__ - INFO - ============================================================
2025-12-25 10:16:10,589 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:16:10,589 - __main__ - INFO - 预处理 MMLU 数据集: 99842 条
2025-12-25 10:16:10,675 - __main__ - INFO - [数据集适配层] 预处理完成: 99842 条有效数据
2025-12-25 10:16:10,675 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:16:10,675 - __main__ - INFO - ============================================================
2025-12-25 10:16:10,700 - __main__ - INFO - 数据集加载成功，共 99842 条数据
2025-12-25 10:16:10,702 - __main__ - INFO - ============================================================
2025-12-25 10:16:10,703 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:16:10,707 - __main__ - INFO - ============================================================
2025-12-25 10:16:10,708 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:16:10,745 - __main__ - INFO - 共需处理 99842 条数据，批次大小: 64
2025-12-25 10:16:10,745 - __main__ - INFO - ============================================================
2025-12-25 10:16:10,745 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:16:10,745 - __main__ - INFO - ============================================================
2025-12-25 10:16:10,745 - __main__ - INFO - 处理批次 [1-128/99842]
2025-12-25 10:16:10,745 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:16:10,745 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:16:15,703 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-25 10:16:15,704 - inference.local_inference - INFO - ============================================================
2025-12-25 10:16:15,704 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:16:15,704 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:16:15,704 - inference.local_inference - INFO - ============================================================
2025-12-25 10:16:53,017 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,017 - __main__ - INFO - 数据集名称: mmlu
2025-12-25 10:16:53,017 - __main__ - INFO - 数据集路径: dataset/mmlu/dev.json
2025-12-25 10:16:53,017 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,017 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-25 10:16:53,017 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,017 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-25 10:16:53,017 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/dev.json
2025-12-25 10:16:53,017 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,020 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:16:53,020 - __main__ - INFO - 预处理 MMLU 数据集: 285 条
2025-12-25 10:16:53,020 - __main__ - INFO - [数据集适配层] 预处理完成: 285 条有效数据
2025-12-25 10:16:53,020 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:16:53,020 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,020 - __main__ - INFO - 数据集加载成功，共 285 条数据
2025-12-25 10:16:53,020 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,021 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:16:53,021 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,021 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:16:53,021 - __main__ - INFO - 共需处理 285 条数据，批次大小: 64
2025-12-25 10:16:53,021 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,021 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:16:53,021 - __main__ - INFO - ============================================================
2025-12-25 10:16:53,021 - __main__ - INFO - 处理批次 [1-128/285]
2025-12-25 10:16:53,021 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:16:53,021 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:16:55,923 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,923 - __main__ - INFO - 数据集名称: mmlu
2025-12-25 10:16:55,923 - __main__ - INFO - 数据集路径: dataset/mmlu/dev.json
2025-12-25 10:16:55,923 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,923 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-25 10:16:55,923 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,923 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-25 10:16:55,923 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/dev.json
2025-12-25 10:16:55,923 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,926 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:16:55,926 - __main__ - INFO - 预处理 MMLU 数据集: 285 条
2025-12-25 10:16:55,926 - __main__ - INFO - [数据集适配层] 预处理完成: 285 条有效数据
2025-12-25 10:16:55,926 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:16:55,926 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,926 - __main__ - INFO - 数据集加载成功，共 285 条数据
2025-12-25 10:16:55,926 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,926 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:16:55,926 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,926 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:16:55,926 - __main__ - INFO - 共需处理 285 条数据，批次大小: 64
2025-12-25 10:16:55,926 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,927 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:16:55,927 - __main__ - INFO - ============================================================
2025-12-25 10:16:55,927 - __main__ - INFO - 处理批次 [1-128/285]
2025-12-25 10:16:55,927 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:16:55,927 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:16:57,550 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-25 10:16:57,550 - inference.local_inference - INFO - ============================================================
2025-12-25 10:16:57,550 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:16:57,550 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:16:57,550 - inference.local_inference - INFO - ============================================================
2025-12-25 10:17:00,601 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-25 10:17:00,601 - inference.local_inference - INFO - ============================================================
2025-12-25 10:17:00,601 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:17:00,601 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:17:00,601 - inference.local_inference - INFO - ============================================================
2025-12-25 10:17:37,527 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,527 - __main__ - INFO - 数据集名称: mmlu
2025-12-25 10:17:37,527 - __main__ - INFO - 数据集路径: dataset/mmlu/test.json
2025-12-25 10:17:37,527 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,527 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-25 10:17:37,527 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,527 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-25 10:17:37,527 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/test.json
2025-12-25 10:17:37,527 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,679 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:17:37,679 - __main__ - INFO - 预处理 MMLU 数据集: 14042 条
2025-12-25 10:17:37,684 - __main__ - INFO - [数据集适配层] 预处理完成: 14042 条有效数据
2025-12-25 10:17:37,684 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:17:37,684 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,686 - __main__ - INFO - 数据集加载成功，共 14042 条数据
2025-12-25 10:17:37,686 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,686 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:17:37,686 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,686 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:17:37,694 - __main__ - INFO - 共需处理 14042 条数据，批次大小: 64
2025-12-25 10:17:37,694 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,694 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:17:37,694 - __main__ - INFO - ============================================================
2025-12-25 10:17:37,694 - __main__ - INFO - 处理批次 [1-128/14042]
2025-12-25 10:17:37,694 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:17:37,694 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:17:42,109 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-25 10:17:42,109 - inference.local_inference - INFO - ============================================================
2025-12-25 10:17:42,109 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:17:42,109 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:17:42,109 - inference.local_inference - INFO - ============================================================
2025-12-25 10:17:57,745 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 10:18:19,015 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,015 - __main__ - INFO - 数据集名称: mmlu
2025-12-25 10:18:19,015 - __main__ - INFO - 数据集路径: dataset/mmlu/validation.json
2025-12-25 10:18:19,015 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,016 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-25 10:18:19,016 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,016 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-25 10:18:19,016 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/validation.json
2025-12-25 10:18:19,016 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,032 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:18:19,032 - __main__ - INFO - 预处理 MMLU 数据集: 1531 条
2025-12-25 10:18:19,033 - __main__ - INFO - [数据集适配层] 预处理完成: 1531 条有效数据
2025-12-25 10:18:19,033 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:18:19,033 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,033 - __main__ - INFO - 数据集加载成功，共 1531 条数据
2025-12-25 10:18:19,033 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,033 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:18:19,033 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,033 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:18:19,034 - __main__ - INFO - 共需处理 1531 条数据，批次大小: 64
2025-12-25 10:18:19,034 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,034 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:18:19,034 - __main__ - INFO - ============================================================
2025-12-25 10:18:19,034 - __main__ - INFO - 处理批次 [1-128/1531]
2025-12-25 10:18:19,034 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:18:19,035 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:18:22,992 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 10:18:22,993 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 10:18:23,343 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-25 10:18:23,345 - inference.local_inference - INFO - ============================================================
2025-12-25 10:18:23,345 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:18:23,345 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:18:23,345 - inference.local_inference - INFO - ============================================================
2025-12-25 10:24:32,467 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,467 - __main__ - INFO - 数据集名称: bbh
2025-12-25 10:24:32,467 - __main__ - INFO - 数据集路径: dataset/bbh/boolean_expressions.json
2025-12-25 10:24:32,467 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,467 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 10:24:32,467 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,467 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 10:24:32,467 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/boolean_expressions.json
2025-12-25 10:24:32,467 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,468 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:24:32,468 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 10:24:32,468 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 10:24:32,468 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:24:32,468 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,468 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 10:24:32,468 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,468 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:24:32,468 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,468 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:24:32,469 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 10:24:32,469 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,469 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:24:32,469 - __main__ - INFO - ============================================================
2025-12-25 10:24:32,469 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 10:24:32,469 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:24:32,469 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:24:36,958 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 10:24:36,958 - inference.local_inference - INFO - ============================================================
2025-12-25 10:24:36,959 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:24:36,959 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:24:36,959 - inference.local_inference - INFO - ============================================================
2025-12-25 10:25:52,045 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 10:26:00,410 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 10:26:00,411 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 10:27:24,470 - __main__ - INFO - ============================================================
2025-12-25 10:27:24,470 - __main__ - INFO - 数据集名称: mmlu
2025-12-25 10:27:24,470 - __main__ - INFO - 数据集路径: dataset/mmlu/auxiliary_train.json
2025-12-25 10:27:24,470 - __main__ - INFO - ============================================================
2025-12-25 10:27:24,470 - __main__ - INFO - 使用数据集适配层加载: mmlu
2025-12-25 10:27:24,470 - __main__ - INFO - ============================================================
2025-12-25 10:27:24,470 - __main__ - INFO - [数据集适配层] 开始加载数据集: mmlu
2025-12-25 10:27:24,470 - __main__ - INFO - [数据集适配层] 文件路径: dataset/mmlu/auxiliary_train.json
2025-12-25 10:27:24,470 - __main__ - INFO - ============================================================
2025-12-25 10:27:27,266 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:27:27,267 - __main__ - INFO - 预处理 MMLU 数据集: 99842 条
2025-12-25 10:27:27,352 - __main__ - INFO - [数据集适配层] 预处理完成: 99842 条有效数据
2025-12-25 10:27:27,352 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:27:27,352 - __main__ - INFO - ============================================================
2025-12-25 10:27:27,381 - __main__ - INFO - 数据集加载成功，共 99842 条数据
2025-12-25 10:27:27,383 - __main__ - INFO - ============================================================
2025-12-25 10:27:27,384 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:27:27,385 - __main__ - INFO - ============================================================
2025-12-25 10:27:27,386 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:27:27,422 - __main__ - INFO - 共需处理 99842 条数据，批次大小: 64
2025-12-25 10:27:27,422 - __main__ - INFO - ============================================================
2025-12-25 10:27:27,422 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:27:27,422 - __main__ - INFO - ============================================================
2025-12-25 10:27:27,422 - __main__ - INFO - 处理批次 [1-128/99842]
2025-12-25 10:27:27,422 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:27:27,422 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:27:32,380 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 6,7
2025-12-25 10:27:32,381 - inference.local_inference - INFO - ============================================================
2025-12-25 10:27:32,381 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:27:32,381 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:27:32,381 - inference.local_inference - INFO - ============================================================
2025-12-25 10:28:48,185 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 10:29:09,333 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 10:29:09,334 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 10:35:14,083 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 10:35:14,083 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 10:35:14,111 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,129 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,147 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,163 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,179 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,195 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,210 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,226 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,240 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,254 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,270 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,275 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 3374 tokens (最大允许: 1808)
2025-12-25 10:35:14,290 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,305 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,318 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8415 tokens (最大允许: 1808)
2025-12-25 10:35:14,332 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,346 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8415 tokens (最大允许: 1808)
2025-12-25 10:35:14,360 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,374 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,389 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,404 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,419 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,433 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,447 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,462 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,476 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,490 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,505 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,520 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,525 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 2892 tokens (最大允许: 1808)
2025-12-25 10:35:14,541 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,556 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,571 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,586 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,606 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,620 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,634 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8415 tokens (最大允许: 1808)
2025-12-25 10:35:14,649 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,664 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,678 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,692 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,707 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,721 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,736 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,751 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,768 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,782 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,797 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,813 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,828 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,842 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,856 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,871 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8415 tokens (最大允许: 1808)
2025-12-25 10:35:14,885 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8415 tokens (最大允许: 1808)
2025-12-25 10:35:14,900 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,915 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,930 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,944 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,959 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:14,973 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:14,989 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,002 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,019 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,033 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,047 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,062 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,077 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,092 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,106 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,110 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 1942 tokens (最大允许: 1808)
2025-12-25 10:35:15,116 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 3985 tokens (最大允许: 1808)
2025-12-25 10:35:15,131 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,145 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,159 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,176 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,190 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,204 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,220 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,235 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,248 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,263 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,277 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,294 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,309 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,318 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 4700 tokens (最大允许: 1808)
2025-12-25 10:35:15,321 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 2060 tokens (最大允许: 1808)
2025-12-25 10:35:15,336 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,351 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,367 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,382 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,396 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,411 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,426 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,440 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,454 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,469 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,484 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,499 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,503 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 1904 tokens (最大允许: 1808)
2025-12-25 10:35:15,517 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,531 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,546 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,560 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,575 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,591 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,607 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,620 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,636 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,651 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,666 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,682 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8415 tokens (最大允许: 1808)
2025-12-25 10:35:15,699 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,715 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,730 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,746 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,760 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,775 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,790 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,806 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8416 tokens (最大允许: 1808)
2025-12-25 10:35:15,822 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8417 tokens (最大允许: 1808)
2025-12-25 10:35:15,825 - inference.local_inference - WARNING - 共跳过 120/128 条超长prompts
2025-12-25 10:37:37,079 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 10:37:37,080 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 10:37:37,080 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 10:37:37,080 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 10:37:44,777 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 10:37:44,777 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 10:39:12,418 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 10:39:12,418 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 10:39:12,446 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8515 tokens (最大允许: 1808)
2025-12-25 10:39:12,465 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8644 tokens (最大允许: 1808)
2025-12-25 10:39:12,483 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8579 tokens (最大允许: 1808)
2025-12-25 10:39:12,502 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8531 tokens (最大允许: 1808)
2025-12-25 10:39:12,519 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8699 tokens (最大允许: 1808)
2025-12-25 10:39:12,536 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8698 tokens (最大允许: 1808)
2025-12-25 10:39:12,552 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8726 tokens (最大允许: 1808)
2025-12-25 10:39:12,568 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8546 tokens (最大允许: 1808)
2025-12-25 10:39:12,584 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8521 tokens (最大允许: 1808)
2025-12-25 10:39:12,592 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 2764 tokens (最大允许: 1808)
2025-12-25 10:39:12,608 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8508 tokens (最大允许: 1808)
2025-12-25 10:39:12,624 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8635 tokens (最大允许: 1808)
2025-12-25 10:39:12,640 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8683 tokens (最大允许: 1808)
2025-12-25 10:39:12,656 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8680 tokens (最大允许: 1808)
2025-12-25 10:39:12,672 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8580 tokens (最大允许: 1808)
2025-12-25 10:39:12,687 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8472 tokens (最大允许: 1808)
2025-12-25 10:39:12,693 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 3262 tokens (最大允许: 1808)
2025-12-25 10:39:12,709 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8717 tokens (最大允许: 1808)
2025-12-25 10:39:12,725 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8602 tokens (最大允许: 1808)
2025-12-25 10:39:12,741 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8647 tokens (最大允许: 1808)
2025-12-25 10:39:12,760 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8655 tokens (最大允许: 1808)
2025-12-25 10:39:12,767 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 3699 tokens (最大允许: 1808)
2025-12-25 10:39:12,784 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8633 tokens (最大允许: 1808)
2025-12-25 10:39:12,800 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8616 tokens (最大允许: 1808)
2025-12-25 10:39:12,816 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8754 tokens (最大允许: 1808)
2025-12-25 10:39:12,834 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8766 tokens (最大允许: 1808)
2025-12-25 10:39:12,850 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8777 tokens (最大允许: 1808)
2025-12-25 10:39:12,867 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8641 tokens (最大允许: 1808)
2025-12-25 10:39:12,883 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8625 tokens (最大允许: 1808)
2025-12-25 10:39:12,899 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8640 tokens (最大允许: 1808)
2025-12-25 10:39:12,915 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8573 tokens (最大允许: 1808)
2025-12-25 10:39:12,931 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8479 tokens (最大允许: 1808)
2025-12-25 10:39:12,947 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8841 tokens (最大允许: 1808)
2025-12-25 10:39:12,964 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8837 tokens (最大允许: 1808)
2025-12-25 10:39:12,982 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8752 tokens (最大允许: 1808)
2025-12-25 10:39:12,999 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8618 tokens (最大允许: 1808)
2025-12-25 10:39:13,016 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8580 tokens (最大允许: 1808)
2025-12-25 10:39:13,033 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8599 tokens (最大允许: 1808)
2025-12-25 10:39:13,049 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8670 tokens (最大允许: 1808)
2025-12-25 10:39:13,065 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8666 tokens (最大允许: 1808)
2025-12-25 10:39:13,080 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8674 tokens (最大允许: 1808)
2025-12-25 10:39:13,096 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8567 tokens (最大允许: 1808)
2025-12-25 10:39:13,112 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8602 tokens (最大允许: 1808)
2025-12-25 10:39:13,127 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8570 tokens (最大允许: 1808)
2025-12-25 10:39:13,142 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8597 tokens (最大允许: 1808)
2025-12-25 10:39:13,159 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8563 tokens (最大允许: 1808)
2025-12-25 10:39:13,165 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 2083 tokens (最大允许: 1808)
2025-12-25 10:39:13,181 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8684 tokens (最大允许: 1808)
2025-12-25 10:39:13,198 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8652 tokens (最大允许: 1808)
2025-12-25 10:39:13,215 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8660 tokens (最大允许: 1808)
2025-12-25 10:39:13,232 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8702 tokens (最大允许: 1808)
2025-12-25 10:39:13,253 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8678 tokens (最大允许: 1808)
2025-12-25 10:39:13,273 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8742 tokens (最大允许: 1808)
2025-12-25 10:39:13,290 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8608 tokens (最大允许: 1808)
2025-12-25 10:39:13,306 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8630 tokens (最大允许: 1808)
2025-12-25 10:39:13,322 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8541 tokens (最大允许: 1808)
2025-12-25 10:39:13,338 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8666 tokens (最大允许: 1808)
2025-12-25 10:39:13,362 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8833 tokens (最大允许: 1808)
2025-12-25 10:39:13,382 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8844 tokens (最大允许: 1808)
2025-12-25 10:39:13,400 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8923 tokens (最大允许: 1808)
2025-12-25 10:39:13,418 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8926 tokens (最大允许: 1808)
2025-12-25 10:39:13,435 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8875 tokens (最大允许: 1808)
2025-12-25 10:39:13,451 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8934 tokens (最大允许: 1808)
2025-12-25 10:39:13,468 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8931 tokens (最大允许: 1808)
2025-12-25 10:39:13,486 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8599 tokens (最大允许: 1808)
2025-12-25 10:39:13,503 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8581 tokens (最大允许: 1808)
2025-12-25 10:39:13,508 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 2168 tokens (最大允许: 1808)
2025-12-25 10:39:13,524 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8584 tokens (最大允许: 1808)
2025-12-25 10:39:13,542 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8495 tokens (最大允许: 1808)
2025-12-25 10:39:13,559 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8773 tokens (最大允许: 1808)
2025-12-25 10:39:13,576 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8885 tokens (最大允许: 1808)
2025-12-25 10:39:13,590 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8750 tokens (最大允许: 1808)
2025-12-25 10:39:13,607 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8770 tokens (最大允许: 1808)
2025-12-25 10:39:13,612 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 2429 tokens (最大允许: 1808)
2025-12-25 10:39:13,628 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8554 tokens (最大允许: 1808)
2025-12-25 10:39:13,645 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8568 tokens (最大允许: 1808)
2025-12-25 10:39:13,662 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8611 tokens (最大允许: 1808)
2025-12-25 10:39:13,679 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8632 tokens (最大允许: 1808)
2025-12-25 10:39:13,696 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8621 tokens (最大允许: 1808)
2025-12-25 10:39:13,712 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8592 tokens (最大允许: 1808)
2025-12-25 10:39:13,728 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8621 tokens (最大允许: 1808)
2025-12-25 10:39:13,744 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8539 tokens (最大允许: 1808)
2025-12-25 10:39:13,760 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8553 tokens (最大允许: 1808)
2025-12-25 10:39:13,776 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8783 tokens (最大允许: 1808)
2025-12-25 10:39:13,792 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8868 tokens (最大允许: 1808)
2025-12-25 10:39:13,809 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8825 tokens (最大允许: 1808)
2025-12-25 10:39:13,825 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8835 tokens (最大允许: 1808)
2025-12-25 10:39:13,841 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8880 tokens (最大允许: 1808)
2025-12-25 10:39:13,845 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 2205 tokens (最大允许: 1808)
2025-12-25 10:39:13,860 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8626 tokens (最大允许: 1808)
2025-12-25 10:39:13,876 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8619 tokens (最大允许: 1808)
2025-12-25 10:39:13,892 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8631 tokens (最大允许: 1808)
2025-12-25 10:39:13,908 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8651 tokens (最大允许: 1808)
2025-12-25 10:39:13,924 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8650 tokens (最大允许: 1808)
2025-12-25 10:39:13,938 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8495 tokens (最大允许: 1808)
2025-12-25 10:39:13,955 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 9401 tokens (最大允许: 1808)
2025-12-25 10:39:13,959 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 2234 tokens (最大允许: 1808)
2025-12-25 10:39:13,974 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8817 tokens (最大允许: 1808)
2025-12-25 10:39:13,991 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8779 tokens (最大允许: 1808)
2025-12-25 10:39:14,006 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8756 tokens (最大允许: 1808)
2025-12-25 10:39:14,022 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 6685 tokens (最大允许: 1808)
2025-12-25 10:39:14,037 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8532 tokens (最大允许: 1808)
2025-12-25 10:39:14,052 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8539 tokens (最大允许: 1808)
2025-12-25 10:39:14,067 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8519 tokens (最大允许: 1808)
2025-12-25 10:39:14,082 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8542 tokens (最大允许: 1808)
2025-12-25 10:39:14,097 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8508 tokens (最大允许: 1808)
2025-12-25 10:39:14,113 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8530 tokens (最大允许: 1808)
2025-12-25 10:39:14,129 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8626 tokens (最大允许: 1808)
2025-12-25 10:39:14,146 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8903 tokens (最大允许: 1808)
2025-12-25 10:39:14,162 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8859 tokens (最大允许: 1808)
2025-12-25 10:39:14,179 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8817 tokens (最大允许: 1808)
2025-12-25 10:39:14,195 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8790 tokens (最大允许: 1808)
2025-12-25 10:39:14,211 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8852 tokens (最大允许: 1808)
2025-12-25 10:39:14,217 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 3123 tokens (最大允许: 1808)
2025-12-25 10:39:14,232 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8549 tokens (最大允许: 1808)
2025-12-25 10:39:14,248 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8557 tokens (最大允许: 1808)
2025-12-25 10:39:14,264 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8674 tokens (最大允许: 1808)
2025-12-25 10:39:14,283 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8679 tokens (最大允许: 1808)
2025-12-25 10:39:14,304 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8627 tokens (最大允许: 1808)
2025-12-25 10:39:14,322 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8687 tokens (最大允许: 1808)
2025-12-25 10:39:14,338 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8854 tokens (最大允许: 1808)
2025-12-25 10:39:14,354 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8804 tokens (最大允许: 1808)
2025-12-25 10:39:14,356 - inference.local_inference - WARNING - 共跳过 122/128 条超长prompts
2025-12-25 10:41:26,027 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 10:41:26,028 - __main__ - INFO - 处理批次 [129-256/99842]
2025-12-25 10:41:26,029 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:41:26,029 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:41:46,854 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 10:41:46,854 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 10:46:46,253 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 10:46:46,253 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 10:46:46,279 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,298 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,317 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,334 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,352 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,369 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,389 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,406 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,423 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:46,442 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,460 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,480 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,488 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 3819 tokens (最大允许: 1808)
2025-12-25 10:46:46,505 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,523 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,541 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:46,557 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,577 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,596 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,614 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,636 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,654 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8415 tokens (最大允许: 1808)
2025-12-25 10:46:46,673 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8415 tokens (最大允许: 1808)
2025-12-25 10:46:46,690 - inference.local_inference - WARNING - 跳过超长prompt [25/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,704 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,720 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,737 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,755 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,761 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 3277 tokens (最大允许: 1808)
2025-12-25 10:46:46,778 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,794 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:46,810 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,826 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,842 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,857 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,872 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,878 - inference.local_inference - WARNING - 跳过超长prompt [39/122]: 3305 tokens (最大允许: 1808)
2025-12-25 10:46:46,895 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,911 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,927 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,946 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,962 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,977 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:46,992 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,009 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,024 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,040 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,055 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,070 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8415 tokens (最大允许: 1808)
2025-12-25 10:46:47,084 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,088 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 2758 tokens (最大允许: 1808)
2025-12-25 10:46:47,103 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,119 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,134 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,149 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,166 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,183 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,200 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,217 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,232 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,248 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 8415 tokens (最大允许: 1808)
2025-12-25 10:46:47,263 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,278 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,294 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,299 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 2299 tokens (最大允许: 1808)
2025-12-25 10:46:47,315 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,331 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,347 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,363 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,380 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,395 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,412 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,431 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,446 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8415 tokens (最大允许: 1808)
2025-12-25 10:46:47,462 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8415 tokens (最大允许: 1808)
2025-12-25 10:46:47,478 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,496 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,513 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,532 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,549 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,567 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,582 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,597 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,612 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,629 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,650 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,665 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,681 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,697 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,712 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,728 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,742 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,758 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,775 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8415 tokens (最大允许: 1808)
2025-12-25 10:46:47,790 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,806 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,822 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,839 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,854 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,870 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,885 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,901 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,915 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,929 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:47,945 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,957 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,972 - inference.local_inference - WARNING - 跳过超长prompt [112/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:47,991 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:48,007 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:48,022 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:48,038 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8416 tokens (最大允许: 1808)
2025-12-25 10:46:48,052 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:48,068 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:48,085 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:48,101 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8417 tokens (最大允许: 1808)
2025-12-25 10:46:48,105 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 2621 tokens (最大允许: 1808)
2025-12-25 10:46:48,106 - inference.local_inference - WARNING - 共跳过 116/122 条超长prompts
2025-12-25 10:49:04,474 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 10:49:04,475 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 10:49:04,476 - __main__ - WARNING - ⚠️  236/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 10:49:04,476 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 10:49:04,548 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 10:49:04,548 - __main__ - INFO - ============================================================
2025-12-25 10:49:04,548 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 10:49:04,548 - __main__ - INFO - ============================================================
2025-12-25 10:49:04,548 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 10:49:04,548 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 10:49:04,549 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:49:51,686 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 10:49:51,687 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 10:49:51,688 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:50:34,101 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 10:50:34,101 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 10:50:34,101 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:51:58,259 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 10:51:58,260 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 10:51:58,260 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:52:16,881 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 10:52:16,881 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 10:52:16,909 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8622 tokens (最大允许: 1808)
2025-12-25 10:52:16,929 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8612 tokens (最大允许: 1808)
2025-12-25 10:52:16,948 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8715 tokens (最大允许: 1808)
2025-12-25 10:52:16,966 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8694 tokens (最大允许: 1808)
2025-12-25 10:52:16,983 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8689 tokens (最大允许: 1808)
2025-12-25 10:52:17,001 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8564 tokens (最大允许: 1808)
2025-12-25 10:52:17,017 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8559 tokens (最大允许: 1808)
2025-12-25 10:52:17,033 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8608 tokens (最大允许: 1808)
2025-12-25 10:52:17,048 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8511 tokens (最大允许: 1808)
2025-12-25 10:52:17,064 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8511 tokens (最大允许: 1808)
2025-12-25 10:52:17,081 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8515 tokens (最大允许: 1808)
2025-12-25 10:52:17,096 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8525 tokens (最大允许: 1808)
2025-12-25 10:52:17,111 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8476 tokens (最大允许: 1808)
2025-12-25 10:52:17,127 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8598 tokens (最大允许: 1808)
2025-12-25 10:52:17,143 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8824 tokens (最大允许: 1808)
2025-12-25 10:52:17,159 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8823 tokens (最大允许: 1808)
2025-12-25 10:52:17,164 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 2549 tokens (最大允许: 1808)
2025-12-25 10:52:17,179 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8616 tokens (最大允许: 1808)
2025-12-25 10:52:17,196 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8816 tokens (最大允许: 1808)
2025-12-25 10:52:17,212 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8568 tokens (最大允许: 1808)
2025-12-25 10:52:17,228 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8651 tokens (最大允许: 1808)
2025-12-25 10:52:17,243 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8548 tokens (最大允许: 1808)
2025-12-25 10:52:17,259 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8724 tokens (最大允许: 1808)
2025-12-25 10:52:17,275 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8684 tokens (最大允许: 1808)
2025-12-25 10:52:17,290 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8703 tokens (最大允许: 1808)
2025-12-25 10:52:17,307 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8732 tokens (最大允许: 1808)
2025-12-25 10:52:17,323 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8811 tokens (最大允许: 1808)
2025-12-25 10:52:17,339 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8725 tokens (最大允许: 1808)
2025-12-25 10:52:17,354 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8677 tokens (最大允许: 1808)
2025-12-25 10:52:17,370 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8686 tokens (最大允许: 1808)
2025-12-25 10:52:17,385 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8705 tokens (最大允许: 1808)
2025-12-25 10:52:17,400 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8701 tokens (最大允许: 1808)
2025-12-25 10:52:17,416 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8547 tokens (最大允许: 1808)
2025-12-25 10:52:17,419 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 1831 tokens (最大允许: 1808)
2025-12-25 10:52:17,436 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8559 tokens (最大允许: 1808)
2025-12-25 10:52:17,452 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8549 tokens (最大允许: 1808)
2025-12-25 10:52:17,468 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8656 tokens (最大允许: 1808)
2025-12-25 10:52:17,483 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8764 tokens (最大允许: 1808)
2025-12-25 10:52:17,499 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8742 tokens (最大允许: 1808)
2025-12-25 10:52:17,515 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8741 tokens (最大允许: 1808)
2025-12-25 10:52:17,530 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8524 tokens (最大允许: 1808)
2025-12-25 10:52:17,546 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8566 tokens (最大允许: 1808)
2025-12-25 10:52:17,563 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8681 tokens (最大允许: 1808)
2025-12-25 10:52:17,579 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8573 tokens (最大允许: 1808)
2025-12-25 10:52:17,595 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8558 tokens (最大允许: 1808)
2025-12-25 10:52:17,611 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8532 tokens (最大允许: 1808)
2025-12-25 10:52:17,628 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8593 tokens (最大允许: 1808)
2025-12-25 10:52:17,644 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8598 tokens (最大允许: 1808)
2025-12-25 10:52:17,648 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 2400 tokens (最大允许: 1808)
2025-12-25 10:52:17,664 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8541 tokens (最大允许: 1808)
2025-12-25 10:52:17,680 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8804 tokens (最大允许: 1808)
2025-12-25 10:52:17,697 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8644 tokens (最大允许: 1808)
2025-12-25 10:52:17,713 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8666 tokens (最大允许: 1808)
2025-12-25 10:52:17,729 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8529 tokens (最大允许: 1808)
2025-12-25 10:52:17,744 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8739 tokens (最大允许: 1808)
2025-12-25 10:52:17,760 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8746 tokens (最大允许: 1808)
2025-12-25 10:52:17,776 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8744 tokens (最大允许: 1808)
2025-12-25 10:52:17,792 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8525 tokens (最大允许: 1808)
2025-12-25 10:52:17,808 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8643 tokens (最大允许: 1808)
2025-12-25 10:52:17,815 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 3653 tokens (最大允许: 1808)
2025-12-25 10:52:17,830 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8932 tokens (最大允许: 1808)
2025-12-25 10:52:17,846 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8973 tokens (最大允许: 1808)
2025-12-25 10:52:17,863 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8562 tokens (最大允许: 1808)
2025-12-25 10:52:17,881 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8808 tokens (最大允许: 1808)
2025-12-25 10:52:17,898 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8881 tokens (最大允许: 1808)
2025-12-25 10:52:17,916 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8660 tokens (最大允许: 1808)
2025-12-25 10:52:17,932 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8532 tokens (最大允许: 1808)
2025-12-25 10:52:17,948 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8551 tokens (最大允许: 1808)
2025-12-25 10:52:17,966 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8686 tokens (最大允许: 1808)
2025-12-25 10:52:17,981 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8542 tokens (最大允许: 1808)
2025-12-25 10:52:17,996 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8562 tokens (最大允许: 1808)
2025-12-25 10:52:18,013 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8695 tokens (最大允许: 1808)
2025-12-25 10:52:18,030 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8698 tokens (最大允许: 1808)
2025-12-25 10:52:18,035 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 2325 tokens (最大允许: 1808)
2025-12-25 10:52:18,052 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8617 tokens (最大允许: 1808)
2025-12-25 10:52:18,069 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8691 tokens (最大允许: 1808)
2025-12-25 10:52:18,085 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8679 tokens (最大允许: 1808)
2025-12-25 10:52:18,101 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8591 tokens (最大允许: 1808)
2025-12-25 10:52:18,117 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8589 tokens (最大允许: 1808)
2025-12-25 10:52:18,133 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8813 tokens (最大允许: 1808)
2025-12-25 10:52:18,150 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8723 tokens (最大允许: 1808)
2025-12-25 10:52:18,166 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8683 tokens (最大允许: 1808)
2025-12-25 10:52:18,183 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8695 tokens (最大允许: 1808)
2025-12-25 10:52:18,198 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8562 tokens (最大允许: 1808)
2025-12-25 10:52:18,214 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8551 tokens (最大允许: 1808)
2025-12-25 10:52:18,230 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8515 tokens (最大允许: 1808)
2025-12-25 10:52:18,246 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8506 tokens (最大允许: 1808)
2025-12-25 10:52:18,262 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8535 tokens (最大允许: 1808)
2025-12-25 10:52:18,278 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8531 tokens (最大允许: 1808)
2025-12-25 10:52:18,293 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8573 tokens (最大允许: 1808)
2025-12-25 10:52:18,308 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8581 tokens (最大允许: 1808)
2025-12-25 10:52:18,324 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8637 tokens (最大允许: 1808)
2025-12-25 10:52:18,341 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8606 tokens (最大允许: 1808)
2025-12-25 10:52:18,356 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8535 tokens (最大允许: 1808)
2025-12-25 10:52:18,372 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8609 tokens (最大允许: 1808)
2025-12-25 10:52:18,388 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8762 tokens (最大允许: 1808)
2025-12-25 10:52:18,404 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8595 tokens (最大允许: 1808)
2025-12-25 10:52:18,420 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8568 tokens (最大允许: 1808)
2025-12-25 10:52:18,436 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8771 tokens (最大允许: 1808)
2025-12-25 10:52:18,453 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8774 tokens (最大允许: 1808)
2025-12-25 10:52:18,458 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 2624 tokens (最大允许: 1808)
2025-12-25 10:52:18,474 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8789 tokens (最大允许: 1808)
2025-12-25 10:52:18,478 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 2132 tokens (最大允许: 1808)
2025-12-25 10:52:18,494 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8557 tokens (最大允许: 1808)
2025-12-25 10:52:18,510 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8597 tokens (最大允许: 1808)
2025-12-25 10:52:18,527 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8640 tokens (最大允许: 1808)
2025-12-25 10:52:18,543 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8572 tokens (最大允许: 1808)
2025-12-25 10:52:18,559 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8575 tokens (最大允许: 1808)
2025-12-25 10:52:18,575 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8670 tokens (最大允许: 1808)
2025-12-25 10:52:18,591 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8692 tokens (最大允许: 1808)
2025-12-25 10:52:18,607 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8691 tokens (最大允许: 1808)
2025-12-25 10:52:18,623 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8832 tokens (最大允许: 1808)
2025-12-25 10:52:18,639 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8605 tokens (最大允许: 1808)
2025-12-25 10:52:18,655 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8579 tokens (最大允许: 1808)
2025-12-25 10:52:18,670 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8623 tokens (最大允许: 1808)
2025-12-25 10:52:18,686 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8603 tokens (最大允许: 1808)
2025-12-25 10:52:18,702 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8625 tokens (最大允许: 1808)
2025-12-25 10:52:18,719 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8692 tokens (最大允许: 1808)
2025-12-25 10:52:18,735 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8658 tokens (最大允许: 1808)
2025-12-25 10:52:18,750 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8582 tokens (最大允许: 1808)
2025-12-25 10:52:18,766 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8537 tokens (最大允许: 1808)
2025-12-25 10:52:18,782 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8996 tokens (最大允许: 1808)
2025-12-25 10:52:18,798 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 9102 tokens (最大允许: 1808)
2025-12-25 10:52:18,814 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8959 tokens (最大允许: 1808)
2025-12-25 10:52:18,819 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 2854 tokens (最大允许: 1808)
2025-12-25 10:52:18,835 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8754 tokens (最大允许: 1808)
2025-12-25 10:52:18,852 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8577 tokens (最大允许: 1808)
2025-12-25 10:52:18,868 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8620 tokens (最大允许: 1808)
2025-12-25 10:52:18,868 - inference.local_inference - WARNING - 共跳过 128/128 条超长prompts
2025-12-25 10:52:18,868 - inference.local_inference - ERROR - 所有prompts都超长，返回空列表
2025-12-25 10:52:18,868 - __main__ - INFO - 批次 [129-256] 本地推理完成
2025-12-25 10:52:18,868 - __main__ - INFO - 处理批次 [257-384/99842]
2025-12-25 10:52:18,868 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:52:18,868 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:52:42,701 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 10:52:42,701 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 10:52:59,993 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 10:52:59,994 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 10:52:59,994 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:54:15,561 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 10:54:15,561 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 10:54:15,562 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:55:05,073 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 10:55:05,074 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 10:55:05,074 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:56:20,579 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 10:56:20,580 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 10:56:20,580 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:57:06,304 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 10:57:06,304 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 10:57:06,305 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 10:57:39,908 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 10:57:39,908 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 10:57:39,909 - __main__ - INFO - 开始数据质量检查...
2025-12-25 10:57:39,909 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 10:57:39,909 - __main__ - INFO - ============================================================
2025-12-25 10:57:39,909 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 10:57:39,909 - __main__ - INFO - ============================================================
2025-12-25 10:57:39,909 - __main__ - INFO - 预检查数据完整性...
2025-12-25 10:57:39,909 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 10:57:39,910 - __main__ - INFO - Rejected非空率: 14/250 (5.6%)
2025-12-25 10:57:39,910 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 10:57:39,931 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 10:57:39,945 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 10:57:39,963 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 10:57:39,980 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 10:57:39,994 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 10:57:40,010 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_boolean_expressions.jsonl
2025-12-25 10:57:40,010 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 10:57:43,713 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 10:57:43,745 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 10:57:44,810 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,810 - __main__ - INFO - 数据集名称: bbh
2025-12-25 10:57:44,810 - __main__ - INFO - 数据集路径: dataset/bbh/causal_judgement.json
2025-12-25 10:57:44,810 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,810 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 10:57:44,810 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,810 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 10:57:44,810 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/causal_judgement.json
2025-12-25 10:57:44,810 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,811 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 10:57:44,811 - __main__ - INFO - 预处理 BBH 数据集: 187 条
2025-12-25 10:57:44,811 - __main__ - INFO - [数据集适配层] 预处理完成: 187 条有效数据
2025-12-25 10:57:44,811 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 10:57:44,811 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,811 - __main__ - INFO - 数据集加载成功，共 187 条数据
2025-12-25 10:57:44,811 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,811 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 10:57:44,811 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,812 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 10:57:44,812 - __main__ - INFO - 共需处理 187 条数据，批次大小: 64
2025-12-25 10:57:44,812 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,812 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 10:57:44,812 - __main__ - INFO - ============================================================
2025-12-25 10:57:44,812 - __main__ - INFO - 处理批次 [1-128/187]
2025-12-25 10:57:44,812 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 10:57:44,812 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 10:57:49,218 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 10:57:49,218 - inference.local_inference - INFO - ============================================================
2025-12-25 10:57:49,218 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 10:57:49,218 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 10:57:49,218 - inference.local_inference - INFO - ============================================================
2025-12-25 10:59:04,482 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 10:59:18,119 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 10:59:18,120 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 11:03:12,430 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 11:03:12,431 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 11:03:12,456 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:03:12,477 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8594 tokens (最大允许: 1808)
2025-12-25 11:03:12,495 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8557 tokens (最大允许: 1808)
2025-12-25 11:03:12,511 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8574 tokens (最大允许: 1808)
2025-12-25 11:03:12,529 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8782 tokens (最大允许: 1808)
2025-12-25 11:03:12,545 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8851 tokens (最大允许: 1808)
2025-12-25 11:03:12,561 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8554 tokens (最大允许: 1808)
2025-12-25 11:03:12,577 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8774 tokens (最大允许: 1808)
2025-12-25 11:03:12,593 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8615 tokens (最大允许: 1808)
2025-12-25 11:03:12,608 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8557 tokens (最大允许: 1808)
2025-12-25 11:03:12,623 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8511 tokens (最大允许: 1808)
2025-12-25 11:03:12,638 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8541 tokens (最大允许: 1808)
2025-12-25 11:03:12,653 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8607 tokens (最大允许: 1808)
2025-12-25 11:03:12,669 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8811 tokens (最大允许: 1808)
2025-12-25 11:03:12,685 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8593 tokens (最大允许: 1808)
2025-12-25 11:03:12,702 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8607 tokens (最大允许: 1808)
2025-12-25 11:03:12,717 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8499 tokens (最大允许: 1808)
2025-12-25 11:03:12,733 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8680 tokens (最大允许: 1808)
2025-12-25 11:03:12,749 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8666 tokens (最大允许: 1808)
2025-12-25 11:03:12,764 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8631 tokens (最大允许: 1808)
2025-12-25 11:03:12,779 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8706 tokens (最大允许: 1808)
2025-12-25 11:03:12,794 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8590 tokens (最大允许: 1808)
2025-12-25 11:03:12,812 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8807 tokens (最大允许: 1808)
2025-12-25 11:03:12,828 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8516 tokens (最大允许: 1808)
2025-12-25 11:03:12,844 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8554 tokens (最大允许: 1808)
2025-12-25 11:03:12,860 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8577 tokens (最大允许: 1808)
2025-12-25 11:03:12,876 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8552 tokens (最大允许: 1808)
2025-12-25 11:03:12,892 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8811 tokens (最大允许: 1808)
2025-12-25 11:03:12,908 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8612 tokens (最大允许: 1808)
2025-12-25 11:03:12,924 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8743 tokens (最大允许: 1808)
2025-12-25 11:03:12,940 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8830 tokens (最大允许: 1808)
2025-12-25 11:03:12,956 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8713 tokens (最大允许: 1808)
2025-12-25 11:03:12,972 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8695 tokens (最大允许: 1808)
2025-12-25 11:03:12,987 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8611 tokens (最大允许: 1808)
2025-12-25 11:03:13,003 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8566 tokens (最大允许: 1808)
2025-12-25 11:03:13,018 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8580 tokens (最大允许: 1808)
2025-12-25 11:03:13,034 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8718 tokens (最大允许: 1808)
2025-12-25 11:03:13,050 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8700 tokens (最大允许: 1808)
2025-12-25 11:03:13,066 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8713 tokens (最大允许: 1808)
2025-12-25 11:03:13,071 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 2459 tokens (最大允许: 1808)
2025-12-25 11:03:13,088 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8752 tokens (最大允许: 1808)
2025-12-25 11:03:13,106 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8731 tokens (最大允许: 1808)
2025-12-25 11:03:13,123 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8786 tokens (最大允许: 1808)
2025-12-25 11:03:13,140 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8835 tokens (最大允许: 1808)
2025-12-25 11:03:13,158 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8584 tokens (最大允许: 1808)
2025-12-25 11:03:13,175 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8756 tokens (最大允许: 1808)
2025-12-25 11:03:13,191 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8778 tokens (最大允许: 1808)
2025-12-25 11:03:13,207 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8826 tokens (最大允许: 1808)
2025-12-25 11:03:13,222 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8628 tokens (最大允许: 1808)
2025-12-25 11:03:13,229 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 3591 tokens (最大允许: 1808)
2025-12-25 11:03:13,244 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8619 tokens (最大允许: 1808)
2025-12-25 11:03:13,259 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8491 tokens (最大允许: 1808)
2025-12-25 11:03:13,274 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8753 tokens (最大允许: 1808)
2025-12-25 11:03:13,289 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8718 tokens (最大允许: 1808)
2025-12-25 11:03:13,305 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8537 tokens (最大允许: 1808)
2025-12-25 11:03:13,321 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8516 tokens (最大允许: 1808)
2025-12-25 11:03:13,337 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8605 tokens (最大允许: 1808)
2025-12-25 11:03:13,353 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8861 tokens (最大允许: 1808)
2025-12-25 11:03:13,358 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 2272 tokens (最大允许: 1808)
2025-12-25 11:03:13,373 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8796 tokens (最大允许: 1808)
2025-12-25 11:03:13,388 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8701 tokens (最大允许: 1808)
2025-12-25 11:03:13,404 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8639 tokens (最大允许: 1808)
2025-12-25 11:03:13,419 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8646 tokens (最大允许: 1808)
2025-12-25 11:03:13,435 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8623 tokens (最大允许: 1808)
2025-12-25 11:03:13,452 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8734 tokens (最大允许: 1808)
2025-12-25 11:03:13,469 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8863 tokens (最大允许: 1808)
2025-12-25 11:03:13,486 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8844 tokens (最大允许: 1808)
2025-12-25 11:03:13,502 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8883 tokens (最大允许: 1808)
2025-12-25 11:03:13,519 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8868 tokens (最大允许: 1808)
2025-12-25 11:03:13,524 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 2108 tokens (最大允许: 1808)
2025-12-25 11:03:13,541 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8627 tokens (最大允许: 1808)
2025-12-25 11:03:13,558 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8629 tokens (最大允许: 1808)
2025-12-25 11:03:13,575 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8938 tokens (最大允许: 1808)
2025-12-25 11:03:13,591 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8950 tokens (最大允许: 1808)
2025-12-25 11:03:13,608 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8596 tokens (最大允许: 1808)
2025-12-25 11:03:13,624 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8643 tokens (最大允许: 1808)
2025-12-25 11:03:13,640 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8580 tokens (最大允许: 1808)
2025-12-25 11:03:13,649 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 5114 tokens (最大允许: 1808)
2025-12-25 11:03:13,665 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8683 tokens (最大允许: 1808)
2025-12-25 11:03:13,681 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8714 tokens (最大允许: 1808)
2025-12-25 11:03:13,696 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8762 tokens (最大允许: 1808)
2025-12-25 11:03:13,712 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8548 tokens (最大允许: 1808)
2025-12-25 11:03:13,728 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8565 tokens (最大允许: 1808)
2025-12-25 11:03:13,744 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8591 tokens (最大允许: 1808)
2025-12-25 11:03:13,759 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8615 tokens (最大允许: 1808)
2025-12-25 11:03:13,775 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8708 tokens (最大允许: 1808)
2025-12-25 11:03:13,790 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8542 tokens (最大允许: 1808)
2025-12-25 11:03:13,806 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8565 tokens (最大允许: 1808)
2025-12-25 11:03:13,822 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8676 tokens (最大允许: 1808)
2025-12-25 11:03:13,837 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8631 tokens (最大允许: 1808)
2025-12-25 11:03:13,853 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8579 tokens (最大允许: 1808)
2025-12-25 11:03:13,869 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8635 tokens (最大允许: 1808)
2025-12-25 11:03:13,885 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8795 tokens (最大允许: 1808)
2025-12-25 11:03:13,901 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8650 tokens (最大允许: 1808)
2025-12-25 11:03:13,917 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8619 tokens (最大允许: 1808)
2025-12-25 11:03:13,934 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8684 tokens (最大允许: 1808)
2025-12-25 11:03:13,951 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8632 tokens (最大允许: 1808)
2025-12-25 11:03:13,967 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8541 tokens (最大允许: 1808)
2025-12-25 11:03:13,983 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8615 tokens (最大允许: 1808)
2025-12-25 11:03:13,999 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8618 tokens (最大允许: 1808)
2025-12-25 11:03:14,015 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8664 tokens (最大允许: 1808)
2025-12-25 11:03:14,031 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8595 tokens (最大允许: 1808)
2025-12-25 11:03:14,046 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8602 tokens (最大允许: 1808)
2025-12-25 11:03:14,064 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8698 tokens (最大允许: 1808)
2025-12-25 11:03:14,079 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8760 tokens (最大允许: 1808)
2025-12-25 11:03:14,097 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8540 tokens (最大允许: 1808)
2025-12-25 11:03:14,113 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8710 tokens (最大允许: 1808)
2025-12-25 11:03:14,131 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8823 tokens (最大允许: 1808)
2025-12-25 11:03:14,146 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8808 tokens (最大允许: 1808)
2025-12-25 11:03:14,162 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8582 tokens (最大允许: 1808)
2025-12-25 11:03:14,178 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8762 tokens (最大允许: 1808)
2025-12-25 11:03:14,194 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8792 tokens (最大允许: 1808)
2025-12-25 11:03:14,210 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8671 tokens (最大允许: 1808)
2025-12-25 11:03:14,226 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8707 tokens (最大允许: 1808)
2025-12-25 11:03:14,242 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8537 tokens (最大允许: 1808)
2025-12-25 11:03:14,259 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8767 tokens (最大允许: 1808)
2025-12-25 11:03:14,275 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8583 tokens (最大允许: 1808)
2025-12-25 11:03:14,290 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8614 tokens (最大允许: 1808)
2025-12-25 11:03:14,295 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 2204 tokens (最大允许: 1808)
2025-12-25 11:03:14,312 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8516 tokens (最大允许: 1808)
2025-12-25 11:03:14,330 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8832 tokens (最大允许: 1808)
2025-12-25 11:03:14,348 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8859 tokens (最大允许: 1808)
2025-12-25 11:03:14,365 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8595 tokens (最大允许: 1808)
2025-12-25 11:03:14,381 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8644 tokens (最大允许: 1808)
2025-12-25 11:03:14,397 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8596 tokens (最大允许: 1808)
2025-12-25 11:03:14,397 - inference.local_inference - WARNING - 共跳过 125/128 条超长prompts
2025-12-25 11:05:18,849 - __main__ - INFO - 批次 [257-384] 本地推理完成
2025-12-25 11:05:18,850 - __main__ - INFO - 处理批次 [385-512/99842]
2025-12-25 11:05:18,850 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 11:05:18,850 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 11:05:43,203 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 11:05:43,204 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 11:09:05,661 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 11:09:05,661 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 11:09:05,688 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8545 tokens (最大允许: 1808)
2025-12-25 11:09:05,709 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8798 tokens (最大允许: 1808)
2025-12-25 11:09:05,729 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8802 tokens (最大允许: 1808)
2025-12-25 11:09:05,745 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8795 tokens (最大允许: 1808)
2025-12-25 11:09:05,761 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8574 tokens (最大允许: 1808)
2025-12-25 11:09:05,776 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8578 tokens (最大允许: 1808)
2025-12-25 11:09:05,792 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8523 tokens (最大允许: 1808)
2025-12-25 11:09:05,808 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8527 tokens (最大允许: 1808)
2025-12-25 11:09:05,824 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8605 tokens (最大允许: 1808)
2025-12-25 11:09:05,840 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8605 tokens (最大允许: 1808)
2025-12-25 11:09:05,855 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8563 tokens (最大允许: 1808)
2025-12-25 11:09:05,871 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8579 tokens (最大允许: 1808)
2025-12-25 11:09:05,886 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8556 tokens (最大允许: 1808)
2025-12-25 11:09:05,890 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 1924 tokens (最大允许: 1808)
2025-12-25 11:09:05,906 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:09:05,921 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8632 tokens (最大允许: 1808)
2025-12-25 11:09:05,937 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8619 tokens (最大允许: 1808)
2025-12-25 11:09:05,952 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8621 tokens (最大允许: 1808)
2025-12-25 11:09:05,968 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8803 tokens (最大允许: 1808)
2025-12-25 11:09:05,984 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8495 tokens (最大允许: 1808)
2025-12-25 11:09:06,000 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8565 tokens (最大允许: 1808)
2025-12-25 11:09:06,016 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8605 tokens (最大允许: 1808)
2025-12-25 11:09:06,031 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8586 tokens (最大允许: 1808)
2025-12-25 11:09:06,047 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:09:06,062 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8600 tokens (最大允许: 1808)
2025-12-25 11:09:06,077 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8592 tokens (最大允许: 1808)
2025-12-25 11:09:06,092 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8588 tokens (最大允许: 1808)
2025-12-25 11:09:06,099 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 3375 tokens (最大允许: 1808)
2025-12-25 11:09:06,114 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8841 tokens (最大允许: 1808)
2025-12-25 11:09:06,129 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:09:06,145 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8974 tokens (最大允许: 1808)
2025-12-25 11:09:06,160 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8978 tokens (最大允许: 1808)
2025-12-25 11:09:06,175 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8567 tokens (最大允许: 1808)
2025-12-25 11:09:06,191 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8977 tokens (最大允许: 1808)
2025-12-25 11:09:06,206 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8617 tokens (最大允许: 1808)
2025-12-25 11:09:06,220 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8613 tokens (最大允许: 1808)
2025-12-25 11:09:06,235 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8574 tokens (最大允许: 1808)
2025-12-25 11:09:06,251 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8839 tokens (最大允许: 1808)
2025-12-25 11:09:06,266 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8594 tokens (最大允许: 1808)
2025-12-25 11:09:06,273 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 2310 tokens (最大允许: 1808)
2025-12-25 11:09:06,288 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8623 tokens (最大允许: 1808)
2025-12-25 11:09:06,305 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8616 tokens (最大允许: 1808)
2025-12-25 11:09:06,321 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8803 tokens (最大允许: 1808)
2025-12-25 11:09:06,336 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8596 tokens (最大允许: 1808)
2025-12-25 11:09:06,352 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8628 tokens (最大允许: 1808)
2025-12-25 11:09:06,367 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8836 tokens (最大允许: 1808)
2025-12-25 11:09:06,383 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8579 tokens (最大允许: 1808)
2025-12-25 11:09:06,398 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8552 tokens (最大允许: 1808)
2025-12-25 11:09:06,414 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8588 tokens (最大允许: 1808)
2025-12-25 11:09:06,429 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8975 tokens (最大允许: 1808)
2025-12-25 11:09:06,433 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 1908 tokens (最大允许: 1808)
2025-12-25 11:09:06,447 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:09:06,462 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8635 tokens (最大允许: 1808)
2025-12-25 11:09:06,477 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8661 tokens (最大允许: 1808)
2025-12-25 11:09:06,492 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8586 tokens (最大允许: 1808)
2025-12-25 11:09:06,507 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8576 tokens (最大允许: 1808)
2025-12-25 11:09:06,523 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8575 tokens (最大允许: 1808)
2025-12-25 11:09:06,538 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8576 tokens (最大允许: 1808)
2025-12-25 11:09:06,554 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8633 tokens (最大允许: 1808)
2025-12-25 11:09:06,569 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8608 tokens (最大允许: 1808)
2025-12-25 11:09:06,573 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 2240 tokens (最大允许: 1808)
2025-12-25 11:09:06,588 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8577 tokens (最大允许: 1808)
2025-12-25 11:09:06,603 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:09:06,618 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8534 tokens (最大允许: 1808)
2025-12-25 11:09:06,633 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8543 tokens (最大允许: 1808)
2025-12-25 11:09:06,651 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8573 tokens (最大允许: 1808)
2025-12-25 11:09:06,667 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8642 tokens (最大允许: 1808)
2025-12-25 11:09:06,682 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8623 tokens (最大允许: 1808)
2025-12-25 11:09:06,697 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8576 tokens (最大允许: 1808)
2025-12-25 11:09:06,712 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:09:06,727 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8601 tokens (最大允许: 1808)
2025-12-25 11:09:06,742 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8936 tokens (最大允许: 1808)
2025-12-25 11:09:06,759 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8797 tokens (最大允许: 1808)
2025-12-25 11:09:06,774 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8652 tokens (最大允许: 1808)
2025-12-25 11:09:06,790 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:09:06,805 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8652 tokens (最大允许: 1808)
2025-12-25 11:09:06,820 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8626 tokens (最大允许: 1808)
2025-12-25 11:09:06,836 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8590 tokens (最大允许: 1808)
2025-12-25 11:09:06,839 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 1880 tokens (最大允许: 1808)
2025-12-25 11:09:06,855 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8663 tokens (最大允许: 1808)
2025-12-25 11:09:06,871 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8534 tokens (最大允许: 1808)
2025-12-25 11:09:06,888 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8533 tokens (最大允许: 1808)
2025-12-25 11:09:06,904 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8577 tokens (最大允许: 1808)
2025-12-25 11:09:06,920 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8571 tokens (最大允许: 1808)
2025-12-25 11:09:06,936 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8617 tokens (最大允许: 1808)
2025-12-25 11:09:06,952 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8574 tokens (最大允许: 1808)
2025-12-25 11:09:06,970 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8571 tokens (最大允许: 1808)
2025-12-25 11:09:06,985 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8492 tokens (最大允许: 1808)
2025-12-25 11:09:07,002 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8532 tokens (最大允许: 1808)
2025-12-25 11:09:07,019 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8561 tokens (最大允许: 1808)
2025-12-25 11:09:07,037 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8899 tokens (最大允许: 1808)
2025-12-25 11:09:07,055 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8574 tokens (最大允许: 1808)
2025-12-25 11:09:07,071 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8489 tokens (最大允许: 1808)
2025-12-25 11:09:07,078 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 3454 tokens (最大允许: 1808)
2025-12-25 11:09:07,095 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8605 tokens (最大允许: 1808)
2025-12-25 11:09:07,112 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8536 tokens (最大允许: 1808)
2025-12-25 11:09:07,128 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8615 tokens (最大允许: 1808)
2025-12-25 11:09:07,144 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8595 tokens (最大允许: 1808)
2025-12-25 11:09:07,160 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8558 tokens (最大允许: 1808)
2025-12-25 11:09:07,176 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8605 tokens (最大允许: 1808)
2025-12-25 11:09:07,191 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8573 tokens (最大允许: 1808)
2025-12-25 11:09:07,207 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8575 tokens (最大允许: 1808)
2025-12-25 11:09:07,222 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8553 tokens (最大允许: 1808)
2025-12-25 11:09:07,238 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8620 tokens (最大允许: 1808)
2025-12-25 11:09:07,253 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8872 tokens (最大允许: 1808)
2025-12-25 11:09:07,270 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8694 tokens (最大允许: 1808)
2025-12-25 11:09:07,285 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8590 tokens (最大允许: 1808)
2025-12-25 11:09:07,301 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8630 tokens (最大允许: 1808)
2025-12-25 11:09:07,316 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8600 tokens (最大允许: 1808)
2025-12-25 11:09:07,331 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8610 tokens (最大允许: 1808)
2025-12-25 11:09:07,347 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8601 tokens (最大允许: 1808)
2025-12-25 11:09:07,362 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8573 tokens (最大允许: 1808)
2025-12-25 11:09:07,377 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8570 tokens (最大允许: 1808)
2025-12-25 11:09:07,393 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8632 tokens (最大允许: 1808)
2025-12-25 11:09:07,409 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8802 tokens (最大允许: 1808)
2025-12-25 11:09:07,424 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8567 tokens (最大允许: 1808)
2025-12-25 11:09:07,440 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8800 tokens (最大允许: 1808)
2025-12-25 11:09:07,455 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8615 tokens (最大允许: 1808)
2025-12-25 11:09:07,471 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8695 tokens (最大允许: 1808)
2025-12-25 11:09:07,487 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8646 tokens (最大允许: 1808)
2025-12-25 11:09:07,502 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8583 tokens (最大允许: 1808)
2025-12-25 11:09:07,506 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 2718 tokens (最大允许: 1808)
2025-12-25 11:09:07,521 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8738 tokens (最大允许: 1808)
2025-12-25 11:09:07,536 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8540 tokens (最大允许: 1808)
2025-12-25 11:09:07,537 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 11:11:18,728 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 11:11:18,729 - __main__ - INFO - 处理批次 [129-187/187]
2025-12-25 11:11:18,729 - __main__ - INFO -   → 生成Baseline答案 (59 条)...
2025-12-25 11:11:18,729 - __main__ - INFO - 批量生成Baseline答案: 59 条
2025-12-25 11:11:29,377 - __main__ - INFO -   → 生成差异分析 (59 条)...
2025-12-25 11:11:29,378 - __main__ - INFO - 批量生成差异分析: 59 条
2025-12-25 11:16:04,756 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 11:16:04,756 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 11:16:04,781 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8606 tokens (最大允许: 1808)
2025-12-25 11:16:04,801 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8587 tokens (最大允许: 1808)
2025-12-25 11:16:04,819 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8784 tokens (最大允许: 1808)
2025-12-25 11:16:04,838 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8652 tokens (最大允许: 1808)
2025-12-25 11:16:04,855 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8658 tokens (最大允许: 1808)
2025-12-25 11:16:04,871 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8660 tokens (最大允许: 1808)
2025-12-25 11:16:04,887 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8763 tokens (最大允许: 1808)
2025-12-25 11:16:04,904 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8538 tokens (最大允许: 1808)
2025-12-25 11:16:04,919 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8534 tokens (最大允许: 1808)
2025-12-25 11:16:04,935 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8547 tokens (最大允许: 1808)
2025-12-25 11:16:04,951 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8637 tokens (最大允许: 1808)
2025-12-25 11:16:04,966 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8507 tokens (最大允许: 1808)
2025-12-25 11:16:04,982 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8536 tokens (最大允许: 1808)
2025-12-25 11:16:04,998 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8575 tokens (最大允许: 1808)
2025-12-25 11:16:05,013 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8764 tokens (最大允许: 1808)
2025-12-25 11:16:05,029 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8629 tokens (最大允许: 1808)
2025-12-25 11:16:05,044 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8603 tokens (最大允许: 1808)
2025-12-25 11:16:05,060 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8572 tokens (最大允许: 1808)
2025-12-25 11:16:05,076 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8582 tokens (最大允许: 1808)
2025-12-25 11:16:05,092 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8741 tokens (最大允许: 1808)
2025-12-25 11:16:05,108 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8789 tokens (最大允许: 1808)
2025-12-25 11:16:05,125 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8860 tokens (最大允许: 1808)
2025-12-25 11:16:05,141 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8490 tokens (最大允许: 1808)
2025-12-25 11:16:05,157 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8698 tokens (最大允许: 1808)
2025-12-25 11:16:05,173 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8646 tokens (最大允许: 1808)
2025-12-25 11:16:05,189 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8581 tokens (最大允许: 1808)
2025-12-25 11:16:05,205 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8544 tokens (最大允许: 1808)
2025-12-25 11:16:05,221 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8539 tokens (最大允许: 1808)
2025-12-25 11:16:05,236 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8524 tokens (最大允许: 1808)
2025-12-25 11:16:05,251 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8740 tokens (最大允许: 1808)
2025-12-25 11:16:05,266 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8555 tokens (最大允许: 1808)
2025-12-25 11:16:05,283 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8706 tokens (最大允许: 1808)
2025-12-25 11:16:05,300 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8717 tokens (最大允许: 1808)
2025-12-25 11:16:05,317 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8619 tokens (最大允许: 1808)
2025-12-25 11:16:05,334 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8560 tokens (最大允许: 1808)
2025-12-25 11:16:05,352 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8564 tokens (最大允许: 1808)
2025-12-25 11:16:05,369 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8663 tokens (最大允许: 1808)
2025-12-25 11:16:05,385 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8602 tokens (最大允许: 1808)
2025-12-25 11:16:05,402 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8503 tokens (最大允许: 1808)
2025-12-25 11:16:05,417 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8531 tokens (最大允许: 1808)
2025-12-25 11:16:05,433 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8671 tokens (最大允许: 1808)
2025-12-25 11:16:05,448 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8581 tokens (最大允许: 1808)
2025-12-25 11:16:05,464 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8713 tokens (最大允许: 1808)
2025-12-25 11:16:05,483 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8581 tokens (最大允许: 1808)
2025-12-25 11:16:05,499 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8592 tokens (最大允许: 1808)
2025-12-25 11:16:05,515 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8556 tokens (最大允许: 1808)
2025-12-25 11:16:05,531 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8567 tokens (最大允许: 1808)
2025-12-25 11:16:05,548 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8607 tokens (最大允许: 1808)
2025-12-25 11:16:05,563 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8540 tokens (最大允许: 1808)
2025-12-25 11:16:05,579 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8669 tokens (最大允许: 1808)
2025-12-25 11:16:05,595 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8656 tokens (最大允许: 1808)
2025-12-25 11:16:05,611 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8613 tokens (最大允许: 1808)
2025-12-25 11:16:05,627 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8624 tokens (最大允许: 1808)
2025-12-25 11:16:05,646 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8520 tokens (最大允许: 1808)
2025-12-25 11:16:05,664 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8622 tokens (最大允许: 1808)
2025-12-25 11:16:05,682 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8634 tokens (最大允许: 1808)
2025-12-25 11:16:05,699 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8604 tokens (最大允许: 1808)
2025-12-25 11:16:05,717 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8890 tokens (最大允许: 1808)
2025-12-25 11:16:05,724 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 3013 tokens (最大允许: 1808)
2025-12-25 11:16:05,740 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8603 tokens (最大允许: 1808)
2025-12-25 11:16:05,757 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8681 tokens (最大允许: 1808)
2025-12-25 11:16:05,774 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8618 tokens (最大允许: 1808)
2025-12-25 11:16:05,790 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8610 tokens (最大允许: 1808)
2025-12-25 11:16:05,798 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 2406 tokens (最大允许: 1808)
2025-12-25 11:16:05,815 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8672 tokens (最大允许: 1808)
2025-12-25 11:16:05,832 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8668 tokens (最大允许: 1808)
2025-12-25 11:16:05,849 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8786 tokens (最大允许: 1808)
2025-12-25 11:16:05,865 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8540 tokens (最大允许: 1808)
2025-12-25 11:16:05,881 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8684 tokens (最大允许: 1808)
2025-12-25 11:16:05,896 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8513 tokens (最大允许: 1808)
2025-12-25 11:16:05,913 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8649 tokens (最大允许: 1808)
2025-12-25 11:16:05,929 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8616 tokens (最大允许: 1808)
2025-12-25 11:16:05,946 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8670 tokens (最大允许: 1808)
2025-12-25 11:16:05,962 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8679 tokens (最大允许: 1808)
2025-12-25 11:16:05,978 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8678 tokens (最大允许: 1808)
2025-12-25 11:16:05,994 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8656 tokens (最大允许: 1808)
2025-12-25 11:16:06,010 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8776 tokens (最大允许: 1808)
2025-12-25 11:16:06,030 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8867 tokens (最大允许: 1808)
2025-12-25 11:16:06,047 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8873 tokens (最大允许: 1808)
2025-12-25 11:16:06,062 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8650 tokens (最大允许: 1808)
2025-12-25 11:16:06,078 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8693 tokens (最大允许: 1808)
2025-12-25 11:16:06,093 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8569 tokens (最大允许: 1808)
2025-12-25 11:16:06,108 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8545 tokens (最大允许: 1808)
2025-12-25 11:16:06,124 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8595 tokens (最大允许: 1808)
2025-12-25 11:16:06,141 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8583 tokens (最大允许: 1808)
2025-12-25 11:16:06,145 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 2052 tokens (最大允许: 1808)
2025-12-25 11:16:06,160 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8736 tokens (最大允许: 1808)
2025-12-25 11:16:06,177 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8614 tokens (最大允许: 1808)
2025-12-25 11:16:06,193 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8776 tokens (最大允许: 1808)
2025-12-25 11:16:06,209 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8537 tokens (最大允许: 1808)
2025-12-25 11:16:06,217 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 4177 tokens (最大允许: 1808)
2025-12-25 11:16:06,232 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8570 tokens (最大允许: 1808)
2025-12-25 11:16:06,248 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8737 tokens (最大允许: 1808)
2025-12-25 11:16:06,263 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8654 tokens (最大允许: 1808)
2025-12-25 11:16:06,280 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8593 tokens (最大允许: 1808)
2025-12-25 11:16:06,297 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8755 tokens (最大允许: 1808)
2025-12-25 11:16:06,315 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:16:06,332 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8603 tokens (最大允许: 1808)
2025-12-25 11:16:06,349 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8644 tokens (最大允许: 1808)
2025-12-25 11:16:06,366 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8794 tokens (最大允许: 1808)
2025-12-25 11:16:06,383 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8880 tokens (最大允许: 1808)
2025-12-25 11:16:06,399 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8500 tokens (最大允许: 1808)
2025-12-25 11:16:06,416 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8602 tokens (最大允许: 1808)
2025-12-25 11:16:06,432 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8522 tokens (最大允许: 1808)
2025-12-25 11:16:06,448 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8677 tokens (最大允许: 1808)
2025-12-25 11:16:06,464 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8584 tokens (最大允许: 1808)
2025-12-25 11:16:06,480 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8727 tokens (最大允许: 1808)
2025-12-25 11:16:06,484 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 2270 tokens (最大允许: 1808)
2025-12-25 11:16:06,500 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8632 tokens (最大允许: 1808)
2025-12-25 11:16:06,519 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8707 tokens (最大允许: 1808)
2025-12-25 11:16:06,535 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8748 tokens (最大允许: 1808)
2025-12-25 11:16:06,551 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8723 tokens (最大允许: 1808)
2025-12-25 11:16:06,567 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8566 tokens (最大允许: 1808)
2025-12-25 11:16:06,583 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8581 tokens (最大允许: 1808)
2025-12-25 11:16:06,601 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8632 tokens (最大允许: 1808)
2025-12-25 11:16:06,617 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8623 tokens (最大允许: 1808)
2025-12-25 11:16:06,634 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8654 tokens (最大允许: 1808)
2025-12-25 11:16:06,650 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8625 tokens (最大允许: 1808)
2025-12-25 11:16:06,666 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8579 tokens (最大允许: 1808)
2025-12-25 11:16:06,682 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8832 tokens (最大允许: 1808)
2025-12-25 11:16:06,699 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8944 tokens (最大允许: 1808)
2025-12-25 11:16:06,715 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8559 tokens (最大允许: 1808)
2025-12-25 11:16:06,716 - inference.local_inference - WARNING - 共跳过 122/128 条超长prompts
2025-12-25 11:16:57,322 - __main__ - INFO -   → 生成Rejected原则 (59 条)...
2025-12-25 11:16:57,322 - __main__ - INFO - 批量生成原则（弱模型）: 59 条
2025-12-25 11:16:57,348 - inference.local_inference - WARNING - 跳过超长prompt [1/59]: 8547 tokens (最大允许: 1808)
2025-12-25 11:16:57,368 - inference.local_inference - WARNING - 跳过超长prompt [2/59]: 8563 tokens (最大允许: 1808)
2025-12-25 11:16:57,388 - inference.local_inference - WARNING - 跳过超长prompt [3/59]: 8596 tokens (最大允许: 1808)
2025-12-25 11:16:57,405 - inference.local_inference - WARNING - 跳过超长prompt [4/59]: 8581 tokens (最大允许: 1808)
2025-12-25 11:16:57,422 - inference.local_inference - WARNING - 跳过超长prompt [5/59]: 8577 tokens (最大允许: 1808)
2025-12-25 11:16:57,439 - inference.local_inference - WARNING - 跳过超长prompt [6/59]: 8633 tokens (最大允许: 1808)
2025-12-25 11:16:57,456 - inference.local_inference - WARNING - 跳过超长prompt [7/59]: 8595 tokens (最大允许: 1808)
2025-12-25 11:16:57,472 - inference.local_inference - WARNING - 跳过超长prompt [8/59]: 8515 tokens (最大允许: 1808)
2025-12-25 11:16:57,488 - inference.local_inference - WARNING - 跳过超长prompt [9/59]: 8618 tokens (最大允许: 1808)
2025-12-25 11:16:57,504 - inference.local_inference - WARNING - 跳过超长prompt [10/59]: 8945 tokens (最大允许: 1808)
2025-12-25 11:16:57,520 - inference.local_inference - WARNING - 跳过超长prompt [11/59]: 8604 tokens (最大允许: 1808)
2025-12-25 11:16:57,535 - inference.local_inference - WARNING - 跳过超长prompt [12/59]: 8555 tokens (最大允许: 1808)
2025-12-25 11:16:57,552 - inference.local_inference - WARNING - 跳过超长prompt [13/59]: 8574 tokens (最大允许: 1808)
2025-12-25 11:16:57,568 - inference.local_inference - WARNING - 跳过超长prompt [14/59]: 8533 tokens (最大允许: 1808)
2025-12-25 11:16:57,584 - inference.local_inference - WARNING - 跳过超长prompt [15/59]: 8605 tokens (最大允许: 1808)
2025-12-25 11:16:57,600 - inference.local_inference - WARNING - 跳过超长prompt [16/59]: 8571 tokens (最大允许: 1808)
2025-12-25 11:16:57,616 - inference.local_inference - WARNING - 跳过超长prompt [17/59]: 8560 tokens (最大允许: 1808)
2025-12-25 11:16:57,632 - inference.local_inference - WARNING - 跳过超长prompt [18/59]: 8940 tokens (最大允许: 1808)
2025-12-25 11:16:57,648 - inference.local_inference - WARNING - 跳过超长prompt [19/59]: 8677 tokens (最大允许: 1808)
2025-12-25 11:16:57,664 - inference.local_inference - WARNING - 跳过超长prompt [20/59]: 8723 tokens (最大允许: 1808)
2025-12-25 11:16:57,680 - inference.local_inference - WARNING - 跳过超长prompt [21/59]: 8944 tokens (最大允许: 1808)
2025-12-25 11:16:57,697 - inference.local_inference - WARNING - 跳过超长prompt [22/59]: 8602 tokens (最大允许: 1808)
2025-12-25 11:16:57,716 - inference.local_inference - WARNING - 跳过超长prompt [24/59]: 8795 tokens (最大允许: 1808)
2025-12-25 11:16:57,732 - inference.local_inference - WARNING - 跳过超长prompt [25/59]: 8584 tokens (最大允许: 1808)
2025-12-25 11:16:57,740 - inference.local_inference - WARNING - 跳过超长prompt [26/59]: 3923 tokens (最大允许: 1808)
2025-12-25 11:16:57,756 - inference.local_inference - WARNING - 跳过超长prompt [27/59]: 8736 tokens (最大允许: 1808)
2025-12-25 11:16:57,773 - inference.local_inference - WARNING - 跳过超长prompt [28/59]: 8872 tokens (最大允许: 1808)
2025-12-25 11:16:57,789 - inference.local_inference - WARNING - 跳过超长prompt [29/59]: 8634 tokens (最大允许: 1808)
2025-12-25 11:16:57,805 - inference.local_inference - WARNING - 跳过超长prompt [30/59]: 8601 tokens (最大允许: 1808)
2025-12-25 11:16:57,820 - inference.local_inference - WARNING - 跳过超长prompt [31/59]: 8563 tokens (最大允许: 1808)
2025-12-25 11:16:57,835 - inference.local_inference - WARNING - 跳过超长prompt [32/59]: 8640 tokens (最大允许: 1808)
2025-12-25 11:16:57,851 - inference.local_inference - WARNING - 跳过超长prompt [33/59]: 8536 tokens (最大允许: 1808)
2025-12-25 11:16:57,866 - inference.local_inference - WARNING - 跳过超长prompt [34/59]: 8597 tokens (最大允许: 1808)
2025-12-25 11:16:57,882 - inference.local_inference - WARNING - 跳过超长prompt [35/59]: 8548 tokens (最大允许: 1808)
2025-12-25 11:16:57,897 - inference.local_inference - WARNING - 跳过超长prompt [36/59]: 8739 tokens (最大允许: 1808)
2025-12-25 11:16:57,913 - inference.local_inference - WARNING - 跳过超长prompt [37/59]: 8530 tokens (最大允许: 1808)
2025-12-25 11:16:57,929 - inference.local_inference - WARNING - 跳过超长prompt [38/59]: 8622 tokens (最大允许: 1808)
2025-12-25 11:16:57,945 - inference.local_inference - WARNING - 跳过超长prompt [39/59]: 8837 tokens (最大允许: 1808)
2025-12-25 11:16:57,961 - inference.local_inference - WARNING - 跳过超长prompt [40/59]: 8613 tokens (最大允许: 1808)
2025-12-25 11:16:57,976 - inference.local_inference - WARNING - 跳过超长prompt [41/59]: 8553 tokens (最大允许: 1808)
2025-12-25 11:16:57,992 - inference.local_inference - WARNING - 跳过超长prompt [42/59]: 8638 tokens (最大允许: 1808)
2025-12-25 11:16:58,009 - inference.local_inference - WARNING - 跳过超长prompt [43/59]: 8634 tokens (最大允许: 1808)
2025-12-25 11:16:58,026 - inference.local_inference - WARNING - 跳过超长prompt [44/59]: 8594 tokens (最大允许: 1808)
2025-12-25 11:16:58,043 - inference.local_inference - WARNING - 跳过超长prompt [45/59]: 8528 tokens (最大允许: 1808)
2025-12-25 11:16:58,059 - inference.local_inference - WARNING - 跳过超长prompt [46/59]: 8637 tokens (最大允许: 1808)
2025-12-25 11:16:58,075 - inference.local_inference - WARNING - 跳过超长prompt [47/59]: 8522 tokens (最大允许: 1808)
2025-12-25 11:16:58,091 - inference.local_inference - WARNING - 跳过超长prompt [48/59]: 8620 tokens (最大允许: 1808)
2025-12-25 11:16:58,107 - inference.local_inference - WARNING - 跳过超长prompt [49/59]: 8671 tokens (最大允许: 1808)
2025-12-25 11:16:58,123 - inference.local_inference - WARNING - 跳过超长prompt [50/59]: 8487 tokens (最大允许: 1808)
2025-12-25 11:16:58,139 - inference.local_inference - WARNING - 跳过超长prompt [51/59]: 8603 tokens (最大允许: 1808)
2025-12-25 11:16:58,155 - inference.local_inference - WARNING - 跳过超长prompt [52/59]: 8539 tokens (最大允许: 1808)
2025-12-25 11:16:58,171 - inference.local_inference - WARNING - 跳过超长prompt [53/59]: 8531 tokens (最大允许: 1808)
2025-12-25 11:16:58,188 - inference.local_inference - WARNING - 跳过超长prompt [54/59]: 8626 tokens (最大允许: 1808)
2025-12-25 11:16:58,205 - inference.local_inference - WARNING - 跳过超长prompt [55/59]: 8533 tokens (最大允许: 1808)
2025-12-25 11:16:58,222 - inference.local_inference - WARNING - 跳过超长prompt [56/59]: 8584 tokens (最大允许: 1808)
2025-12-25 11:16:58,238 - inference.local_inference - WARNING - 跳过超长prompt [57/59]: 8545 tokens (最大允许: 1808)
2025-12-25 11:16:58,255 - inference.local_inference - WARNING - 跳过超长prompt [58/59]: 8935 tokens (最大允许: 1808)
2025-12-25 11:16:58,271 - inference.local_inference - WARNING - 跳过超长prompt [59/59]: 8803 tokens (最大允许: 1808)
2025-12-25 11:16:58,271 - inference.local_inference - WARNING - 共跳过 58/59 条超长prompts
2025-12-25 11:18:25,873 - __main__ - INFO - 批次 [385-512] 本地推理完成
2025-12-25 11:18:25,873 - __main__ - INFO - 处理批次 [513-640/99842]
2025-12-25 11:18:25,874 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 11:18:25,874 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 11:18:48,406 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 11:18:48,406 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 11:18:54,183 - __main__ - INFO - 批次 [129-187] 本地推理完成
2025-12-25 11:18:54,184 - __main__ - INFO - 阶段1完成: 共生成 187 条本地推理结果
2025-12-25 11:18:54,184 - __main__ - WARNING - ⚠️  182/187 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 11:18:54,185 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 11:18:54,254 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 11:18:54,254 - __main__ - INFO - ============================================================
2025-12-25 11:18:54,254 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 11:18:54,254 - __main__ - INFO - ============================================================
2025-12-25 11:18:54,255 - __main__ - INFO - API分批处理: 每批 30 条，共 7 批
2025-12-25 11:18:54,255 - __main__ - INFO - API批次 [1-30/187] 开始处理...
2025-12-25 11:18:54,255 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:20:14,553 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 11:20:14,555 - __main__ - INFO - API批次 [31-60/187] 开始处理...
2025-12-25 11:20:14,555 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:21:15,852 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 11:21:15,853 - __main__ - INFO - API批次 [61-90/187] 开始处理...
2025-12-25 11:21:15,853 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:21:50,371 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 11:21:50,372 - __main__ - INFO - API批次 [91-120/187] 开始处理...
2025-12-25 11:21:50,372 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:22:21,206 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 11:22:21,206 - __main__ - INFO - API批次 [121-150/187] 开始处理...
2025-12-25 11:22:21,206 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:22:50,233 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 11:22:50,234 - __main__ - INFO - API批次 [151-180/187] 开始处理...
2025-12-25 11:22:50,234 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:23:23,904 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 11:23:23,905 - __main__ - INFO - API批次 [181-187/187] 开始处理...
2025-12-25 11:23:23,905 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:23:48,747 - __main__ - INFO - API批次 [181-187] 完成
2025-12-25 11:23:48,747 - __main__ - INFO - 阶段2完成: 共生成 187 条Chosen结果
2025-12-25 11:23:48,747 - __main__ - INFO - 开始数据质量检查...
2025-12-25 11:23:48,751 - __main__ - INFO - ✅ 数据质量检查通过: 187 条chosen全部非空
2025-12-25 11:23:48,752 - __main__ - INFO - ============================================================
2025-12-25 11:23:48,752 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 11:23:48,752 - __main__ - INFO - ============================================================
2025-12-25 11:23:48,752 - __main__ - INFO - 预检查数据完整性...
2025-12-25 11:23:48,752 - __main__ - INFO - Chosen非空率: 187/187 (100.0%)
2025-12-25 11:23:48,752 - __main__ - INFO - Rejected非空率: 5/187 (2.7%)
2025-12-25 11:23:48,753 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 11:23:48,775 - __main__ - INFO - 已保存 50/187 条到JSONL
2025-12-25 11:23:48,792 - __main__ - INFO - 已保存 100/187 条到JSONL
2025-12-25 11:23:48,812 - __main__ - INFO - 已保存 150/187 条到JSONL
2025-12-25 11:23:48,836 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_causal_judgement.jsonl
2025-12-25 11:23:48,837 - __main__ - INFO - 共保存 187 条数据到JSONL格式
2025-12-25 11:23:52,681 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 11:23:52,713 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 11:23:53,753 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,753 - __main__ - INFO - 数据集名称: bbh
2025-12-25 11:23:53,753 - __main__ - INFO - 数据集路径: dataset/bbh/date_understanding.json
2025-12-25 11:23:53,753 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,753 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 11:23:53,753 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,753 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 11:23:53,753 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/date_understanding.json
2025-12-25 11:23:53,753 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,754 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 11:23:53,754 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 11:23:53,754 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 11:23:53,754 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 11:23:53,754 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,754 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 11:23:53,754 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,754 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 11:23:53,754 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,755 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 11:23:53,755 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 11:23:53,755 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,755 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 11:23:53,755 - __main__ - INFO - ============================================================
2025-12-25 11:23:53,755 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 11:23:53,755 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 11:23:53,755 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 11:23:58,155 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 11:23:58,155 - inference.local_inference - INFO - ============================================================
2025-12-25 11:23:58,155 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 11:23:58,155 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 11:23:58,155 - inference.local_inference - INFO - ============================================================
2025-12-25 11:25:13,143 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 11:27:12,955 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 11:27:12,956 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 11:27:13,049 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8636 tokens (最大允许: 1808)
2025-12-25 11:27:13,138 - inference.local_inference - WARNING - 共跳过 1/128 条超长prompts
2025-12-25 11:29:20,886 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 11:29:20,887 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 11:29:20,914 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8573 tokens (最大允许: 1808)
2025-12-25 11:29:20,934 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8545 tokens (最大允许: 1808)
2025-12-25 11:29:20,953 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8497 tokens (最大允许: 1808)
2025-12-25 11:29:20,970 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8608 tokens (最大允许: 1808)
2025-12-25 11:29:20,987 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8653 tokens (最大允许: 1808)
2025-12-25 11:29:21,003 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8603 tokens (最大允许: 1808)
2025-12-25 11:29:21,019 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8688 tokens (最大允许: 1808)
2025-12-25 11:29:21,034 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8675 tokens (最大允许: 1808)
2025-12-25 11:29:21,050 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8540 tokens (最大允许: 1808)
2025-12-25 11:29:21,066 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8668 tokens (最大允许: 1808)
2025-12-25 11:29:21,082 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8745 tokens (最大允许: 1808)
2025-12-25 11:29:21,099 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8509 tokens (最大允许: 1808)
2025-12-25 11:29:21,116 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8554 tokens (最大允许: 1808)
2025-12-25 11:29:21,132 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8506 tokens (最大允许: 1808)
2025-12-25 11:29:21,150 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8711 tokens (最大允许: 1808)
2025-12-25 11:29:21,167 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8823 tokens (最大允许: 1808)
2025-12-25 11:29:21,184 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8665 tokens (最大允许: 1808)
2025-12-25 11:29:21,200 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8672 tokens (最大允许: 1808)
2025-12-25 11:29:21,217 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8697 tokens (最大允许: 1808)
2025-12-25 11:29:21,233 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8599 tokens (最大允许: 1808)
2025-12-25 11:29:21,248 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8554 tokens (最大允许: 1808)
2025-12-25 11:29:21,264 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8595 tokens (最大允许: 1808)
2025-12-25 11:29:21,281 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8743 tokens (最大允许: 1808)
2025-12-25 11:29:21,297 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8624 tokens (最大允许: 1808)
2025-12-25 11:29:21,314 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8717 tokens (最大允许: 1808)
2025-12-25 11:29:21,331 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8554 tokens (最大允许: 1808)
2025-12-25 11:29:21,348 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8546 tokens (最大允许: 1808)
2025-12-25 11:29:21,364 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8543 tokens (最大允许: 1808)
2025-12-25 11:29:21,369 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 2080 tokens (最大允许: 1808)
2025-12-25 11:29:21,384 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8663 tokens (最大允许: 1808)
2025-12-25 11:29:21,402 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8682 tokens (最大允许: 1808)
2025-12-25 11:29:21,421 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8551 tokens (最大允许: 1808)
2025-12-25 11:29:21,437 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8618 tokens (最大允许: 1808)
2025-12-25 11:29:21,451 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8731 tokens (最大允许: 1808)
2025-12-25 11:29:21,468 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8701 tokens (最大允许: 1808)
2025-12-25 11:29:21,472 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 2178 tokens (最大允许: 1808)
2025-12-25 11:29:21,490 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8586 tokens (最大允许: 1808)
2025-12-25 11:29:21,507 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8593 tokens (最大允许: 1808)
2025-12-25 11:29:21,524 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8753 tokens (最大允许: 1808)
2025-12-25 11:29:21,541 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8899 tokens (最大允许: 1808)
2025-12-25 11:29:21,558 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8649 tokens (最大允许: 1808)
2025-12-25 11:29:21,574 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8722 tokens (最大允许: 1808)
2025-12-25 11:29:21,590 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8636 tokens (最大允许: 1808)
2025-12-25 11:29:21,608 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8676 tokens (最大允许: 1808)
2025-12-25 11:29:21,614 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 3391 tokens (最大允许: 1808)
2025-12-25 11:29:21,630 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8682 tokens (最大允许: 1808)
2025-12-25 11:29:21,646 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8536 tokens (最大允许: 1808)
2025-12-25 11:29:21,662 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8798 tokens (最大允许: 1808)
2025-12-25 11:29:21,678 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8804 tokens (最大允许: 1808)
2025-12-25 11:29:21,694 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8606 tokens (最大允许: 1808)
2025-12-25 11:29:21,710 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8673 tokens (最大允许: 1808)
2025-12-25 11:29:21,726 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8537 tokens (最大允许: 1808)
2025-12-25 11:29:21,742 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8650 tokens (最大允许: 1808)
2025-12-25 11:29:21,763 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8577 tokens (最大允许: 1808)
2025-12-25 11:29:21,768 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 1897 tokens (最大允许: 1808)
2025-12-25 11:29:21,791 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8598 tokens (最大允许: 1808)
2025-12-25 11:29:21,809 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8569 tokens (最大允许: 1808)
2025-12-25 11:29:21,826 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8618 tokens (最大允许: 1808)
2025-12-25 11:29:21,842 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8743 tokens (最大允许: 1808)
2025-12-25 11:29:21,864 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8569 tokens (最大允许: 1808)
2025-12-25 11:29:21,886 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8536 tokens (最大允许: 1808)
2025-12-25 11:29:21,904 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8716 tokens (最大允许: 1808)
2025-12-25 11:29:21,920 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8655 tokens (最大允许: 1808)
2025-12-25 11:29:21,936 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8741 tokens (最大允许: 1808)
2025-12-25 11:29:21,953 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8715 tokens (最大允许: 1808)
2025-12-25 11:29:21,970 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8718 tokens (最大允许: 1808)
2025-12-25 11:29:21,986 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8526 tokens (最大允许: 1808)
2025-12-25 11:29:22,002 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8553 tokens (最大允许: 1808)
2025-12-25 11:29:22,017 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8599 tokens (最大允许: 1808)
2025-12-25 11:29:22,034 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8802 tokens (最大允许: 1808)
2025-12-25 11:29:22,050 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8614 tokens (最大允许: 1808)
2025-12-25 11:29:22,067 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8745 tokens (最大允许: 1808)
2025-12-25 11:29:22,082 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:29:22,098 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8632 tokens (最大允许: 1808)
2025-12-25 11:29:22,114 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8768 tokens (最大允许: 1808)
2025-12-25 11:29:22,130 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8625 tokens (最大允许: 1808)
2025-12-25 11:29:22,147 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8696 tokens (最大允许: 1808)
2025-12-25 11:29:22,164 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8569 tokens (最大允许: 1808)
2025-12-25 11:29:22,181 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8763 tokens (最大允许: 1808)
2025-12-25 11:29:22,198 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8576 tokens (最大允许: 1808)
2025-12-25 11:29:22,215 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8645 tokens (最大允许: 1808)
2025-12-25 11:29:22,232 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8663 tokens (最大允许: 1808)
2025-12-25 11:29:22,249 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8704 tokens (最大允许: 1808)
2025-12-25 11:29:22,266 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8679 tokens (最大允许: 1808)
2025-12-25 11:29:22,283 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8727 tokens (最大允许: 1808)
2025-12-25 11:29:22,299 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8643 tokens (最大允许: 1808)
2025-12-25 11:29:22,315 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8709 tokens (最大允许: 1808)
2025-12-25 11:29:22,333 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8704 tokens (最大允许: 1808)
2025-12-25 11:29:22,351 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8705 tokens (最大允许: 1808)
2025-12-25 11:29:22,368 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8628 tokens (最大允许: 1808)
2025-12-25 11:29:22,384 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8709 tokens (最大允许: 1808)
2025-12-25 11:29:22,401 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8749 tokens (最大允许: 1808)
2025-12-25 11:29:22,405 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 2324 tokens (最大允许: 1808)
2025-12-25 11:29:22,410 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 2681 tokens (最大允许: 1808)
2025-12-25 11:29:22,426 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8564 tokens (最大允许: 1808)
2025-12-25 11:29:22,443 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8757 tokens (最大允许: 1808)
2025-12-25 11:29:22,460 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8638 tokens (最大允许: 1808)
2025-12-25 11:29:22,476 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8591 tokens (最大允许: 1808)
2025-12-25 11:29:22,491 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8549 tokens (最大允许: 1808)
2025-12-25 11:29:22,508 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8762 tokens (最大允许: 1808)
2025-12-25 11:29:22,524 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8643 tokens (最大允许: 1808)
2025-12-25 11:29:22,541 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8770 tokens (最大允许: 1808)
2025-12-25 11:29:22,557 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8776 tokens (最大允许: 1808)
2025-12-25 11:29:22,574 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8859 tokens (最大允许: 1808)
2025-12-25 11:29:22,598 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8515 tokens (最大允许: 1808)
2025-12-25 11:29:22,618 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8768 tokens (最大允许: 1808)
2025-12-25 11:29:22,636 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8646 tokens (最大允许: 1808)
2025-12-25 11:29:22,654 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8783 tokens (最大允许: 1808)
2025-12-25 11:29:22,671 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8748 tokens (最大允许: 1808)
2025-12-25 11:29:22,687 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8572 tokens (最大允许: 1808)
2025-12-25 11:29:22,705 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8862 tokens (最大允许: 1808)
2025-12-25 11:29:22,721 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8563 tokens (最大允许: 1808)
2025-12-25 11:29:22,737 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8803 tokens (最大允许: 1808)
2025-12-25 11:29:22,753 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8678 tokens (最大允许: 1808)
2025-12-25 11:29:22,770 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8737 tokens (最大允许: 1808)
2025-12-25 11:29:22,788 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8676 tokens (最大允许: 1808)
2025-12-25 11:29:22,811 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8547 tokens (最大允许: 1808)
2025-12-25 11:29:22,833 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8657 tokens (最大允许: 1808)
2025-12-25 11:29:22,852 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8841 tokens (最大允许: 1808)
2025-12-25 11:29:22,869 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8805 tokens (最大允许: 1808)
2025-12-25 11:29:22,886 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8858 tokens (最大允许: 1808)
2025-12-25 11:29:22,906 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8540 tokens (最大允许: 1808)
2025-12-25 11:29:22,927 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8578 tokens (最大允许: 1808)
2025-12-25 11:29:22,948 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8559 tokens (最大允许: 1808)
2025-12-25 11:29:22,965 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8665 tokens (最大允许: 1808)
2025-12-25 11:29:22,982 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8759 tokens (最大允许: 1808)
2025-12-25 11:29:22,982 - inference.local_inference - WARNING - 共跳过 126/128 条超长prompts
2025-12-25 11:31:27,412 - __main__ - INFO - 批次 [513-640] 本地推理完成
2025-12-25 11:31:27,413 - __main__ - INFO - 处理批次 [641-768/99842]
2025-12-25 11:31:27,413 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 11:31:27,413 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 11:31:50,531 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 11:31:50,531 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 11:36:05,840 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 11:36:05,841 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 11:36:05,865 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8514 tokens (最大允许: 1808)
2025-12-25 11:36:05,884 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8539 tokens (最大允许: 1808)
2025-12-25 11:36:05,890 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 2646 tokens (最大允许: 1808)
2025-12-25 11:36:05,907 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8534 tokens (最大允许: 1808)
2025-12-25 11:36:05,924 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8530 tokens (最大允许: 1808)
2025-12-25 11:36:05,940 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8542 tokens (最大允许: 1808)
2025-12-25 11:36:05,955 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8537 tokens (最大允许: 1808)
2025-12-25 11:36:05,973 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8517 tokens (最大允许: 1808)
2025-12-25 11:36:05,990 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8536 tokens (最大允许: 1808)
2025-12-25 11:36:06,006 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8532 tokens (最大允许: 1808)
2025-12-25 11:36:06,021 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8541 tokens (最大允许: 1808)
2025-12-25 11:36:06,034 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8530 tokens (最大允许: 1808)
2025-12-25 11:36:06,048 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8520 tokens (最大允许: 1808)
2025-12-25 11:36:06,063 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8532 tokens (最大允许: 1808)
2025-12-25 11:36:06,078 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8520 tokens (最大允许: 1808)
2025-12-25 11:36:06,093 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8530 tokens (最大允许: 1808)
2025-12-25 11:36:06,107 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8525 tokens (最大允许: 1808)
2025-12-25 11:36:06,121 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:36:06,137 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8515 tokens (最大允许: 1808)
2025-12-25 11:36:06,143 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 3511 tokens (最大允许: 1808)
2025-12-25 11:36:06,157 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8530 tokens (最大允许: 1808)
2025-12-25 11:36:06,170 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8503 tokens (最大允许: 1808)
2025-12-25 11:36:06,174 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 2631 tokens (最大允许: 1808)
2025-12-25 11:36:06,188 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8538 tokens (最大允许: 1808)
2025-12-25 11:36:06,203 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8524 tokens (最大允许: 1808)
2025-12-25 11:36:06,219 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8529 tokens (最大允许: 1808)
2025-12-25 11:36:06,237 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8519 tokens (最大允许: 1808)
2025-12-25 11:36:06,253 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8539 tokens (最大允许: 1808)
2025-12-25 11:36:06,269 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8536 tokens (最大允许: 1808)
2025-12-25 11:36:06,283 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8534 tokens (最大允许: 1808)
2025-12-25 11:36:06,299 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8538 tokens (最大允许: 1808)
2025-12-25 11:36:06,313 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8522 tokens (最大允许: 1808)
2025-12-25 11:36:06,328 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8533 tokens (最大允许: 1808)
2025-12-25 11:36:06,343 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8518 tokens (最大允许: 1808)
2025-12-25 11:36:06,346 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 2073 tokens (最大允许: 1808)
2025-12-25 11:36:06,360 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8541 tokens (最大允许: 1808)
2025-12-25 11:36:06,375 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8543 tokens (最大允许: 1808)
2025-12-25 11:36:06,390 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8520 tokens (最大允许: 1808)
2025-12-25 11:36:06,407 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8541 tokens (最大允许: 1808)
2025-12-25 11:36:06,419 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8511 tokens (最大允许: 1808)
2025-12-25 11:36:06,433 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8516 tokens (最大允许: 1808)
2025-12-25 11:36:06,448 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8514 tokens (最大允许: 1808)
2025-12-25 11:36:06,463 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8531 tokens (最大允许: 1808)
2025-12-25 11:36:06,477 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8535 tokens (最大允许: 1808)
2025-12-25 11:36:06,491 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8515 tokens (最大允许: 1808)
2025-12-25 11:36:06,506 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8511 tokens (最大允许: 1808)
2025-12-25 11:36:06,525 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8520 tokens (最大允许: 1808)
2025-12-25 11:36:06,540 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8545 tokens (最大允许: 1808)
2025-12-25 11:36:06,552 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8506 tokens (最大允许: 1808)
2025-12-25 11:36:06,555 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 1841 tokens (最大允许: 1808)
2025-12-25 11:36:06,570 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8515 tokens (最大允许: 1808)
2025-12-25 11:36:06,584 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8534 tokens (最大允许: 1808)
2025-12-25 11:36:06,600 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8539 tokens (最大允许: 1808)
2025-12-25 11:36:06,612 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8518 tokens (最大允许: 1808)
2025-12-25 11:36:06,627 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8521 tokens (最大允许: 1808)
2025-12-25 11:36:06,631 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 2549 tokens (最大允许: 1808)
2025-12-25 11:36:06,644 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8520 tokens (最大允许: 1808)
2025-12-25 11:36:06,657 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8525 tokens (最大允许: 1808)
2025-12-25 11:36:06,672 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8531 tokens (最大允许: 1808)
2025-12-25 11:36:06,688 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8533 tokens (最大允许: 1808)
2025-12-25 11:36:06,702 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8523 tokens (最大允许: 1808)
2025-12-25 11:36:06,707 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 2797 tokens (最大允许: 1808)
2025-12-25 11:36:06,721 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8530 tokens (最大允许: 1808)
2025-12-25 11:36:06,736 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:36:06,750 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8526 tokens (最大允许: 1808)
2025-12-25 11:36:06,767 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8520 tokens (最大允许: 1808)
2025-12-25 11:36:06,782 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8522 tokens (最大允许: 1808)
2025-12-25 11:36:06,795 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8522 tokens (最大允许: 1808)
2025-12-25 11:36:06,811 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8522 tokens (最大允许: 1808)
2025-12-25 11:36:06,825 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8521 tokens (最大允许: 1808)
2025-12-25 11:36:06,840 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8507 tokens (最大允许: 1808)
2025-12-25 11:36:06,855 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8517 tokens (最大允许: 1808)
2025-12-25 11:36:06,868 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8514 tokens (最大允许: 1808)
2025-12-25 11:36:06,883 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8518 tokens (最大允许: 1808)
2025-12-25 11:36:06,898 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8534 tokens (最大允许: 1808)
2025-12-25 11:36:06,914 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8541 tokens (最大允许: 1808)
2025-12-25 11:36:06,928 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8514 tokens (最大允许: 1808)
2025-12-25 11:36:06,943 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8526 tokens (最大允许: 1808)
2025-12-25 11:36:06,958 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8535 tokens (最大允许: 1808)
2025-12-25 11:36:06,976 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8531 tokens (最大允许: 1808)
2025-12-25 11:36:06,992 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8523 tokens (最大允许: 1808)
2025-12-25 11:36:07,006 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8530 tokens (最大允许: 1808)
2025-12-25 11:36:07,009 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 2308 tokens (最大允许: 1808)
2025-12-25 11:36:07,024 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:36:07,040 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8523 tokens (最大允许: 1808)
2025-12-25 11:36:07,055 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8535 tokens (最大允许: 1808)
2025-12-25 11:36:07,068 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8538 tokens (最大允许: 1808)
2025-12-25 11:36:07,083 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8517 tokens (最大允许: 1808)
2025-12-25 11:36:07,099 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8535 tokens (最大允许: 1808)
2025-12-25 11:36:07,114 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8518 tokens (最大允许: 1808)
2025-12-25 11:36:07,129 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8533 tokens (最大允许: 1808)
2025-12-25 11:36:07,143 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8535 tokens (最大允许: 1808)
2025-12-25 11:36:07,158 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:36:07,173 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:36:07,187 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8529 tokens (最大允许: 1808)
2025-12-25 11:36:07,192 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 2891 tokens (最大允许: 1808)
2025-12-25 11:36:07,207 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8531 tokens (最大允许: 1808)
2025-12-25 11:36:07,219 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8518 tokens (最大允许: 1808)
2025-12-25 11:36:07,234 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8521 tokens (最大允许: 1808)
2025-12-25 11:36:07,249 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8525 tokens (最大允许: 1808)
2025-12-25 11:36:07,263 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8521 tokens (最大允许: 1808)
2025-12-25 11:36:07,278 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8503 tokens (最大允许: 1808)
2025-12-25 11:36:07,292 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8525 tokens (最大允许: 1808)
2025-12-25 11:36:07,306 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8524 tokens (最大允许: 1808)
2025-12-25 11:36:07,324 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8531 tokens (最大允许: 1808)
2025-12-25 11:36:07,331 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 4723 tokens (最大允许: 1808)
2025-12-25 11:36:07,345 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:36:07,359 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8543 tokens (最大允许: 1808)
2025-12-25 11:36:07,372 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8531 tokens (最大允许: 1808)
2025-12-25 11:36:07,387 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8528 tokens (最大允许: 1808)
2025-12-25 11:36:07,403 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8542 tokens (最大允许: 1808)
2025-12-25 11:36:07,417 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8527 tokens (最大允许: 1808)
2025-12-25 11:36:07,436 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8515 tokens (最大允许: 1808)
2025-12-25 11:36:07,440 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 2556 tokens (最大允许: 1808)
2025-12-25 11:36:07,455 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8525 tokens (最大允许: 1808)
2025-12-25 11:36:07,470 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8507 tokens (最大允许: 1808)
2025-12-25 11:36:07,470 - inference.local_inference - WARNING - 共跳过 116/128 条超长prompts
2025-12-25 11:38:40,750 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 11:38:40,751 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 11:38:40,751 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 11:38:40,751 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 11:40:40,581 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 11:40:40,582 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 11:40:40,728 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8640 tokens (最大允许: 1808)
2025-12-25 11:40:40,745 - inference.local_inference - WARNING - 共跳过 1/122 条超长prompts
2025-12-25 11:42:13,064 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 11:42:13,064 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 11:42:13,089 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8546 tokens (最大允许: 1808)
2025-12-25 11:42:13,109 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8683 tokens (最大允许: 1808)
2025-12-25 11:42:13,127 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8583 tokens (最大允许: 1808)
2025-12-25 11:42:13,143 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8573 tokens (最大允许: 1808)
2025-12-25 11:42:13,160 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8752 tokens (最大允许: 1808)
2025-12-25 11:42:13,176 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8682 tokens (最大允许: 1808)
2025-12-25 11:42:13,191 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8561 tokens (最大允许: 1808)
2025-12-25 11:42:13,208 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8646 tokens (最大允许: 1808)
2025-12-25 11:42:13,225 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8738 tokens (最大允许: 1808)
2025-12-25 11:42:13,243 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8767 tokens (最大允许: 1808)
2025-12-25 11:42:13,258 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8739 tokens (最大允许: 1808)
2025-12-25 11:42:13,274 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8594 tokens (最大允许: 1808)
2025-12-25 11:42:13,279 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 2148 tokens (最大允许: 1808)
2025-12-25 11:42:13,294 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8563 tokens (最大允许: 1808)
2025-12-25 11:42:13,311 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8792 tokens (最大允许: 1808)
2025-12-25 11:42:13,327 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8659 tokens (最大允许: 1808)
2025-12-25 11:42:13,343 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8608 tokens (最大允许: 1808)
2025-12-25 11:42:13,361 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8795 tokens (最大允许: 1808)
2025-12-25 11:42:13,377 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8688 tokens (最大允许: 1808)
2025-12-25 11:42:13,393 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8596 tokens (最大允许: 1808)
2025-12-25 11:42:13,409 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8550 tokens (最大允许: 1808)
2025-12-25 11:42:13,424 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8667 tokens (最大允许: 1808)
2025-12-25 11:42:13,441 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8635 tokens (最大允许: 1808)
2025-12-25 11:42:13,459 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8705 tokens (最大允许: 1808)
2025-12-25 11:42:13,475 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8707 tokens (最大允许: 1808)
2025-12-25 11:42:13,491 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8569 tokens (最大允许: 1808)
2025-12-25 11:42:13,507 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8567 tokens (最大允许: 1808)
2025-12-25 11:42:13,524 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8637 tokens (最大允许: 1808)
2025-12-25 11:42:13,542 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8665 tokens (最大允许: 1808)
2025-12-25 11:42:13,560 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8557 tokens (最大允许: 1808)
2025-12-25 11:42:13,577 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8720 tokens (最大允许: 1808)
2025-12-25 11:42:13,593 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8660 tokens (最大允许: 1808)
2025-12-25 11:42:13,609 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8654 tokens (最大允许: 1808)
2025-12-25 11:42:13,626 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8670 tokens (最大允许: 1808)
2025-12-25 11:42:13,643 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8580 tokens (最大允许: 1808)
2025-12-25 11:42:13,660 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8638 tokens (最大允许: 1808)
2025-12-25 11:42:13,677 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8621 tokens (最大允许: 1808)
2025-12-25 11:42:13,694 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8616 tokens (最大允许: 1808)
2025-12-25 11:42:13,711 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8848 tokens (最大允许: 1808)
2025-12-25 11:42:13,727 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8537 tokens (最大允许: 1808)
2025-12-25 11:42:13,743 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8815 tokens (最大允许: 1808)
2025-12-25 11:42:13,759 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8572 tokens (最大允许: 1808)
2025-12-25 11:42:13,775 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8794 tokens (最大允许: 1808)
2025-12-25 11:42:13,792 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8744 tokens (最大允许: 1808)
2025-12-25 11:42:13,809 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8718 tokens (最大允许: 1808)
2025-12-25 11:42:13,825 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8646 tokens (最大允许: 1808)
2025-12-25 11:42:13,844 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8651 tokens (最大允许: 1808)
2025-12-25 11:42:13,864 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8669 tokens (最大允许: 1808)
2025-12-25 11:42:13,884 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8753 tokens (最大允许: 1808)
2025-12-25 11:42:13,907 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8599 tokens (最大允许: 1808)
2025-12-25 11:42:13,926 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8883 tokens (最大允许: 1808)
2025-12-25 11:42:13,942 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8592 tokens (最大允许: 1808)
2025-12-25 11:42:13,947 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 2477 tokens (最大允许: 1808)
2025-12-25 11:42:13,952 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 2496 tokens (最大允许: 1808)
2025-12-25 11:42:13,970 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8765 tokens (最大允许: 1808)
2025-12-25 11:42:13,986 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8592 tokens (最大允许: 1808)
2025-12-25 11:42:14,003 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8795 tokens (最大允许: 1808)
2025-12-25 11:42:14,019 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8667 tokens (最大允许: 1808)
2025-12-25 11:42:14,037 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8521 tokens (最大允许: 1808)
2025-12-25 11:42:14,054 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8566 tokens (最大允许: 1808)
2025-12-25 11:42:14,072 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8691 tokens (最大允许: 1808)
2025-12-25 11:42:14,089 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8748 tokens (最大允许: 1808)
2025-12-25 11:42:14,106 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8749 tokens (最大允许: 1808)
2025-12-25 11:42:14,123 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8582 tokens (最大允许: 1808)
2025-12-25 11:42:14,140 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8738 tokens (最大允许: 1808)
2025-12-25 11:42:14,155 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8629 tokens (最大允许: 1808)
2025-12-25 11:42:14,171 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8669 tokens (最大允许: 1808)
2025-12-25 11:42:14,187 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8861 tokens (最大允许: 1808)
2025-12-25 11:42:14,201 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8704 tokens (最大允许: 1808)
2025-12-25 11:42:14,217 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8683 tokens (最大允许: 1808)
2025-12-25 11:42:14,225 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 4247 tokens (最大允许: 1808)
2025-12-25 11:42:14,229 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 2284 tokens (最大允许: 1808)
2025-12-25 11:42:14,234 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 2553 tokens (最大允许: 1808)
2025-12-25 11:42:14,250 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8757 tokens (最大允许: 1808)
2025-12-25 11:42:14,256 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 2749 tokens (最大允许: 1808)
2025-12-25 11:42:14,272 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8544 tokens (最大允许: 1808)
2025-12-25 11:42:14,288 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8556 tokens (最大允许: 1808)
2025-12-25 11:42:14,305 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8555 tokens (最大允许: 1808)
2025-12-25 11:42:14,323 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8925 tokens (最大允许: 1808)
2025-12-25 11:42:14,327 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 2066 tokens (最大允许: 1808)
2025-12-25 11:42:14,344 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8668 tokens (最大允许: 1808)
2025-12-25 11:42:14,360 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8537 tokens (最大允许: 1808)
2025-12-25 11:42:14,376 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8584 tokens (最大允许: 1808)
2025-12-25 11:42:14,394 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8801 tokens (最大允许: 1808)
2025-12-25 11:42:14,411 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8596 tokens (最大允许: 1808)
2025-12-25 11:42:14,429 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8777 tokens (最大允许: 1808)
2025-12-25 11:42:14,446 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8770 tokens (最大允许: 1808)
2025-12-25 11:42:14,461 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8521 tokens (最大允许: 1808)
2025-12-25 11:42:14,478 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8631 tokens (最大允许: 1808)
2025-12-25 11:42:14,494 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8631 tokens (最大允许: 1808)
2025-12-25 11:42:14,510 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8542 tokens (最大允许: 1808)
2025-12-25 11:42:14,527 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8791 tokens (最大允许: 1808)
2025-12-25 11:42:14,543 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8767 tokens (最大允许: 1808)
2025-12-25 11:42:14,559 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8617 tokens (最大允许: 1808)
2025-12-25 11:42:14,575 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8603 tokens (最大允许: 1808)
2025-12-25 11:42:14,590 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8623 tokens (最大允许: 1808)
2025-12-25 11:42:14,605 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8582 tokens (最大允许: 1808)
2025-12-25 11:42:14,622 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8757 tokens (最大允许: 1808)
2025-12-25 11:42:14,637 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8676 tokens (最大允许: 1808)
2025-12-25 11:42:14,643 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 2885 tokens (最大允许: 1808)
2025-12-25 11:42:14,658 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8591 tokens (最大允许: 1808)
2025-12-25 11:42:14,674 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8647 tokens (最大允许: 1808)
2025-12-25 11:42:14,689 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8533 tokens (最大允许: 1808)
2025-12-25 11:42:14,706 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8807 tokens (最大允许: 1808)
2025-12-25 11:42:14,722 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8676 tokens (最大允许: 1808)
2025-12-25 11:42:14,738 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8611 tokens (最大允许: 1808)
2025-12-25 11:42:14,754 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8564 tokens (最大允许: 1808)
2025-12-25 11:42:14,770 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8691 tokens (最大允许: 1808)
2025-12-25 11:42:14,785 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8555 tokens (最大允许: 1808)
2025-12-25 11:42:14,789 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 1925 tokens (最大允许: 1808)
2025-12-25 11:42:14,805 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8628 tokens (最大允许: 1808)
2025-12-25 11:42:14,821 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8544 tokens (最大允许: 1808)
2025-12-25 11:42:14,837 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8697 tokens (最大允许: 1808)
2025-12-25 11:42:14,853 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8640 tokens (最大允许: 1808)
2025-12-25 11:42:14,873 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8746 tokens (最大允许: 1808)
2025-12-25 11:42:14,894 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8596 tokens (最大允许: 1808)
2025-12-25 11:42:14,913 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8553 tokens (最大允许: 1808)
2025-12-25 11:42:14,936 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8649 tokens (最大允许: 1808)
2025-12-25 11:42:14,957 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8595 tokens (最大允许: 1808)
2025-12-25 11:42:14,978 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8621 tokens (最大允许: 1808)
2025-12-25 11:42:14,997 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8544 tokens (最大允许: 1808)
2025-12-25 11:42:15,013 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8590 tokens (最大允许: 1808)
2025-12-25 11:42:15,029 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8679 tokens (最大允许: 1808)
2025-12-25 11:42:15,046 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8535 tokens (最大允许: 1808)
2025-12-25 11:42:15,063 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8529 tokens (最大允许: 1808)
2025-12-25 11:42:15,079 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8555 tokens (最大允许: 1808)
2025-12-25 11:42:15,094 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8651 tokens (最大允许: 1808)
2025-12-25 11:42:15,094 - inference.local_inference - WARNING - 共跳过 127/128 条超长prompts
2025-12-25 11:44:11,087 - __main__ - INFO - 批次 [641-768] 本地推理完成
2025-12-25 11:44:11,088 - __main__ - INFO - 处理批次 [769-896/99842]
2025-12-25 11:44:11,088 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 11:44:11,088 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 11:44:33,249 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 11:44:33,249 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 11:48:36,243 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 11:48:36,244 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 11:48:36,269 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8538 tokens (最大允许: 1808)
2025-12-25 11:48:36,287 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8528 tokens (最大允许: 1808)
2025-12-25 11:48:36,306 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8525 tokens (最大允许: 1808)
2025-12-25 11:48:36,323 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8520 tokens (最大允许: 1808)
2025-12-25 11:48:36,338 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8541 tokens (最大允许: 1808)
2025-12-25 11:48:36,354 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8523 tokens (最大允许: 1808)
2025-12-25 11:48:36,370 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8534 tokens (最大允许: 1808)
2025-12-25 11:48:36,386 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8531 tokens (最大允许: 1808)
2025-12-25 11:48:36,402 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8529 tokens (最大允许: 1808)
2025-12-25 11:48:36,405 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 1859 tokens (最大允许: 1808)
2025-12-25 11:48:36,422 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8526 tokens (最大允许: 1808)
2025-12-25 11:48:36,438 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8521 tokens (最大允许: 1808)
2025-12-25 11:48:36,455 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 8517 tokens (最大允许: 1808)
2025-12-25 11:48:36,463 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 4831 tokens (最大允许: 1808)
2025-12-25 11:48:36,480 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8521 tokens (最大允许: 1808)
2025-12-25 11:48:36,495 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8526 tokens (最大允许: 1808)
2025-12-25 11:48:36,511 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8508 tokens (最大允许: 1808)
2025-12-25 11:48:36,527 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8535 tokens (最大允许: 1808)
2025-12-25 11:48:36,540 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8505 tokens (最大允许: 1808)
2025-12-25 11:48:36,555 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8542 tokens (最大允许: 1808)
2025-12-25 11:48:36,570 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8530 tokens (最大允许: 1808)
2025-12-25 11:48:36,576 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 2028 tokens (最大允许: 1808)
2025-12-25 11:48:36,591 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8531 tokens (最大允许: 1808)
2025-12-25 11:48:36,606 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8525 tokens (最大允许: 1808)
2025-12-25 11:48:36,621 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8528 tokens (最大允许: 1808)
2025-12-25 11:48:36,636 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8535 tokens (最大允许: 1808)
2025-12-25 11:48:36,641 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 3374 tokens (最大允许: 1808)
2025-12-25 11:48:36,656 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8521 tokens (最大允许: 1808)
2025-12-25 11:48:36,670 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8548 tokens (最大允许: 1808)
2025-12-25 11:48:36,685 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8530 tokens (最大允许: 1808)
2025-12-25 11:48:36,699 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8520 tokens (最大允许: 1808)
2025-12-25 11:48:36,713 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8520 tokens (最大允许: 1808)
2025-12-25 11:48:36,717 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 2449 tokens (最大允许: 1808)
2025-12-25 11:48:36,736 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8517 tokens (最大允许: 1808)
2025-12-25 11:48:36,750 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8530 tokens (最大允许: 1808)
2025-12-25 11:48:36,765 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 8523 tokens (最大允许: 1808)
2025-12-25 11:48:36,780 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8518 tokens (最大允许: 1808)
2025-12-25 11:48:36,795 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8534 tokens (最大允许: 1808)
2025-12-25 11:48:36,800 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 1814 tokens (最大允许: 1808)
2025-12-25 11:48:36,814 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8529 tokens (最大允许: 1808)
2025-12-25 11:48:36,829 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8528 tokens (最大允许: 1808)
2025-12-25 11:48:36,843 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8535 tokens (最大允许: 1808)
2025-12-25 11:48:36,857 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8514 tokens (最大允许: 1808)
2025-12-25 11:48:36,874 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8528 tokens (最大允许: 1808)
2025-12-25 11:48:36,888 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8521 tokens (最大允许: 1808)
2025-12-25 11:48:36,903 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8513 tokens (最大允许: 1808)
2025-12-25 11:48:36,918 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8534 tokens (最大允许: 1808)
2025-12-25 11:48:36,933 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8530 tokens (最大允许: 1808)
2025-12-25 11:48:36,947 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8516 tokens (最大允许: 1808)
2025-12-25 11:48:36,962 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8519 tokens (最大允许: 1808)
2025-12-25 11:48:36,976 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8525 tokens (最大允许: 1808)
2025-12-25 11:48:36,991 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8525 tokens (最大允许: 1808)
2025-12-25 11:48:37,005 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8521 tokens (最大允许: 1808)
2025-12-25 11:48:37,020 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8502 tokens (最大允许: 1808)
2025-12-25 11:48:37,028 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 4867 tokens (最大允许: 1808)
2025-12-25 11:48:37,042 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8528 tokens (最大允许: 1808)
2025-12-25 11:48:37,056 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8518 tokens (最大允许: 1808)
2025-12-25 11:48:37,071 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8537 tokens (最大允许: 1808)
2025-12-25 11:48:37,086 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8526 tokens (最大允许: 1808)
2025-12-25 11:48:37,089 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 2051 tokens (最大允许: 1808)
2025-12-25 11:48:37,102 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8530 tokens (最大允许: 1808)
2025-12-25 11:48:37,119 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8520 tokens (最大允许: 1808)
2025-12-25 11:48:37,134 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8526 tokens (最大允许: 1808)
2025-12-25 11:48:37,149 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8510 tokens (最大允许: 1808)
2025-12-25 11:48:37,163 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8531 tokens (最大允许: 1808)
2025-12-25 11:48:37,178 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8541 tokens (最大允许: 1808)
2025-12-25 11:48:37,192 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8514 tokens (最大允许: 1808)
2025-12-25 11:48:37,208 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8524 tokens (最大允许: 1808)
2025-12-25 11:48:37,222 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8524 tokens (最大允许: 1808)
2025-12-25 11:48:37,226 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 2670 tokens (最大允许: 1808)
2025-12-25 11:48:37,242 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8524 tokens (最大允许: 1808)
2025-12-25 11:48:37,258 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8519 tokens (最大允许: 1808)
2025-12-25 11:48:37,262 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 2173 tokens (最大允许: 1808)
2025-12-25 11:48:37,276 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8534 tokens (最大允许: 1808)
2025-12-25 11:48:37,290 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8534 tokens (最大允许: 1808)
2025-12-25 11:48:37,299 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 5484 tokens (最大允许: 1808)
2025-12-25 11:48:37,313 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8524 tokens (最大允许: 1808)
2025-12-25 11:48:37,329 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8533 tokens (最大允许: 1808)
2025-12-25 11:48:37,344 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8531 tokens (最大允许: 1808)
2025-12-25 11:48:37,358 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8525 tokens (最大允许: 1808)
2025-12-25 11:48:37,373 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8525 tokens (最大允许: 1808)
2025-12-25 11:48:37,386 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8540 tokens (最大允许: 1808)
2025-12-25 11:48:37,402 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8526 tokens (最大允许: 1808)
2025-12-25 11:48:37,417 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8542 tokens (最大允许: 1808)
2025-12-25 11:48:37,432 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8519 tokens (最大允许: 1808)
2025-12-25 11:48:37,446 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8532 tokens (最大允许: 1808)
2025-12-25 11:48:37,463 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8541 tokens (最大允许: 1808)
2025-12-25 11:48:37,476 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8529 tokens (最大允许: 1808)
2025-12-25 11:48:37,480 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 2675 tokens (最大允许: 1808)
2025-12-25 11:48:37,495 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8516 tokens (最大允许: 1808)
2025-12-25 11:48:37,510 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 8519 tokens (最大允许: 1808)
2025-12-25 11:48:37,531 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8517 tokens (最大允许: 1808)
2025-12-25 11:48:37,547 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8518 tokens (最大允许: 1808)
2025-12-25 11:48:37,554 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 4448 tokens (最大允许: 1808)
2025-12-25 11:48:37,569 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8531 tokens (最大允许: 1808)
2025-12-25 11:48:37,583 - inference.local_inference - WARNING - 跳过超长prompt [112/122]: 8543 tokens (最大允许: 1808)
2025-12-25 11:48:37,598 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8525 tokens (最大允许: 1808)
2025-12-25 11:48:37,613 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8503 tokens (最大允许: 1808)
2025-12-25 11:48:37,627 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8505 tokens (最大允许: 1808)
2025-12-25 11:48:37,641 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8526 tokens (最大允许: 1808)
2025-12-25 11:48:37,657 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8531 tokens (最大允许: 1808)
2025-12-25 11:48:37,672 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8523 tokens (最大允许: 1808)
2025-12-25 11:48:37,677 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 3582 tokens (最大允许: 1808)
2025-12-25 11:48:37,695 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8529 tokens (最大允许: 1808)
2025-12-25 11:48:37,710 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8533 tokens (最大允许: 1808)
2025-12-25 11:48:37,710 - inference.local_inference - WARNING - 共跳过 105/122 条超长prompts
2025-12-25 11:51:30,185 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 11:51:30,186 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 11:51:30,186 - __main__ - WARNING - ⚠️  221/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 11:51:30,186 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 11:51:30,277 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 11:51:30,277 - __main__ - INFO - ============================================================
2025-12-25 11:51:30,277 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 11:51:30,277 - __main__ - INFO - ============================================================
2025-12-25 11:51:30,277 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 11:51:30,277 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 11:51:30,277 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:52:17,610 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 11:52:17,611 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 11:52:17,611 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:53:23,627 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 11:53:23,628 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 11:53:23,628 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:54:05,841 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 11:54:05,842 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 11:54:05,842 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:54:52,353 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 11:54:52,353 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 11:54:52,354 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:55:09,845 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 11:55:09,845 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 11:55:09,871 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8756 tokens (最大允许: 1808)
2025-12-25 11:55:09,891 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8795 tokens (最大允许: 1808)
2025-12-25 11:55:09,911 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8739 tokens (最大允许: 1808)
2025-12-25 11:55:09,928 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8638 tokens (最大允许: 1808)
2025-12-25 11:55:09,944 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8675 tokens (最大允许: 1808)
2025-12-25 11:55:09,961 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8679 tokens (最大允许: 1808)
2025-12-25 11:55:09,977 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8559 tokens (最大允许: 1808)
2025-12-25 11:55:09,992 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8577 tokens (最大允许: 1808)
2025-12-25 11:55:10,007 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8568 tokens (最大允许: 1808)
2025-12-25 11:55:10,023 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8758 tokens (最大允许: 1808)
2025-12-25 11:55:10,038 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8718 tokens (最大允许: 1808)
2025-12-25 11:55:10,057 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8714 tokens (最大允许: 1808)
2025-12-25 11:55:10,073 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8712 tokens (最大允许: 1808)
2025-12-25 11:55:10,089 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8661 tokens (最大允许: 1808)
2025-12-25 11:55:10,105 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8603 tokens (最大允许: 1808)
2025-12-25 11:55:10,121 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8655 tokens (最大允许: 1808)
2025-12-25 11:55:10,137 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8764 tokens (最大允许: 1808)
2025-12-25 11:55:10,152 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8739 tokens (最大允许: 1808)
2025-12-25 11:55:10,167 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8716 tokens (最大允许: 1808)
2025-12-25 11:55:10,183 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8749 tokens (最大允许: 1808)
2025-12-25 11:55:10,198 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8497 tokens (最大允许: 1808)
2025-12-25 11:55:10,214 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8630 tokens (最大允许: 1808)
2025-12-25 11:55:10,229 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8655 tokens (最大允许: 1808)
2025-12-25 11:55:10,245 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8698 tokens (最大允许: 1808)
2025-12-25 11:55:10,260 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8664 tokens (最大允许: 1808)
2025-12-25 11:55:10,277 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8607 tokens (最大允许: 1808)
2025-12-25 11:55:10,295 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8723 tokens (最大允许: 1808)
2025-12-25 11:55:10,314 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8647 tokens (最大允许: 1808)
2025-12-25 11:55:10,331 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8729 tokens (最大允许: 1808)
2025-12-25 11:55:10,347 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8651 tokens (最大允许: 1808)
2025-12-25 11:55:10,363 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8724 tokens (最大允许: 1808)
2025-12-25 11:55:10,379 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8604 tokens (最大允许: 1808)
2025-12-25 11:55:10,395 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8598 tokens (最大允许: 1808)
2025-12-25 11:55:10,410 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8690 tokens (最大允许: 1808)
2025-12-25 11:55:10,426 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8692 tokens (最大允许: 1808)
2025-12-25 11:55:10,442 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8769 tokens (最大允许: 1808)
2025-12-25 11:55:10,457 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8631 tokens (最大允许: 1808)
2025-12-25 11:55:10,473 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8599 tokens (最大允许: 1808)
2025-12-25 11:55:10,489 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8516 tokens (最大允许: 1808)
2025-12-25 11:55:10,504 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8522 tokens (最大允许: 1808)
2025-12-25 11:55:10,521 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8799 tokens (最大允许: 1808)
2025-12-25 11:55:10,536 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8630 tokens (最大允许: 1808)
2025-12-25 11:55:10,549 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 7076 tokens (最大允许: 1808)
2025-12-25 11:55:10,566 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8608 tokens (最大允许: 1808)
2025-12-25 11:55:10,584 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8686 tokens (最大允许: 1808)
2025-12-25 11:55:10,604 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8751 tokens (最大允许: 1808)
2025-12-25 11:55:10,620 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8723 tokens (最大允许: 1808)
2025-12-25 11:55:10,636 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8614 tokens (最大允许: 1808)
2025-12-25 11:55:10,651 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8659 tokens (最大允许: 1808)
2025-12-25 11:55:10,666 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8597 tokens (最大允许: 1808)
2025-12-25 11:55:10,682 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8558 tokens (最大允许: 1808)
2025-12-25 11:55:10,698 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8484 tokens (最大允许: 1808)
2025-12-25 11:55:10,715 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8718 tokens (最大允许: 1808)
2025-12-25 11:55:10,730 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8592 tokens (最大允许: 1808)
2025-12-25 11:55:10,747 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8925 tokens (最大允许: 1808)
2025-12-25 11:55:10,762 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8698 tokens (最大允许: 1808)
2025-12-25 11:55:10,778 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8730 tokens (最大允许: 1808)
2025-12-25 11:55:10,794 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8812 tokens (最大允许: 1808)
2025-12-25 11:55:10,810 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8526 tokens (最大允许: 1808)
2025-12-25 11:55:10,826 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8621 tokens (最大允许: 1808)
2025-12-25 11:55:10,843 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8606 tokens (最大允许: 1808)
2025-12-25 11:55:10,860 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8676 tokens (最大允许: 1808)
2025-12-25 11:55:10,877 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8569 tokens (最大允许: 1808)
2025-12-25 11:55:10,893 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8567 tokens (最大允许: 1808)
2025-12-25 11:55:10,911 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8680 tokens (最大允许: 1808)
2025-12-25 11:55:10,932 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8677 tokens (最大允许: 1808)
2025-12-25 11:55:10,952 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8616 tokens (最大允许: 1808)
2025-12-25 11:55:10,955 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 1914 tokens (最大允许: 1808)
2025-12-25 11:55:10,972 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8793 tokens (最大允许: 1808)
2025-12-25 11:55:10,989 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8698 tokens (最大允许: 1808)
2025-12-25 11:55:11,007 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8703 tokens (最大允许: 1808)
2025-12-25 11:55:11,011 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 2174 tokens (最大允许: 1808)
2025-12-25 11:55:11,015 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 2046 tokens (最大允许: 1808)
2025-12-25 11:55:11,031 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8673 tokens (最大允许: 1808)
2025-12-25 11:55:11,047 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8674 tokens (最大允许: 1808)
2025-12-25 11:55:11,062 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8587 tokens (最大允许: 1808)
2025-12-25 11:55:11,083 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8879 tokens (最大允许: 1808)
2025-12-25 11:55:11,099 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8769 tokens (最大允许: 1808)
2025-12-25 11:55:11,115 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8701 tokens (最大允许: 1808)
2025-12-25 11:55:11,131 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8825 tokens (最大允许: 1808)
2025-12-25 11:55:11,148 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8576 tokens (最大允许: 1808)
2025-12-25 11:55:11,163 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8677 tokens (最大允许: 1808)
2025-12-25 11:55:11,178 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8697 tokens (最大允许: 1808)
2025-12-25 11:55:11,194 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8582 tokens (最大允许: 1808)
2025-12-25 11:55:11,210 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8551 tokens (最大允许: 1808)
2025-12-25 11:55:11,226 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8658 tokens (最大允许: 1808)
2025-12-25 11:55:11,241 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8540 tokens (最大允许: 1808)
2025-12-25 11:55:11,256 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8574 tokens (最大允许: 1808)
2025-12-25 11:55:11,274 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8771 tokens (最大允许: 1808)
2025-12-25 11:55:11,292 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8700 tokens (最大允许: 1808)
2025-12-25 11:55:11,310 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8685 tokens (最大允许: 1808)
2025-12-25 11:55:11,327 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8548 tokens (最大允许: 1808)
2025-12-25 11:55:11,343 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8569 tokens (最大允许: 1808)
2025-12-25 11:55:11,360 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8688 tokens (最大允许: 1808)
2025-12-25 11:55:11,377 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8742 tokens (最大允许: 1808)
2025-12-25 11:55:11,393 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8610 tokens (最大允许: 1808)
2025-12-25 11:55:11,410 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8641 tokens (最大允许: 1808)
2025-12-25 11:55:11,426 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8862 tokens (最大允许: 1808)
2025-12-25 11:55:11,442 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8603 tokens (最大允许: 1808)
2025-12-25 11:55:11,458 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8614 tokens (最大允许: 1808)
2025-12-25 11:55:11,474 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8612 tokens (最大允许: 1808)
2025-12-25 11:55:11,489 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8743 tokens (最大允许: 1808)
2025-12-25 11:55:11,506 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8788 tokens (最大允许: 1808)
2025-12-25 11:55:11,521 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8559 tokens (最大允许: 1808)
2025-12-25 11:55:11,537 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8727 tokens (最大允许: 1808)
2025-12-25 11:55:11,553 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8654 tokens (最大允许: 1808)
2025-12-25 11:55:11,568 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8666 tokens (最大允许: 1808)
2025-12-25 11:55:11,584 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8726 tokens (最大允许: 1808)
2025-12-25 11:55:11,599 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8668 tokens (最大允许: 1808)
2025-12-25 11:55:11,615 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8542 tokens (最大允许: 1808)
2025-12-25 11:55:11,630 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8571 tokens (最大允许: 1808)
2025-12-25 11:55:11,646 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8620 tokens (最大允许: 1808)
2025-12-25 11:55:11,661 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8558 tokens (最大允许: 1808)
2025-12-25 11:55:11,677 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8855 tokens (最大允许: 1808)
2025-12-25 11:55:11,693 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8707 tokens (最大允许: 1808)
2025-12-25 11:55:11,710 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8656 tokens (最大允许: 1808)
2025-12-25 11:55:11,725 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8685 tokens (最大允许: 1808)
2025-12-25 11:55:11,741 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8674 tokens (最大允许: 1808)
2025-12-25 11:55:11,757 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8751 tokens (最大允许: 1808)
2025-12-25 11:55:11,773 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8611 tokens (最大允许: 1808)
2025-12-25 11:55:11,789 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8590 tokens (最大允许: 1808)
2025-12-25 11:55:11,805 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8745 tokens (最大允许: 1808)
2025-12-25 11:55:11,821 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8550 tokens (最大允许: 1808)
2025-12-25 11:55:11,838 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8742 tokens (最大允许: 1808)
2025-12-25 11:55:11,838 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 11:56:07,470 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 11:56:07,471 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 11:56:07,471 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:56:40,620 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 11:56:40,621 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 11:56:40,621 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:57:20,354 - __main__ - INFO - 批次 [769-896] 本地推理完成
2025-12-25 11:57:20,354 - __main__ - INFO - 处理批次 [897-1024/99842]
2025-12-25 11:57:20,355 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 11:57:20,355 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 11:57:43,058 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 11:57:43,059 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 11:58:20,854 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 11:58:20,855 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 11:58:20,855 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:58:55,537 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 11:58:55,538 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 11:58:55,538 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 11:59:26,729 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 11:59:26,729 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 11:59:26,729 - __main__ - INFO - 开始数据质量检查...
2025-12-25 11:59:26,729 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 11:59:26,730 - __main__ - INFO - ============================================================
2025-12-25 11:59:26,730 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 11:59:26,730 - __main__ - INFO - ============================================================
2025-12-25 11:59:26,730 - __main__ - INFO - 预检查数据完整性...
2025-12-25 11:59:26,730 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 11:59:26,730 - __main__ - INFO - Rejected非空率: 29/250 (11.6%)
2025-12-25 11:59:26,730 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 11:59:26,753 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 11:59:26,768 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 11:59:26,785 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 11:59:26,798 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 11:59:26,810 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 11:59:26,825 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_date_understanding.jsonl
2025-12-25 11:59:26,825 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 11:59:30,306 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 11:59:30,339 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 11:59:31,345 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,346 - __main__ - INFO - 数据集名称: bbh
2025-12-25 11:59:31,346 - __main__ - INFO - 数据集路径: dataset/bbh/disambiguation_qa.json
2025-12-25 11:59:31,346 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,346 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 11:59:31,346 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,346 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 11:59:31,346 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/disambiguation_qa.json
2025-12-25 11:59:31,346 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,346 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 11:59:31,346 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 11:59:31,346 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 11:59:31,347 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 11:59:31,347 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,347 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 11:59:31,347 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,347 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 11:59:31,347 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,347 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 11:59:31,349 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 11:59:31,349 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,349 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 11:59:31,349 - __main__ - INFO - ============================================================
2025-12-25 11:59:31,349 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 11:59:31,349 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 11:59:31,349 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 11:59:35,706 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 11:59:35,706 - inference.local_inference - INFO - ============================================================
2025-12-25 11:59:35,706 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 11:59:35,706 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 11:59:35,706 - inference.local_inference - INFO - ============================================================
2025-12-25 12:00:51,845 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 12:01:02,028 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 12:01:02,028 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 12:07:50,038 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 12:07:50,038 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 12:07:50,066 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8786 tokens (最大允许: 1808)
2025-12-25 12:07:50,088 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8541 tokens (最大允许: 1808)
2025-12-25 12:07:50,106 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8585 tokens (最大允许: 1808)
2025-12-25 12:07:50,123 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8735 tokens (最大允许: 1808)
2025-12-25 12:07:50,140 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8736 tokens (最大允许: 1808)
2025-12-25 12:07:50,157 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8648 tokens (最大允许: 1808)
2025-12-25 12:07:50,172 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8640 tokens (最大允许: 1808)
2025-12-25 12:07:50,193 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8750 tokens (最大允许: 1808)
2025-12-25 12:07:50,210 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8779 tokens (最大允许: 1808)
2025-12-25 12:07:50,228 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8729 tokens (最大允许: 1808)
2025-12-25 12:07:50,243 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8565 tokens (最大允许: 1808)
2025-12-25 12:07:50,260 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8667 tokens (最大允许: 1808)
2025-12-25 12:07:50,276 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8585 tokens (最大允许: 1808)
2025-12-25 12:07:50,293 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8862 tokens (最大允许: 1808)
2025-12-25 12:07:50,309 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8731 tokens (最大允许: 1808)
2025-12-25 12:07:50,326 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8760 tokens (最大允许: 1808)
2025-12-25 12:07:50,342 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8615 tokens (最大允许: 1808)
2025-12-25 12:07:50,358 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8704 tokens (最大允许: 1808)
2025-12-25 12:07:50,374 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8669 tokens (最大允许: 1808)
2025-12-25 12:07:50,391 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8676 tokens (最大允许: 1808)
2025-12-25 12:07:50,406 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8637 tokens (最大允许: 1808)
2025-12-25 12:07:50,422 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8630 tokens (最大允许: 1808)
2025-12-25 12:07:50,438 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8785 tokens (最大允许: 1808)
2025-12-25 12:07:50,459 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8790 tokens (最大允许: 1808)
2025-12-25 12:07:50,477 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8798 tokens (最大允许: 1808)
2025-12-25 12:07:50,494 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8625 tokens (最大允许: 1808)
2025-12-25 12:07:50,510 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8601 tokens (最大允许: 1808)
2025-12-25 12:07:50,525 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8687 tokens (最大允许: 1808)
2025-12-25 12:07:50,542 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8678 tokens (最大允许: 1808)
2025-12-25 12:07:50,557 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8625 tokens (最大允许: 1808)
2025-12-25 12:07:50,574 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8605 tokens (最大允许: 1808)
2025-12-25 12:07:50,590 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8558 tokens (最大允许: 1808)
2025-12-25 12:07:50,606 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8957 tokens (最大允许: 1808)
2025-12-25 12:07:50,622 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8733 tokens (最大允许: 1808)
2025-12-25 12:07:50,637 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8584 tokens (最大允许: 1808)
2025-12-25 12:07:50,642 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 2342 tokens (最大允许: 1808)
2025-12-25 12:07:50,646 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 2332 tokens (最大允许: 1808)
2025-12-25 12:07:50,662 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8691 tokens (最大允许: 1808)
2025-12-25 12:07:50,677 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8578 tokens (最大允许: 1808)
2025-12-25 12:07:50,694 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8818 tokens (最大允许: 1808)
2025-12-25 12:07:50,710 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 9003 tokens (最大允许: 1808)
2025-12-25 12:07:50,727 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8954 tokens (最大允许: 1808)
2025-12-25 12:07:50,742 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8562 tokens (最大允许: 1808)
2025-12-25 12:07:50,755 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 7429 tokens (最大允许: 1808)
2025-12-25 12:07:50,771 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8607 tokens (最大允许: 1808)
2025-12-25 12:07:50,787 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8509 tokens (最大允许: 1808)
2025-12-25 12:07:50,803 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8766 tokens (最大允许: 1808)
2025-12-25 12:07:50,819 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8676 tokens (最大允许: 1808)
2025-12-25 12:07:50,835 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8713 tokens (最大允许: 1808)
2025-12-25 12:07:50,851 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8680 tokens (最大允许: 1808)
2025-12-25 12:07:50,867 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8665 tokens (最大允许: 1808)
2025-12-25 12:07:50,884 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8592 tokens (最大允许: 1808)
2025-12-25 12:07:50,900 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8605 tokens (最大允许: 1808)
2025-12-25 12:07:50,916 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8696 tokens (最大允许: 1808)
2025-12-25 12:07:50,931 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8546 tokens (最大允许: 1808)
2025-12-25 12:07:50,951 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8681 tokens (最大允许: 1808)
2025-12-25 12:07:50,969 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8654 tokens (最大允许: 1808)
2025-12-25 12:07:50,986 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8752 tokens (最大允许: 1808)
2025-12-25 12:07:51,003 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8662 tokens (最大允许: 1808)
2025-12-25 12:07:51,010 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 3743 tokens (最大允许: 1808)
2025-12-25 12:07:51,026 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8540 tokens (最大允许: 1808)
2025-12-25 12:07:51,043 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8622 tokens (最大允许: 1808)
2025-12-25 12:07:51,058 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8625 tokens (最大允许: 1808)
2025-12-25 12:07:51,075 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8726 tokens (最大允许: 1808)
2025-12-25 12:07:51,090 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8572 tokens (最大允许: 1808)
2025-12-25 12:07:51,095 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 2278 tokens (最大允许: 1808)
2025-12-25 12:07:51,103 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 2785 tokens (最大允许: 1808)
2025-12-25 12:07:51,119 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8761 tokens (最大允许: 1808)
2025-12-25 12:07:51,136 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8861 tokens (最大允许: 1808)
2025-12-25 12:07:51,152 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8806 tokens (最大允许: 1808)
2025-12-25 12:07:51,168 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8818 tokens (最大允许: 1808)
2025-12-25 12:07:51,185 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8825 tokens (最大允许: 1808)
2025-12-25 12:07:51,201 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8630 tokens (最大允许: 1808)
2025-12-25 12:07:51,217 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8705 tokens (最大允许: 1808)
2025-12-25 12:07:51,234 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8772 tokens (最大允许: 1808)
2025-12-25 12:07:51,251 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8580 tokens (最大允许: 1808)
2025-12-25 12:07:51,268 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8732 tokens (最大允许: 1808)
2025-12-25 12:07:51,285 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8772 tokens (最大允许: 1808)
2025-12-25 12:07:51,301 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8614 tokens (最大允许: 1808)
2025-12-25 12:07:51,317 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8585 tokens (最大允许: 1808)
2025-12-25 12:07:51,333 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8661 tokens (最大允许: 1808)
2025-12-25 12:07:51,348 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8745 tokens (最大允许: 1808)
2025-12-25 12:07:51,364 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8748 tokens (最大允许: 1808)
2025-12-25 12:07:51,381 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8602 tokens (最大允许: 1808)
2025-12-25 12:07:51,397 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8572 tokens (最大允许: 1808)
2025-12-25 12:07:51,413 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8891 tokens (最大允许: 1808)
2025-12-25 12:07:51,429 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8532 tokens (最大允许: 1808)
2025-12-25 12:07:51,445 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8646 tokens (最大允许: 1808)
2025-12-25 12:07:51,449 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 2218 tokens (最大允许: 1808)
2025-12-25 12:07:51,466 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8767 tokens (最大允许: 1808)
2025-12-25 12:07:51,485 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8756 tokens (最大允许: 1808)
2025-12-25 12:07:51,503 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8776 tokens (最大允许: 1808)
2025-12-25 12:07:51,521 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8617 tokens (最大允许: 1808)
2025-12-25 12:07:51,538 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8610 tokens (最大允许: 1808)
2025-12-25 12:07:51,554 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8675 tokens (最大允许: 1808)
2025-12-25 12:07:51,570 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8667 tokens (最大允许: 1808)
2025-12-25 12:07:51,575 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 2639 tokens (最大允许: 1808)
2025-12-25 12:07:51,591 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8680 tokens (最大允许: 1808)
2025-12-25 12:07:51,607 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8767 tokens (最大允许: 1808)
2025-12-25 12:07:51,622 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8673 tokens (最大允许: 1808)
2025-12-25 12:07:51,638 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8547 tokens (最大允许: 1808)
2025-12-25 12:07:51,647 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 4866 tokens (最大允许: 1808)
2025-12-25 12:07:51,663 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8611 tokens (最大允许: 1808)
2025-12-25 12:07:51,679 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8554 tokens (最大允许: 1808)
2025-12-25 12:07:51,695 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8618 tokens (最大允许: 1808)
2025-12-25 12:07:51,710 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8549 tokens (最大允许: 1808)
2025-12-25 12:07:51,726 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8735 tokens (最大允许: 1808)
2025-12-25 12:07:51,742 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8663 tokens (最大允许: 1808)
2025-12-25 12:07:51,759 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8697 tokens (最大允许: 1808)
2025-12-25 12:07:51,775 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8607 tokens (最大允许: 1808)
2025-12-25 12:07:51,790 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8593 tokens (最大允许: 1808)
2025-12-25 12:07:51,806 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8586 tokens (最大允许: 1808)
2025-12-25 12:07:51,821 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8577 tokens (最大允许: 1808)
2025-12-25 12:07:51,837 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8625 tokens (最大允许: 1808)
2025-12-25 12:07:51,853 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8665 tokens (最大允许: 1808)
2025-12-25 12:07:51,870 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8854 tokens (最大允许: 1808)
2025-12-25 12:07:51,885 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8523 tokens (最大允许: 1808)
2025-12-25 12:07:51,902 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8691 tokens (最大允许: 1808)
2025-12-25 12:07:51,918 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8835 tokens (最大允许: 1808)
2025-12-25 12:07:51,933 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8591 tokens (最大允许: 1808)
2025-12-25 12:07:51,948 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8583 tokens (最大允许: 1808)
2025-12-25 12:07:51,948 - inference.local_inference - WARNING - 共跳过 121/128 条超长prompts
2025-12-25 12:10:09,106 - __main__ - INFO - 批次 [897-1024] 本地推理完成
2025-12-25 12:10:09,106 - __main__ - INFO - 处理批次 [1025-1152/99842]
2025-12-25 12:10:09,107 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 12:10:09,107 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 12:10:28,859 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 12:10:28,859 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 12:11:01,902 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 12:11:01,903 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 12:11:01,929 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:01,949 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:01,967 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:01,984 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:11:02,000 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,015 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:02,030 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:02,044 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:02,060 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,075 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:02,090 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:02,104 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,120 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:11:02,134 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:11:02,149 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,164 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:02,179 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,194 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,209 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:02,225 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:02,240 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:02,255 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,270 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:02,284 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:02,300 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:11:02,315 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:02,330 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:02,345 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:02,360 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,375 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,390 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,406 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:02,421 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8473 tokens (最大允许: 1808)
2025-12-25 12:11:02,436 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:11:02,451 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:02,466 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:11:02,483 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8490 tokens (最大允许: 1808)
2025-12-25 12:11:02,499 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,516 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8491 tokens (最大允许: 1808)
2025-12-25 12:11:02,532 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8488 tokens (最大允许: 1808)
2025-12-25 12:11:02,547 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:02,563 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:02,578 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8488 tokens (最大允许: 1808)
2025-12-25 12:11:02,593 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:02,608 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,623 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:11:02,638 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:02,653 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:02,668 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8488 tokens (最大允许: 1808)
2025-12-25 12:11:02,684 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8488 tokens (最大允许: 1808)
2025-12-25 12:11:02,698 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:11:02,713 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:02,728 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8491 tokens (最大允许: 1808)
2025-12-25 12:11:02,744 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,758 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:02,773 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:11:02,788 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:11:02,802 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:11:02,817 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:02,832 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:02,848 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:02,862 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,877 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:02,892 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,907 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:11:02,921 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:02,936 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,951 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:11:02,966 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:11:02,980 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:02,995 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:03,010 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,025 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:03,030 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 2658 tokens (最大允许: 1808)
2025-12-25 12:11:03,044 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:03,059 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:03,074 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:03,089 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:11:03,104 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:11:03,108 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 1899 tokens (最大允许: 1808)
2025-12-25 12:11:03,122 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:03,137 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:03,151 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,166 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:11:03,181 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:11:03,196 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:03,211 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,225 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:03,240 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:03,255 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:03,270 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:11:03,285 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:11:03,300 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:11:03,315 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:03,331 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:03,345 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,361 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:03,375 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,390 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,405 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:03,420 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:11:03,437 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:03,452 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:11:03,467 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:03,482 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:03,497 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:03,513 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:03,528 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:03,543 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,559 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:11:03,575 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:11:03,591 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:11:03,607 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:11:03,622 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8473 tokens (最大允许: 1808)
2025-12-25 12:11:03,638 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,655 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8473 tokens (最大允许: 1808)
2025-12-25 12:11:03,670 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:03,686 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:11:03,702 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:11:03,718 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:03,735 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:11:03,751 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:11:03,766 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:11:03,781 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:11:03,796 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:11:03,811 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:11:03,826 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:11:03,826 - inference.local_inference - WARNING - 共跳过 127/128 条超长prompts
2025-12-25 12:11:04,917 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 12:11:04,918 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 12:11:04,918 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 12:11:04,918 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 12:11:14,993 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 12:11:14,993 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 12:20:41,823 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 12:20:41,824 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 12:20:41,851 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8812 tokens (最大允许: 1808)
2025-12-25 12:20:41,871 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8613 tokens (最大允许: 1808)
2025-12-25 12:20:41,890 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8612 tokens (最大允许: 1808)
2025-12-25 12:20:41,906 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8712 tokens (最大允许: 1808)
2025-12-25 12:20:41,922 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8778 tokens (最大允许: 1808)
2025-12-25 12:20:41,939 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8505 tokens (最大允许: 1808)
2025-12-25 12:20:41,954 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8663 tokens (最大允许: 1808)
2025-12-25 12:20:41,970 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8676 tokens (最大允许: 1808)
2025-12-25 12:20:41,986 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8545 tokens (最大允许: 1808)
2025-12-25 12:20:41,991 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 2218 tokens (最大允许: 1808)
2025-12-25 12:20:42,007 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8565 tokens (最大允许: 1808)
2025-12-25 12:20:42,022 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8522 tokens (最大允许: 1808)
2025-12-25 12:20:42,039 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8778 tokens (最大允许: 1808)
2025-12-25 12:20:42,055 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8787 tokens (最大允许: 1808)
2025-12-25 12:20:42,071 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8551 tokens (最大允许: 1808)
2025-12-25 12:20:42,088 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8588 tokens (最大允许: 1808)
2025-12-25 12:20:42,105 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8583 tokens (最大允许: 1808)
2025-12-25 12:20:42,121 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8595 tokens (最大允许: 1808)
2025-12-25 12:20:42,137 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8633 tokens (最大允许: 1808)
2025-12-25 12:20:42,154 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8577 tokens (最大允许: 1808)
2025-12-25 12:20:42,169 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8536 tokens (最大允许: 1808)
2025-12-25 12:20:42,173 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 2111 tokens (最大允许: 1808)
2025-12-25 12:20:42,189 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8548 tokens (最大允许: 1808)
2025-12-25 12:20:42,204 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8564 tokens (最大允许: 1808)
2025-12-25 12:20:42,220 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8635 tokens (最大允许: 1808)
2025-12-25 12:20:42,236 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8644 tokens (最大允许: 1808)
2025-12-25 12:20:42,252 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8663 tokens (最大允许: 1808)
2025-12-25 12:20:42,268 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8662 tokens (最大允许: 1808)
2025-12-25 12:20:42,284 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8771 tokens (最大允许: 1808)
2025-12-25 12:20:42,300 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8604 tokens (最大允许: 1808)
2025-12-25 12:20:42,316 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8649 tokens (最大允许: 1808)
2025-12-25 12:20:42,332 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8646 tokens (最大允许: 1808)
2025-12-25 12:20:42,348 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8828 tokens (最大允许: 1808)
2025-12-25 12:20:42,363 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8575 tokens (最大允许: 1808)
2025-12-25 12:20:42,379 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8640 tokens (最大允许: 1808)
2025-12-25 12:20:42,395 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8674 tokens (最大允许: 1808)
2025-12-25 12:20:42,412 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8730 tokens (最大允许: 1808)
2025-12-25 12:20:42,427 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8747 tokens (最大允许: 1808)
2025-12-25 12:20:42,443 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8600 tokens (最大允许: 1808)
2025-12-25 12:20:42,459 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8561 tokens (最大允许: 1808)
2025-12-25 12:20:42,475 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8552 tokens (最大允许: 1808)
2025-12-25 12:20:42,491 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8818 tokens (最大允许: 1808)
2025-12-25 12:20:42,507 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8781 tokens (最大允许: 1808)
2025-12-25 12:20:42,523 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8538 tokens (最大允许: 1808)
2025-12-25 12:20:42,526 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 1923 tokens (最大允许: 1808)
2025-12-25 12:20:42,542 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8648 tokens (最大允许: 1808)
2025-12-25 12:20:42,546 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 2188 tokens (最大允许: 1808)
2025-12-25 12:20:42,562 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8823 tokens (最大允许: 1808)
2025-12-25 12:20:42,578 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8547 tokens (最大允许: 1808)
2025-12-25 12:20:42,593 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8632 tokens (最大允许: 1808)
2025-12-25 12:20:42,611 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8976 tokens (最大允许: 1808)
2025-12-25 12:20:42,628 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8557 tokens (最大允许: 1808)
2025-12-25 12:20:42,647 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8611 tokens (最大允许: 1808)
2025-12-25 12:20:42,664 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8647 tokens (最大允许: 1808)
2025-12-25 12:20:42,680 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8589 tokens (最大允许: 1808)
2025-12-25 12:20:42,698 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8622 tokens (最大允许: 1808)
2025-12-25 12:20:42,714 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8656 tokens (最大允许: 1808)
2025-12-25 12:20:42,729 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8527 tokens (最大允许: 1808)
2025-12-25 12:20:42,745 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8705 tokens (最大允许: 1808)
2025-12-25 12:20:42,761 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8901 tokens (最大允许: 1808)
2025-12-25 12:20:42,779 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8560 tokens (最大允许: 1808)
2025-12-25 12:20:42,798 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8732 tokens (最大允许: 1808)
2025-12-25 12:20:42,814 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8568 tokens (最大允许: 1808)
2025-12-25 12:20:42,831 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8876 tokens (最大允许: 1808)
2025-12-25 12:20:42,846 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8542 tokens (最大允许: 1808)
2025-12-25 12:20:42,862 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8709 tokens (最大允许: 1808)
2025-12-25 12:20:42,878 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8662 tokens (最大允许: 1808)
2025-12-25 12:20:42,895 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8668 tokens (最大允许: 1808)
2025-12-25 12:20:42,913 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8647 tokens (最大允许: 1808)
2025-12-25 12:20:42,929 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8699 tokens (最大允许: 1808)
2025-12-25 12:20:42,945 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8572 tokens (最大允许: 1808)
2025-12-25 12:20:42,962 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8557 tokens (最大允许: 1808)
2025-12-25 12:20:42,978 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8707 tokens (最大允许: 1808)
2025-12-25 12:20:42,994 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8653 tokens (最大允许: 1808)
2025-12-25 12:20:43,009 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8516 tokens (最大允许: 1808)
2025-12-25 12:20:43,025 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8517 tokens (最大允许: 1808)
2025-12-25 12:20:43,029 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 1914 tokens (最大允许: 1808)
2025-12-25 12:20:43,047 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8624 tokens (最大允许: 1808)
2025-12-25 12:20:43,063 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8597 tokens (最大允许: 1808)
2025-12-25 12:20:43,079 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8692 tokens (最大允许: 1808)
2025-12-25 12:20:43,096 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8646 tokens (最大允许: 1808)
2025-12-25 12:20:43,112 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8536 tokens (最大允许: 1808)
2025-12-25 12:20:43,129 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8808 tokens (最大允许: 1808)
2025-12-25 12:20:43,145 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 9118 tokens (最大允许: 1808)
2025-12-25 12:20:43,161 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8660 tokens (最大允许: 1808)
2025-12-25 12:20:43,176 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8513 tokens (最大允许: 1808)
2025-12-25 12:20:43,192 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8661 tokens (最大允许: 1808)
2025-12-25 12:20:43,207 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8608 tokens (最大允许: 1808)
2025-12-25 12:20:43,223 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:20:43,239 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8465 tokens (最大允许: 1808)
2025-12-25 12:20:43,255 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8454 tokens (最大允许: 1808)
2025-12-25 12:20:43,271 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:20:43,287 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:20:43,303 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:20:43,320 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8492 tokens (最大允许: 1808)
2025-12-25 12:20:43,336 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:20:43,351 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:20:43,366 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:20:43,383 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:20:43,399 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:20:43,415 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:43,432 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8453 tokens (最大允许: 1808)
2025-12-25 12:20:43,450 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:20:43,468 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:20:43,487 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:20:43,503 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:20:43,520 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:20:43,537 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8447 tokens (最大允许: 1808)
2025-12-25 12:20:43,555 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:20:43,572 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8463 tokens (最大允许: 1808)
2025-12-25 12:20:43,589 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8433 tokens (最大允许: 1808)
2025-12-25 12:20:43,605 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:20:43,622 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8502 tokens (最大允许: 1808)
2025-12-25 12:20:43,640 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:20:43,657 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:20:43,674 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8431 tokens (最大允许: 1808)
2025-12-25 12:20:43,692 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:20:43,709 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:20:43,725 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:43,742 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8460 tokens (最大允许: 1808)
2025-12-25 12:20:43,759 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8468 tokens (最大允许: 1808)
2025-12-25 12:20:43,776 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:20:43,792 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8455 tokens (最大允许: 1808)
2025-12-25 12:20:43,807 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8431 tokens (最大允许: 1808)
2025-12-25 12:20:43,808 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 12:20:53,711 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 12:20:53,711 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 12:20:53,736 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:53,755 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8478 tokens (最大允许: 1808)
2025-12-25 12:20:53,773 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:53,790 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:53,807 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8482 tokens (最大允许: 1808)
2025-12-25 12:20:53,823 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8472 tokens (最大允许: 1808)
2025-12-25 12:20:53,838 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8490 tokens (最大允许: 1808)
2025-12-25 12:20:53,854 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:53,871 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:53,887 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 8478 tokens (最大允许: 1808)
2025-12-25 12:20:53,902 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:53,918 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:53,933 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:53,949 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:53,963 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:53,978 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8478 tokens (最大允许: 1808)
2025-12-25 12:20:53,993 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8480 tokens (最大允许: 1808)
2025-12-25 12:20:54,008 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:54,023 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8469 tokens (最大允许: 1808)
2025-12-25 12:20:54,038 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,053 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:54,067 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8470 tokens (最大允许: 1808)
2025-12-25 12:20:54,082 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,098 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,115 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8490 tokens (最大允许: 1808)
2025-12-25 12:20:54,130 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8480 tokens (最大允许: 1808)
2025-12-25 12:20:54,145 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8482 tokens (最大允许: 1808)
2025-12-25 12:20:54,160 - inference.local_inference - WARNING - 跳过超长prompt [29/122]: 8490 tokens (最大允许: 1808)
2025-12-25 12:20:54,174 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:54,189 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,204 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,219 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,233 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,248 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:54,263 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,278 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8468 tokens (最大允许: 1808)
2025-12-25 12:20:54,294 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8480 tokens (最大允许: 1808)
2025-12-25 12:20:54,310 - inference.local_inference - WARNING - 跳过超长prompt [39/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,327 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:54,345 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,363 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,378 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,393 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,408 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8469 tokens (最大允许: 1808)
2025-12-25 12:20:54,423 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:54,437 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8471 tokens (最大允许: 1808)
2025-12-25 12:20:54,452 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,467 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,482 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,497 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8481 tokens (最大允许: 1808)
2025-12-25 12:20:54,511 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,526 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:54,541 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:54,556 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:54,571 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,586 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8482 tokens (最大允许: 1808)
2025-12-25 12:20:54,601 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:54,616 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:54,631 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8471 tokens (最大允许: 1808)
2025-12-25 12:20:54,646 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8471 tokens (最大允许: 1808)
2025-12-25 12:20:54,661 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8478 tokens (最大允许: 1808)
2025-12-25 12:20:54,676 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,680 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 2277 tokens (最大允许: 1808)
2025-12-25 12:20:54,695 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8478 tokens (最大允许: 1808)
2025-12-25 12:20:54,709 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:54,724 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:54,739 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:54,753 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,768 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8472 tokens (最大允许: 1808)
2025-12-25 12:20:54,783 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,798 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,813 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:54,828 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:54,842 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,857 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,872 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,887 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:54,902 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,916 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:54,931 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 8481 tokens (最大允许: 1808)
2025-12-25 12:20:54,946 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8478 tokens (最大允许: 1808)
2025-12-25 12:20:54,960 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8488 tokens (最大允许: 1808)
2025-12-25 12:20:54,975 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:54,990 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 8479 tokens (最大允许: 1808)
2025-12-25 12:20:55,004 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8472 tokens (最大允许: 1808)
2025-12-25 12:20:55,019 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8480 tokens (最大允许: 1808)
2025-12-25 12:20:55,033 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:55,048 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:55,063 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8471 tokens (最大允许: 1808)
2025-12-25 12:20:55,078 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:55,092 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8482 tokens (最大允许: 1808)
2025-12-25 12:20:55,107 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:55,122 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:55,137 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8481 tokens (最大允许: 1808)
2025-12-25 12:20:55,151 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:55,166 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:55,181 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8480 tokens (最大允许: 1808)
2025-12-25 12:20:55,197 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:55,211 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:55,226 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:55,243 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8481 tokens (最大允许: 1808)
2025-12-25 12:20:55,258 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8471 tokens (最大允许: 1808)
2025-12-25 12:20:55,274 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 8477 tokens (最大允许: 1808)
2025-12-25 12:20:55,289 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8471 tokens (最大允许: 1808)
2025-12-25 12:20:55,303 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:55,318 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:55,334 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8468 tokens (最大允许: 1808)
2025-12-25 12:20:55,348 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8478 tokens (最大允许: 1808)
2025-12-25 12:20:55,364 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:55,379 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:55,396 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:20:55,411 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8469 tokens (最大允许: 1808)
2025-12-25 12:20:55,426 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8468 tokens (最大允许: 1808)
2025-12-25 12:20:55,440 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8474 tokens (最大允许: 1808)
2025-12-25 12:20:55,455 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8480 tokens (最大允许: 1808)
2025-12-25 12:20:55,470 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8472 tokens (最大允许: 1808)
2025-12-25 12:20:55,485 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:55,500 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:20:55,515 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8470 tokens (最大允许: 1808)
2025-12-25 12:20:55,530 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8476 tokens (最大允许: 1808)
2025-12-25 12:20:55,530 - inference.local_inference - WARNING - 共跳过 120/122 条超长prompts
2025-12-25 12:22:55,302 - __main__ - INFO - 批次 [1025-1152] 本地推理完成
2025-12-25 12:22:55,303 - __main__ - INFO - 处理批次 [1153-1280/99842]
2025-12-25 12:22:55,303 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 12:22:55,303 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 12:22:59,817 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 12:22:59,818 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 12:22:59,818 - __main__ - WARNING - ⚠️  247/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 12:22:59,818 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 12:22:59,899 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 12:22:59,899 - __main__ - INFO - ============================================================
2025-12-25 12:22:59,899 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 12:22:59,899 - __main__ - INFO - ============================================================
2025-12-25 12:22:59,899 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 12:22:59,899 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 12:22:59,899 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:23:11,435 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 12:23:11,435 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 12:23:33,005 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 12:23:33,006 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 12:23:33,007 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:24:02,892 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 12:24:02,893 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 12:24:02,893 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:24:37,175 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 12:24:37,176 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 12:24:37,176 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:25:19,022 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 12:25:19,022 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 12:25:19,022 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:25:54,099 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 12:25:54,100 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 12:25:54,100 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:26:36,834 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 12:26:36,835 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 12:26:36,835 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:27:32,125 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 12:27:32,126 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 12:27:32,126 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:28:10,313 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 12:28:10,313 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 12:28:10,313 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:28:43,464 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 12:28:43,464 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 12:28:43,464 - __main__ - INFO - 开始数据质量检查...
2025-12-25 12:28:43,464 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 12:28:43,464 - __main__ - INFO - ============================================================
2025-12-25 12:28:43,464 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 12:28:43,464 - __main__ - INFO - ============================================================
2025-12-25 12:28:43,464 - __main__ - INFO - 预检查数据完整性...
2025-12-25 12:28:43,465 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 12:28:43,465 - __main__ - INFO - Rejected非空率: 3/250 (1.2%)
2025-12-25 12:28:43,465 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 12:28:43,490 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 12:28:43,506 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 12:28:43,525 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 12:28:43,540 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 12:28:43,556 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 12:28:43,573 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_disambiguation_qa.jsonl
2025-12-25 12:28:43,573 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 12:28:47,159 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 12:28:47,194 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 12:28:48,288 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,288 - __main__ - INFO - 数据集名称: bbh
2025-12-25 12:28:48,288 - __main__ - INFO - 数据集路径: dataset/bbh/dyck_languages.json
2025-12-25 12:28:48,288 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,288 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 12:28:48,288 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,288 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 12:28:48,288 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/dyck_languages.json
2025-12-25 12:28:48,288 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,288 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 12:28:48,288 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 12:28:48,289 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 12:28:48,289 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 12:28:48,289 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,289 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 12:28:48,289 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,289 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 12:28:48,289 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,289 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 12:28:48,290 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 12:28:48,290 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,290 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 12:28:48,290 - __main__ - INFO - ============================================================
2025-12-25 12:28:48,290 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 12:28:48,290 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 12:28:48,290 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 12:28:52,899 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 12:28:52,899 - inference.local_inference - INFO - ============================================================
2025-12-25 12:28:52,899 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 12:28:52,899 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 12:28:52,899 - inference.local_inference - INFO - ============================================================
2025-12-25 12:30:08,815 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 12:32:22,111 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 12:32:22,112 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 12:32:22,208 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8622 tokens (最大允许: 1808)
2025-12-25 12:32:22,227 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8533 tokens (最大允许: 1808)
2025-12-25 12:32:22,254 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 1834 tokens (最大允许: 1808)
2025-12-25 12:32:22,304 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8612 tokens (最大允许: 1808)
2025-12-25 12:32:22,351 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8563 tokens (最大允许: 1808)
2025-12-25 12:32:22,364 - inference.local_inference - WARNING - 共跳过 5/128 条超长prompts
2025-12-25 12:32:49,149 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 12:32:49,149 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 12:32:49,179 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:32:49,200 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8491 tokens (最大允许: 1808)
2025-12-25 12:32:49,218 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8465 tokens (最大允许: 1808)
2025-12-25 12:32:49,234 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8458 tokens (最大允许: 1808)
2025-12-25 12:32:49,252 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:32:49,270 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8521 tokens (最大允许: 1808)
2025-12-25 12:32:49,291 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8524 tokens (最大允许: 1808)
2025-12-25 12:32:49,308 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:32:49,325 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8505 tokens (最大允许: 1808)
2025-12-25 12:32:49,330 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 2273 tokens (最大允许: 1808)
2025-12-25 12:32:49,346 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:32:49,367 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8501 tokens (最大允许: 1808)
2025-12-25 12:32:49,387 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:32:49,408 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:32:49,428 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8558 tokens (最大允许: 1808)
2025-12-25 12:32:49,434 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 3420 tokens (最大允许: 1808)
2025-12-25 12:32:49,449 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8468 tokens (最大允许: 1808)
2025-12-25 12:32:49,466 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:32:49,482 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8519 tokens (最大允许: 1808)
2025-12-25 12:32:49,498 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8529 tokens (最大允许: 1808)
2025-12-25 12:32:49,515 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8509 tokens (最大允许: 1808)
2025-12-25 12:32:49,531 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8447 tokens (最大允许: 1808)
2025-12-25 12:32:49,546 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:32:49,566 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8465 tokens (最大允许: 1808)
2025-12-25 12:32:49,583 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:32:49,599 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:32:49,615 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:32:49,630 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8485 tokens (最大允许: 1808)
2025-12-25 12:32:49,647 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8516 tokens (最大允许: 1808)
2025-12-25 12:32:49,662 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:32:49,682 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8467 tokens (最大允许: 1808)
2025-12-25 12:32:49,698 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8505 tokens (最大允许: 1808)
2025-12-25 12:32:49,714 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:32:49,729 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:32:49,747 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8496 tokens (最大允许: 1808)
2025-12-25 12:32:49,762 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8455 tokens (最大允许: 1808)
2025-12-25 12:32:49,778 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:32:49,794 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:32:49,810 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:32:49,825 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8473 tokens (最大允许: 1808)
2025-12-25 12:32:49,841 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8454 tokens (最大允许: 1808)
2025-12-25 12:32:49,857 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:32:49,872 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:32:49,888 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:32:49,903 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:32:49,919 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:32:49,936 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8493 tokens (最大允许: 1808)
2025-12-25 12:32:49,953 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8449 tokens (最大允许: 1808)
2025-12-25 12:32:49,968 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8453 tokens (最大允许: 1808)
2025-12-25 12:32:49,983 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:32:49,999 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:32:50,003 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 2105 tokens (最大允许: 1808)
2025-12-25 12:32:50,019 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8455 tokens (最大允许: 1808)
2025-12-25 12:32:50,035 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:32:50,051 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8516 tokens (最大允许: 1808)
2025-12-25 12:32:50,067 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8489 tokens (最大允许: 1808)
2025-12-25 12:32:50,083 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:32:50,098 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:32:50,114 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8465 tokens (最大允许: 1808)
2025-12-25 12:32:50,130 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8494 tokens (最大允许: 1808)
2025-12-25 12:32:50,145 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8460 tokens (最大允许: 1808)
2025-12-25 12:32:50,161 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8457 tokens (最大允许: 1808)
2025-12-25 12:32:50,177 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8457 tokens (最大允许: 1808)
2025-12-25 12:32:50,192 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:32:50,207 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:32:50,224 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8484 tokens (最大允许: 1808)
2025-12-25 12:32:50,239 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:32:50,255 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:32:50,277 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8450 tokens (最大允许: 1808)
2025-12-25 12:32:50,294 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:32:50,312 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:32:50,327 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:32:50,343 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:32:50,359 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:32:50,374 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:32:50,391 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:32:50,408 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:32:50,414 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 2360 tokens (最大允许: 1808)
2025-12-25 12:32:50,430 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:32:50,446 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:32:50,463 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8450 tokens (最大允许: 1808)
2025-12-25 12:32:50,480 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8464 tokens (最大允许: 1808)
2025-12-25 12:32:50,496 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:32:50,512 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8484 tokens (最大允许: 1808)
2025-12-25 12:32:50,528 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:32:50,533 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 2408 tokens (最大允许: 1808)
2025-12-25 12:32:50,549 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:32:50,565 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8512 tokens (最大允许: 1808)
2025-12-25 12:32:50,581 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8454 tokens (最大允许: 1808)
2025-12-25 12:32:50,599 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:32:50,617 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:32:50,634 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:32:50,650 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:32:50,665 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:32:50,684 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8498 tokens (最大允许: 1808)
2025-12-25 12:32:50,700 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8458 tokens (最大允许: 1808)
2025-12-25 12:32:50,716 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:32:50,733 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:32:50,750 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:32:50,767 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8516 tokens (最大允许: 1808)
2025-12-25 12:32:50,782 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8510 tokens (最大允许: 1808)
2025-12-25 12:32:50,798 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:32:50,814 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8454 tokens (最大允许: 1808)
2025-12-25 12:32:50,825 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 5595 tokens (最大允许: 1808)
2025-12-25 12:32:50,840 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8539 tokens (最大允许: 1808)
2025-12-25 12:32:50,856 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8458 tokens (最大允许: 1808)
2025-12-25 12:32:50,871 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8485 tokens (最大允许: 1808)
2025-12-25 12:32:50,888 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:32:50,904 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8433 tokens (最大允许: 1808)
2025-12-25 12:32:50,921 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:32:50,937 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:32:50,953 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8453 tokens (最大允许: 1808)
2025-12-25 12:32:50,969 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8447 tokens (最大允许: 1808)
2025-12-25 12:32:50,984 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8509 tokens (最大允许: 1808)
2025-12-25 12:32:50,999 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8511 tokens (最大允许: 1808)
2025-12-25 12:32:51,015 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8513 tokens (最大允许: 1808)
2025-12-25 12:32:51,032 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8450 tokens (最大允许: 1808)
2025-12-25 12:32:51,047 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:32:51,062 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8483 tokens (最大允许: 1808)
2025-12-25 12:32:51,068 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 2835 tokens (最大允许: 1808)
2025-12-25 12:32:51,084 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8473 tokens (最大允许: 1808)
2025-12-25 12:32:51,100 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8464 tokens (最大允许: 1808)
2025-12-25 12:32:51,100 - inference.local_inference - WARNING - 共跳过 122/128 条超长prompts
2025-12-25 12:35:07,897 - __main__ - INFO - 批次 [1153-1280] 本地推理完成
2025-12-25 12:35:07,898 - __main__ - INFO - 处理批次 [1281-1408/99842]
2025-12-25 12:35:07,898 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 12:35:07,898 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 12:35:19,546 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 12:35:19,547 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 12:42:07,707 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 12:42:07,708 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 12:42:07,734 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8427 tokens (最大允许: 1808)
2025-12-25 12:42:07,752 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:07,771 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8489 tokens (最大允许: 1808)
2025-12-25 12:42:07,789 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:42:07,805 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8450 tokens (最大允许: 1808)
2025-12-25 12:42:07,821 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:42:07,838 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8429 tokens (最大允许: 1808)
2025-12-25 12:42:07,856 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:42:07,874 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8433 tokens (最大允许: 1808)
2025-12-25 12:42:07,891 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:42:07,907 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:42:07,922 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:07,937 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:42:07,952 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8505 tokens (最大允许: 1808)
2025-12-25 12:42:07,964 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8458 tokens (最大允许: 1808)
2025-12-25 12:42:07,978 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:07,993 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:08,008 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8429 tokens (最大允许: 1808)
2025-12-25 12:42:08,023 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:42:08,037 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:42:08,050 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:08,064 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,079 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:42:08,094 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:42:08,109 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:08,123 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,141 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:08,160 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8516 tokens (最大允许: 1808)
2025-12-25 12:42:08,176 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:08,191 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:42:08,206 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,221 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:42:08,235 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8403 tokens (最大允许: 1808)
2025-12-25 12:42:08,250 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:08,265 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:42:08,279 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:08,294 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:42:08,309 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:08,322 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8465 tokens (最大允许: 1808)
2025-12-25 12:42:08,336 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:08,350 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:42:08,364 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:08,379 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,394 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:42:08,409 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,423 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:42:08,438 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8508 tokens (最大允许: 1808)
2025-12-25 12:42:08,452 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:42:08,467 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:42:08,481 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:08,497 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:42:08,511 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,525 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8433 tokens (最大允许: 1808)
2025-12-25 12:42:08,541 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,556 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,571 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:08,586 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:42:08,602 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:42:08,617 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:42:08,633 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:42:08,648 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:42:08,662 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:42:08,677 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:42:08,692 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:42:08,708 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:42:08,725 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:42:08,739 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:42:08,753 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:42:08,767 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:42:08,784 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8489 tokens (最大允许: 1808)
2025-12-25 12:42:08,799 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8523 tokens (最大允许: 1808)
2025-12-25 12:42:08,814 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:42:08,829 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:42:08,833 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 2300 tokens (最大允许: 1808)
2025-12-25 12:42:08,849 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8460 tokens (最大允许: 1808)
2025-12-25 12:42:08,865 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:42:08,880 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:42:08,895 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:42:08,910 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8412 tokens (最大允许: 1808)
2025-12-25 12:42:08,915 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 2615 tokens (最大允许: 1808)
2025-12-25 12:42:08,930 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8433 tokens (最大允许: 1808)
2025-12-25 12:42:08,947 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:08,963 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:42:08,979 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:42:08,996 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:42:09,011 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:42:09,026 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:42:09,041 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:42:09,057 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8511 tokens (最大允许: 1808)
2025-12-25 12:42:09,072 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:09,088 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:09,103 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8429 tokens (最大允许: 1808)
2025-12-25 12:42:09,119 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8447 tokens (最大允许: 1808)
2025-12-25 12:42:09,136 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8431 tokens (最大允许: 1808)
2025-12-25 12:42:09,150 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:09,166 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8499 tokens (最大允许: 1808)
2025-12-25 12:42:09,181 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8404 tokens (最大允许: 1808)
2025-12-25 12:42:09,197 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:42:09,213 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:09,229 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:42:09,243 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:42:09,258 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8430 tokens (最大允许: 1808)
2025-12-25 12:42:09,273 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8517 tokens (最大允许: 1808)
2025-12-25 12:42:09,288 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8431 tokens (最大允许: 1808)
2025-12-25 12:42:09,304 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8464 tokens (最大允许: 1808)
2025-12-25 12:42:09,320 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8517 tokens (最大允许: 1808)
2025-12-25 12:42:09,336 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8429 tokens (最大允许: 1808)
2025-12-25 12:42:09,351 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:42:09,366 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:09,382 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8457 tokens (最大允许: 1808)
2025-12-25 12:42:09,398 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:42:09,405 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 3370 tokens (最大允许: 1808)
2025-12-25 12:42:09,419 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:42:09,434 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:42:09,448 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8494 tokens (最大允许: 1808)
2025-12-25 12:42:09,464 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8428 tokens (最大允许: 1808)
2025-12-25 12:42:09,479 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8455 tokens (最大允许: 1808)
2025-12-25 12:42:09,494 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:42:09,509 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:42:09,524 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:42:09,524 - inference.local_inference - WARNING - 共跳过 120/128 条超长prompts
2025-12-25 12:44:14,012 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 12:44:14,012 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 12:44:14,012 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 12:44:14,013 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 12:44:57,974 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 12:44:57,974 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 12:44:58,001 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8496 tokens (最大允许: 1808)
2025-12-25 12:44:58,020 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:44:58,039 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:44:58,047 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 3979 tokens (最大允许: 1808)
2025-12-25 12:44:58,067 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:44:58,085 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:44:58,101 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:44:58,116 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:44:58,134 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8495 tokens (最大允许: 1808)
2025-12-25 12:44:58,152 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8486 tokens (最大允许: 1808)
2025-12-25 12:44:58,170 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:44:58,174 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 1813 tokens (最大允许: 1808)
2025-12-25 12:44:58,191 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8485 tokens (最大允许: 1808)
2025-12-25 12:44:58,207 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8490 tokens (最大允许: 1808)
2025-12-25 12:44:58,224 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8488 tokens (最大允许: 1808)
2025-12-25 12:44:58,244 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:44:58,261 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8464 tokens (最大允许: 1808)
2025-12-25 12:44:58,280 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:44:58,297 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:44:58,313 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8464 tokens (最大允许: 1808)
2025-12-25 12:44:58,328 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8484 tokens (最大允许: 1808)
2025-12-25 12:44:58,344 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8455 tokens (最大允许: 1808)
2025-12-25 12:44:58,360 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8467 tokens (最大允许: 1808)
2025-12-25 12:44:58,376 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8463 tokens (最大允许: 1808)
2025-12-25 12:44:58,382 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 2955 tokens (最大允许: 1808)
2025-12-25 12:44:58,397 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:44:58,413 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:44:58,429 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:44:58,445 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:44:58,460 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:44:58,477 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:44:58,494 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8502 tokens (最大允许: 1808)
2025-12-25 12:44:58,510 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:44:58,527 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:44:58,543 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8525 tokens (最大允许: 1808)
2025-12-25 12:44:58,558 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:44:58,574 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8500 tokens (最大允许: 1808)
2025-12-25 12:44:58,590 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8486 tokens (最大允许: 1808)
2025-12-25 12:44:58,606 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8513 tokens (最大允许: 1808)
2025-12-25 12:44:58,622 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8486 tokens (最大允许: 1808)
2025-12-25 12:44:58,638 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8508 tokens (最大允许: 1808)
2025-12-25 12:44:58,655 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8501 tokens (最大允许: 1808)
2025-12-25 12:44:58,671 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8492 tokens (最大允许: 1808)
2025-12-25 12:44:58,687 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:44:58,703 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:44:58,720 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8508 tokens (最大允许: 1808)
2025-12-25 12:44:58,736 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8814 tokens (最大允许: 1808)
2025-12-25 12:44:58,753 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8495 tokens (最大允许: 1808)
2025-12-25 12:44:58,759 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 2882 tokens (最大允许: 1808)
2025-12-25 12:44:58,776 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8820 tokens (最大允许: 1808)
2025-12-25 12:44:58,793 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8460 tokens (最大允许: 1808)
2025-12-25 12:44:58,813 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8546 tokens (最大允许: 1808)
2025-12-25 12:44:58,831 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8788 tokens (最大允许: 1808)
2025-12-25 12:44:58,850 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8867 tokens (最大允许: 1808)
2025-12-25 12:44:58,855 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 2189 tokens (最大允许: 1808)
2025-12-25 12:44:58,872 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8559 tokens (最大允许: 1808)
2025-12-25 12:44:58,889 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8568 tokens (最大允许: 1808)
2025-12-25 12:44:58,905 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:44:58,923 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8463 tokens (最大允许: 1808)
2025-12-25 12:44:58,941 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:44:58,957 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:44:58,973 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8471 tokens (最大允许: 1808)
2025-12-25 12:44:58,989 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8515 tokens (最大允许: 1808)
2025-12-25 12:44:59,005 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8498 tokens (最大允许: 1808)
2025-12-25 12:44:59,021 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:44:59,037 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:44:59,053 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:44:59,069 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8475 tokens (最大允许: 1808)
2025-12-25 12:44:59,086 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8492 tokens (最大允许: 1808)
2025-12-25 12:44:59,102 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8449 tokens (最大允许: 1808)
2025-12-25 12:44:59,118 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8511 tokens (最大允许: 1808)
2025-12-25 12:44:59,135 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:44:59,154 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:44:59,172 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:44:59,188 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:44:59,204 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:44:59,222 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:44:59,239 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:44:59,256 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:44:59,274 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:44:59,290 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:44:59,306 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8468 tokens (最大允许: 1808)
2025-12-25 12:44:59,322 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8431 tokens (最大允许: 1808)
2025-12-25 12:44:59,339 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8493 tokens (最大允许: 1808)
2025-12-25 12:44:59,354 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8482 tokens (最大允许: 1808)
2025-12-25 12:44:59,371 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:44:59,387 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:44:59,403 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:44:59,419 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:44:59,435 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:44:59,447 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 5607 tokens (最大允许: 1808)
2025-12-25 12:44:59,463 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:44:59,480 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:44:59,497 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:44:59,512 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8493 tokens (最大允许: 1808)
2025-12-25 12:44:59,530 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:44:59,545 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:44:59,561 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:44:59,578 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:44:59,595 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8493 tokens (最大允许: 1808)
2025-12-25 12:44:59,613 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:44:59,620 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 2646 tokens (最大允许: 1808)
2025-12-25 12:44:59,643 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:44:59,663 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:44:59,682 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:44:59,701 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:44:59,717 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:44:59,734 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8454 tokens (最大允许: 1808)
2025-12-25 12:44:59,750 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:44:59,766 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:44:59,782 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:44:59,799 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:44:59,815 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:44:59,833 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:44:59,849 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:44:59,865 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:44:59,882 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8499 tokens (最大允许: 1808)
2025-12-25 12:44:59,899 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:44:59,916 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8469 tokens (最大允许: 1808)
2025-12-25 12:44:59,932 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:44:59,949 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8465 tokens (最大允许: 1808)
2025-12-25 12:44:59,965 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:44:59,982 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:44:59,982 - inference.local_inference - WARNING - 共跳过 123/128 条超长prompts
2025-12-25 12:46:31,384 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 12:46:31,384 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 12:46:31,473 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8541 tokens (最大允许: 1808)
2025-12-25 12:46:31,510 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8567 tokens (最大允许: 1808)
2025-12-25 12:46:31,593 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8591 tokens (最大允许: 1808)
2025-12-25 12:46:31,612 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 7161 tokens (最大允许: 1808)
2025-12-25 12:46:31,635 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8585 tokens (最大允许: 1808)
2025-12-25 12:46:31,642 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 2985 tokens (最大允许: 1808)
2025-12-25 12:46:31,689 - inference.local_inference - WARNING - 共跳过 6/122 条超长prompts
2025-12-25 12:47:08,082 - __main__ - INFO - 批次 [1281-1408] 本地推理完成
2025-12-25 12:47:08,082 - __main__ - INFO - 处理批次 [1409-1536/99842]
2025-12-25 12:47:08,083 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 12:47:08,083 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 12:47:20,929 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 12:47:20,929 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 12:55:42,147 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 12:55:42,147 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 12:55:42,174 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:42,193 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8429 tokens (最大允许: 1808)
2025-12-25 12:55:42,210 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8440 tokens (最大允许: 1808)
2025-12-25 12:55:42,226 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8461 tokens (最大允许: 1808)
2025-12-25 12:55:42,243 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8431 tokens (最大允许: 1808)
2025-12-25 12:55:42,259 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8439 tokens (最大允许: 1808)
2025-12-25 12:55:42,274 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8430 tokens (最大允许: 1808)
2025-12-25 12:55:42,290 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:55:42,306 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:42,321 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 8442 tokens (最大允许: 1808)
2025-12-25 12:55:42,337 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8449 tokens (最大允许: 1808)
2025-12-25 12:55:42,354 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8502 tokens (最大允许: 1808)
2025-12-25 12:55:42,370 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:42,385 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8435 tokens (最大允许: 1808)
2025-12-25 12:55:42,400 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8429 tokens (最大允许: 1808)
2025-12-25 12:55:42,415 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8438 tokens (最大允许: 1808)
2025-12-25 12:55:42,431 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8500 tokens (最大允许: 1808)
2025-12-25 12:55:42,447 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8438 tokens (最大允许: 1808)
2025-12-25 12:55:42,462 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:42,474 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8470 tokens (最大允许: 1808)
2025-12-25 12:55:42,490 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8432 tokens (最大允许: 1808)
2025-12-25 12:55:42,505 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:42,520 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8431 tokens (最大允许: 1808)
2025-12-25 12:55:42,538 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8461 tokens (最大允许: 1808)
2025-12-25 12:55:42,552 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8460 tokens (最大允许: 1808)
2025-12-25 12:55:42,568 - inference.local_inference - WARNING - 跳过超长prompt [29/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:42,584 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8438 tokens (最大允许: 1808)
2025-12-25 12:55:42,598 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:42,613 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8444 tokens (最大允许: 1808)
2025-12-25 12:55:42,628 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8450 tokens (最大允许: 1808)
2025-12-25 12:55:42,643 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:42,658 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8436 tokens (最大允许: 1808)
2025-12-25 12:55:42,672 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:42,688 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8429 tokens (最大允许: 1808)
2025-12-25 12:55:42,704 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8444 tokens (最大允许: 1808)
2025-12-25 12:55:42,721 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8459 tokens (最大允许: 1808)
2025-12-25 12:55:42,737 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8427 tokens (最大允许: 1808)
2025-12-25 12:55:42,752 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8440 tokens (最大允许: 1808)
2025-12-25 12:55:42,767 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 8475 tokens (最大允许: 1808)
2025-12-25 12:55:42,782 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8454 tokens (最大允许: 1808)
2025-12-25 12:55:42,797 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8438 tokens (最大允许: 1808)
2025-12-25 12:55:42,812 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8454 tokens (最大允许: 1808)
2025-12-25 12:55:42,827 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8516 tokens (最大允许: 1808)
2025-12-25 12:55:42,843 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8456 tokens (最大允许: 1808)
2025-12-25 12:55:42,858 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8434 tokens (最大允许: 1808)
2025-12-25 12:55:42,873 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:42,888 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8450 tokens (最大允许: 1808)
2025-12-25 12:55:42,902 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8431 tokens (最大允许: 1808)
2025-12-25 12:55:42,917 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8442 tokens (最大允许: 1808)
2025-12-25 12:55:42,933 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8435 tokens (最大允许: 1808)
2025-12-25 12:55:42,948 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8432 tokens (最大允许: 1808)
2025-12-25 12:55:42,964 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8435 tokens (最大允许: 1808)
2025-12-25 12:55:42,980 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8520 tokens (最大允许: 1808)
2025-12-25 12:55:42,995 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8431 tokens (最大允许: 1808)
2025-12-25 12:55:43,011 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8487 tokens (最大允许: 1808)
2025-12-25 12:55:43,026 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8427 tokens (最大允许: 1808)
2025-12-25 12:55:43,041 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8427 tokens (最大允许: 1808)
2025-12-25 12:55:43,057 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8503 tokens (最大允许: 1808)
2025-12-25 12:55:43,072 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8432 tokens (最大允许: 1808)
2025-12-25 12:55:43,088 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 8434 tokens (最大允许: 1808)
2025-12-25 12:55:43,105 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8434 tokens (最大允许: 1808)
2025-12-25 12:55:43,121 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8427 tokens (最大允许: 1808)
2025-12-25 12:55:43,137 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8456 tokens (最大允许: 1808)
2025-12-25 12:55:43,153 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:43,170 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:43,186 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8498 tokens (最大允许: 1808)
2025-12-25 12:55:43,202 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8473 tokens (最大允许: 1808)
2025-12-25 12:55:43,218 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8442 tokens (最大允许: 1808)
2025-12-25 12:55:43,233 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8430 tokens (最大允许: 1808)
2025-12-25 12:55:43,249 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8430 tokens (最大允许: 1808)
2025-12-25 12:55:43,264 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8440 tokens (最大允许: 1808)
2025-12-25 12:55:43,279 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8443 tokens (最大允许: 1808)
2025-12-25 12:55:43,295 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8435 tokens (最大允许: 1808)
2025-12-25 12:55:43,310 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8443 tokens (最大允许: 1808)
2025-12-25 12:55:43,316 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 2931 tokens (最大允许: 1808)
2025-12-25 12:55:43,331 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8437 tokens (最大允许: 1808)
2025-12-25 12:55:43,346 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8430 tokens (最大允许: 1808)
2025-12-25 12:55:43,362 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8441 tokens (最大允许: 1808)
2025-12-25 12:55:43,382 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:43,398 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8407 tokens (最大允许: 1808)
2025-12-25 12:55:43,416 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8442 tokens (最大允许: 1808)
2025-12-25 12:55:43,432 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8427 tokens (最大允许: 1808)
2025-12-25 12:55:43,448 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8456 tokens (最大允许: 1808)
2025-12-25 12:55:43,464 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8445 tokens (最大允许: 1808)
2025-12-25 12:55:43,478 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8429 tokens (最大允许: 1808)
2025-12-25 12:55:43,495 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8429 tokens (最大允许: 1808)
2025-12-25 12:55:43,510 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8518 tokens (最大允许: 1808)
2025-12-25 12:55:43,526 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8461 tokens (最大允许: 1808)
2025-12-25 12:55:43,543 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8521 tokens (最大允许: 1808)
2025-12-25 12:55:43,559 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8427 tokens (最大允许: 1808)
2025-12-25 12:55:43,575 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8435 tokens (最大允许: 1808)
2025-12-25 12:55:43,593 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 8441 tokens (最大允许: 1808)
2025-12-25 12:55:43,609 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8445 tokens (最大允许: 1808)
2025-12-25 12:55:43,625 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8444 tokens (最大允许: 1808)
2025-12-25 12:55:43,640 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:43,656 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8486 tokens (最大允许: 1808)
2025-12-25 12:55:43,671 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8442 tokens (最大允许: 1808)
2025-12-25 12:55:43,684 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8520 tokens (最大允许: 1808)
2025-12-25 12:55:43,699 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8431 tokens (最大允许: 1808)
2025-12-25 12:55:43,715 - inference.local_inference - WARNING - 跳过超长prompt [112/122]: 8440 tokens (最大允许: 1808)
2025-12-25 12:55:43,731 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8451 tokens (最大允许: 1808)
2025-12-25 12:55:43,747 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8433 tokens (最大允许: 1808)
2025-12-25 12:55:43,763 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8435 tokens (最大允许: 1808)
2025-12-25 12:55:43,779 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8450 tokens (最大允许: 1808)
2025-12-25 12:55:43,794 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8428 tokens (最大允许: 1808)
2025-12-25 12:55:43,809 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8448 tokens (最大允许: 1808)
2025-12-25 12:55:43,824 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 8471 tokens (最大允许: 1808)
2025-12-25 12:55:43,839 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8444 tokens (最大允许: 1808)
2025-12-25 12:55:43,854 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8431 tokens (最大允许: 1808)
2025-12-25 12:55:43,869 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8430 tokens (最大允许: 1808)
2025-12-25 12:55:43,869 - inference.local_inference - WARNING - 共跳过 110/122 条超长prompts
2025-12-25 12:56:56,078 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 12:56:56,078 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 12:56:56,106 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8479 tokens (最大允许: 1808)
2025-12-25 12:56:56,126 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8485 tokens (最大允许: 1808)
2025-12-25 12:56:56,145 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:56:56,162 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8453 tokens (最大允许: 1808)
2025-12-25 12:56:56,179 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:56:56,194 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8467 tokens (最大允许: 1808)
2025-12-25 12:56:56,210 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:56:56,226 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:56:56,230 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 2080 tokens (最大允许: 1808)
2025-12-25 12:56:56,246 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:56:56,262 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8450 tokens (最大允许: 1808)
2025-12-25 12:56:56,278 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:56:56,294 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8470 tokens (最大允许: 1808)
2025-12-25 12:56:56,311 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8473 tokens (最大允许: 1808)
2025-12-25 12:56:56,326 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:56:56,342 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:56:56,358 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8454 tokens (最大允许: 1808)
2025-12-25 12:56:56,374 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:56:56,380 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 2981 tokens (最大允许: 1808)
2025-12-25 12:56:56,395 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:56:56,411 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8504 tokens (最大允许: 1808)
2025-12-25 12:56:56,427 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:56:56,442 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8453 tokens (最大允许: 1808)
2025-12-25 12:56:56,457 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8545 tokens (最大允许: 1808)
2025-12-25 12:56:56,474 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:56:56,492 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8526 tokens (最大允许: 1808)
2025-12-25 12:56:56,507 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8449 tokens (最大允许: 1808)
2025-12-25 12:56:56,523 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8477 tokens (最大允许: 1808)
2025-12-25 12:56:56,539 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8491 tokens (最大允许: 1808)
2025-12-25 12:56:56,555 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8455 tokens (最大允许: 1808)
2025-12-25 12:56:56,571 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:56:56,587 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:56:56,603 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:56:56,619 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8491 tokens (最大允许: 1808)
2025-12-25 12:56:56,635 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:56:56,651 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8453 tokens (最大允许: 1808)
2025-12-25 12:56:56,667 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8506 tokens (最大允许: 1808)
2025-12-25 12:56:56,682 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8499 tokens (最大允许: 1808)
2025-12-25 12:56:56,698 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8496 tokens (最大允许: 1808)
2025-12-25 12:56:56,714 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8476 tokens (最大允许: 1808)
2025-12-25 12:56:56,730 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:56:56,746 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8462 tokens (最大允许: 1808)
2025-12-25 12:56:56,762 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8465 tokens (最大允许: 1808)
2025-12-25 12:56:56,778 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:56:56,794 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:56:56,803 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 3679 tokens (最大允许: 1808)
2025-12-25 12:56:56,821 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8494 tokens (最大允许: 1808)
2025-12-25 12:56:56,838 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:56:56,856 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8478 tokens (最大允许: 1808)
2025-12-25 12:56:56,873 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8460 tokens (最大允许: 1808)
2025-12-25 12:56:56,889 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8490 tokens (最大允许: 1808)
2025-12-25 12:56:56,906 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8457 tokens (最大允许: 1808)
2025-12-25 12:56:56,922 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8454 tokens (最大允许: 1808)
2025-12-25 12:56:56,938 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8481 tokens (最大允许: 1808)
2025-12-25 12:56:56,953 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:56:56,969 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:56:56,987 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:56:57,003 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:56:57,018 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:56:57,037 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:56:57,054 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:56:57,070 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:56:57,085 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:56:57,101 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:56:57,118 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8439 tokens (最大允许: 1808)
2025-12-25 12:56:57,134 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8458 tokens (最大允许: 1808)
2025-12-25 12:56:57,150 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8447 tokens (最大允许: 1808)
2025-12-25 12:56:57,166 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8433 tokens (最大允许: 1808)
2025-12-25 12:56:57,182 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:56:57,198 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:56:57,215 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8487 tokens (最大允许: 1808)
2025-12-25 12:56:57,230 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8464 tokens (最大允许: 1808)
2025-12-25 12:56:57,246 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:56:57,264 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8493 tokens (最大允许: 1808)
2025-12-25 12:56:57,279 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8461 tokens (最大允许: 1808)
2025-12-25 12:56:57,295 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8468 tokens (最大允许: 1808)
2025-12-25 12:56:57,311 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8447 tokens (最大允许: 1808)
2025-12-25 12:56:57,326 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:56:57,343 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8453 tokens (最大允许: 1808)
2025-12-25 12:56:57,359 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:56:57,376 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8457 tokens (最大允许: 1808)
2025-12-25 12:56:57,391 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8467 tokens (最大允许: 1808)
2025-12-25 12:56:57,406 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:56:57,422 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8437 tokens (最大允许: 1808)
2025-12-25 12:56:57,437 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8450 tokens (最大允许: 1808)
2025-12-25 12:56:57,453 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8432 tokens (最大允许: 1808)
2025-12-25 12:56:57,469 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8460 tokens (最大允许: 1808)
2025-12-25 12:56:57,482 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8434 tokens (最大允许: 1808)
2025-12-25 12:56:57,499 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8435 tokens (最大允许: 1808)
2025-12-25 12:56:57,518 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:56:57,534 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:56:57,539 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 2776 tokens (最大允许: 1808)
2025-12-25 12:56:57,554 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8443 tokens (最大允许: 1808)
2025-12-25 12:56:57,571 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8480 tokens (最大允许: 1808)
2025-12-25 12:56:57,587 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8466 tokens (最大允许: 1808)
2025-12-25 12:56:57,603 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8444 tokens (最大允许: 1808)
2025-12-25 12:56:57,618 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8448 tokens (最大允许: 1808)
2025-12-25 12:56:57,635 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8464 tokens (最大允许: 1808)
2025-12-25 12:56:57,651 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8456 tokens (最大允许: 1808)
2025-12-25 12:56:57,666 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8451 tokens (最大允许: 1808)
2025-12-25 12:56:57,682 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:56:57,698 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8438 tokens (最大允许: 1808)
2025-12-25 12:56:57,714 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8446 tokens (最大允许: 1808)
2025-12-25 12:56:57,722 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 3916 tokens (最大允许: 1808)
2025-12-25 12:56:57,737 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:56:57,753 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8472 tokens (最大允许: 1808)
2025-12-25 12:56:57,769 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8436 tokens (最大允许: 1808)
2025-12-25 12:56:57,785 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8441 tokens (最大允许: 1808)
2025-12-25 12:56:57,802 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8467 tokens (最大允许: 1808)
2025-12-25 12:56:57,820 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8459 tokens (最大允许: 1808)
2025-12-25 12:56:57,838 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8488 tokens (最大允许: 1808)
2025-12-25 12:56:57,855 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8429 tokens (最大允许: 1808)
2025-12-25 12:56:57,871 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8449 tokens (最大允许: 1808)
2025-12-25 12:56:57,886 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:56:57,902 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:56:57,920 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8440 tokens (最大允许: 1808)
2025-12-25 12:56:57,937 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8458 tokens (最大允许: 1808)
2025-12-25 12:56:57,954 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8445 tokens (最大允许: 1808)
2025-12-25 12:56:57,970 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8474 tokens (最大允许: 1808)
2025-12-25 12:56:57,986 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8442 tokens (最大允许: 1808)
2025-12-25 12:56:58,002 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8452 tokens (最大允许: 1808)
2025-12-25 12:56:58,002 - inference.local_inference - WARNING - 共跳过 121/128 条超长prompts
2025-12-25 12:58:07,005 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 12:58:07,005 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 12:58:07,005 - __main__ - WARNING - ⚠️  230/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 12:58:07,006 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 12:58:07,082 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 12:58:07,082 - __main__ - INFO - ============================================================
2025-12-25 12:58:07,082 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 12:58:07,082 - __main__ - INFO - ============================================================
2025-12-25 12:58:07,082 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 12:58:07,082 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 12:58:07,082 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:58:48,990 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 12:58:48,990 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 12:58:48,990 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:59:19,477 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 12:59:19,478 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 12:59:19,478 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 12:59:19,692 - __main__ - INFO - 批次 [1409-1536] 本地推理完成
2025-12-25 12:59:19,693 - __main__ - INFO - 处理批次 [1537-1664/99842]
2025-12-25 12:59:19,693 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 12:59:19,693 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 12:59:32,654 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 12:59:32,654 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 12:59:53,313 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 12:59:53,314 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 12:59:53,314 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:00:49,252 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 13:00:49,253 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 13:00:49,253 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:01:36,221 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 13:01:36,221 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 13:01:36,222 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:02:01,578 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 13:02:01,578 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 13:02:01,578 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:02:26,288 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 13:02:26,288 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 13:02:26,288 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:03:08,712 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 13:03:08,713 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 13:03:08,713 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:03:29,939 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 13:03:29,939 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 13:03:29,939 - __main__ - INFO - 开始数据质量检查...
2025-12-25 13:03:29,939 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 13:03:29,940 - __main__ - INFO - ============================================================
2025-12-25 13:03:29,940 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 13:03:29,940 - __main__ - INFO - ============================================================
2025-12-25 13:03:29,940 - __main__ - INFO - 预检查数据完整性...
2025-12-25 13:03:29,940 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 13:03:29,940 - __main__ - INFO - Rejected非空率: 20/250 (8.0%)
2025-12-25 13:03:29,940 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 13:03:29,962 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 13:03:29,977 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 13:03:29,995 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 13:03:30,011 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 13:03:30,025 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 13:03:30,041 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_dyck_languages.jsonl
2025-12-25 13:03:30,041 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 13:03:33,536 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 13:03:33,570 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 13:03:34,596 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,596 - __main__ - INFO - 数据集名称: bbh
2025-12-25 13:03:34,596 - __main__ - INFO - 数据集路径: dataset/bbh/formal_fallacies.json
2025-12-25 13:03:34,596 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,596 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 13:03:34,596 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,596 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 13:03:34,596 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/formal_fallacies.json
2025-12-25 13:03:34,596 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,597 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 13:03:34,597 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 13:03:34,597 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 13:03:34,597 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 13:03:34,597 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,597 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 13:03:34,597 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,597 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 13:03:34,597 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,598 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 13:03:34,598 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 13:03:34,599 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,599 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 13:03:34,599 - __main__ - INFO - ============================================================
2025-12-25 13:03:34,599 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 13:03:34,599 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 13:03:34,599 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 13:03:39,013 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 13:03:39,013 - inference.local_inference - INFO - ============================================================
2025-12-25 13:03:39,013 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 13:03:39,013 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 13:03:39,013 - inference.local_inference - INFO - ============================================================
2025-12-25 13:04:54,270 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 13:05:17,731 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 13:05:17,732 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 13:09:09,582 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 13:09:09,582 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 13:09:09,592 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 2163 tokens (最大允许: 1808)
2025-12-25 13:09:09,614 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:09:09,634 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:09:09,651 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:09:09,669 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:09:09,685 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:09:09,702 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:09:09,719 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:09:09,734 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:09:09,750 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:09:09,755 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 2546 tokens (最大允许: 1808)
2025-12-25 13:09:09,761 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 2928 tokens (最大允许: 1808)
2025-12-25 13:09:09,778 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:09:09,796 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:09:09,813 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:09:09,829 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:09:09,844 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:09:09,860 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:09:09,876 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8433 tokens (最大允许: 1808)
2025-12-25 13:09:09,893 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:09:09,909 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:09:09,925 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:09:09,941 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8432 tokens (最大允许: 1808)
2025-12-25 13:09:09,957 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:09:09,973 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:09:09,988 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:09:10,004 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:09:10,022 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:09:10,039 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:09:10,055 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:09:10,071 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8433 tokens (最大允许: 1808)
2025-12-25 13:09:10,089 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8432 tokens (最大允许: 1808)
2025-12-25 13:09:10,106 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:09:10,122 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8434 tokens (最大允许: 1808)
2025-12-25 13:09:10,138 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:09:10,154 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:09:10,170 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:09:10,186 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:09:10,203 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:09:10,219 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8494 tokens (最大允许: 1808)
2025-12-25 13:09:10,236 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:09:10,253 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:09:10,269 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:09:10,285 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:09:10,301 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:09:10,317 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8452 tokens (最大允许: 1808)
2025-12-25 13:09:10,322 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 2060 tokens (最大允许: 1808)
2025-12-25 13:09:10,337 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:09:10,353 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8460 tokens (最大允许: 1808)
2025-12-25 13:09:10,369 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:09:10,374 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 2319 tokens (最大允许: 1808)
2025-12-25 13:09:10,389 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:09:10,405 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:09:10,409 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 1951 tokens (最大允许: 1808)
2025-12-25 13:09:10,413 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 1984 tokens (最大允许: 1808)
2025-12-25 13:09:10,429 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:09:10,445 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:09:10,460 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:09:10,475 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:09:10,493 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:09:10,508 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:09:10,523 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8483 tokens (最大允许: 1808)
2025-12-25 13:09:10,539 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:09:10,555 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8461 tokens (最大允许: 1808)
2025-12-25 13:09:10,570 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:09:10,580 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 5020 tokens (最大允许: 1808)
2025-12-25 13:09:10,596 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:09:10,612 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:09:10,628 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:09:10,644 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:09:10,648 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 1852 tokens (最大允许: 1808)
2025-12-25 13:09:10,663 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:09:10,679 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:09:10,694 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8500 tokens (最大允许: 1808)
2025-12-25 13:09:10,711 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:09:10,728 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:09:10,744 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:09:10,760 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8468 tokens (最大允许: 1808)
2025-12-25 13:09:10,777 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:09:10,797 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:09:10,814 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:09:10,832 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8481 tokens (最大允许: 1808)
2025-12-25 13:09:10,850 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:09:10,866 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8544 tokens (最大允许: 1808)
2025-12-25 13:09:10,870 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 2224 tokens (最大允许: 1808)
2025-12-25 13:09:10,886 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:09:10,891 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 2954 tokens (最大允许: 1808)
2025-12-25 13:09:10,909 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8495 tokens (最大允许: 1808)
2025-12-25 13:09:10,927 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:09:10,944 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:09:10,960 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8448 tokens (最大允许: 1808)
2025-12-25 13:09:10,977 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:09:10,994 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8460 tokens (最大允许: 1808)
2025-12-25 13:09:11,012 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:09:11,028 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8481 tokens (最大允许: 1808)
2025-12-25 13:09:11,044 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:09:11,060 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:09:11,076 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:09:11,092 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:09:11,108 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:09:11,124 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:09:11,139 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:09:11,156 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8497 tokens (最大允许: 1808)
2025-12-25 13:09:11,171 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8489 tokens (最大允许: 1808)
2025-12-25 13:09:11,187 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:09:11,203 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8517 tokens (最大允许: 1808)
2025-12-25 13:09:11,219 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:09:11,235 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:09:11,250 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:09:11,266 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:09:11,282 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:09:11,298 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:09:11,315 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:09:11,333 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:09:11,350 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:09:11,367 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:09:11,383 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:09:11,399 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8467 tokens (最大允许: 1808)
2025-12-25 13:09:11,415 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:09:11,430 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:09:11,447 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:09:11,463 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8461 tokens (最大允许: 1808)
2025-12-25 13:09:11,478 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8499 tokens (最大允许: 1808)
2025-12-25 13:09:11,494 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8504 tokens (最大允许: 1808)
2025-12-25 13:09:11,511 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:09:11,528 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8469 tokens (最大允许: 1808)
2025-12-25 13:09:11,545 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:09:11,546 - inference.local_inference - WARNING - 共跳过 127/128 条超长prompts
2025-12-25 13:10:07,526 - __main__ - INFO - 加载数据集: data/dpo_by_level/level1.jsonl
2025-12-25 13:10:07,531 - __main__ - INFO - 数据集加载成功（JSONL格式），共 404 条数据
2025-12-25 13:10:07,531 - __main__ - INFO - 数据字段: ['messages', 'rejected_response']
2025-12-25 13:10:07,531 - __main__ - INFO - ============================================================
2025-12-25 13:10:07,531 - __main__ - INFO - Step 3: 开始推理（批处理模式）
2025-12-25 13:10:07,531 - __main__ - INFO - ============================================================
2025-12-25 13:10:07,533 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: /home/metanew2/em_model/all-MiniLM-L6-v2
2025-12-25 13:10:07,552 - __main__ - ERROR - MemoryManager 初始化失败: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /home/metanew2/em_model/all-MiniLM-L6-v2.
2025-12-25 13:11:07,245 - __main__ - INFO - 批次 [1537-1664] 本地推理完成
2025-12-25 13:11:07,246 - __main__ - INFO - 处理批次 [1665-1792/99842]
2025-12-25 13:11:07,246 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 13:11:07,246 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 13:13:07,434 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 13:13:07,435 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 13:13:07,547 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8569 tokens (最大允许: 1808)
2025-12-25 13:13:07,653 - inference.local_inference - WARNING - 共跳过 1/128 条超长prompts
2025-12-25 13:15:44,924 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 13:15:44,925 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 13:15:44,949 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8484 tokens (最大允许: 1808)
2025-12-25 13:15:44,969 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:15:44,991 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8552 tokens (最大允许: 1808)
2025-12-25 13:15:45,010 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8536 tokens (最大允许: 1808)
2025-12-25 13:15:45,026 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8481 tokens (最大允许: 1808)
2025-12-25 13:15:45,042 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8524 tokens (最大允许: 1808)
2025-12-25 13:15:45,060 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8530 tokens (最大允许: 1808)
2025-12-25 13:15:45,077 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:45,093 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8525 tokens (最大允许: 1808)
2025-12-25 13:15:45,110 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8532 tokens (最大允许: 1808)
2025-12-25 13:15:45,126 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8506 tokens (最大允许: 1808)
2025-12-25 13:15:45,143 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8536 tokens (最大允许: 1808)
2025-12-25 13:15:45,159 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:45,175 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:15:45,190 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8581 tokens (最大允许: 1808)
2025-12-25 13:15:45,204 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8511 tokens (最大允许: 1808)
2025-12-25 13:15:45,220 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8509 tokens (最大允许: 1808)
2025-12-25 13:15:45,235 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8505 tokens (最大允许: 1808)
2025-12-25 13:15:45,250 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8537 tokens (最大允许: 1808)
2025-12-25 13:15:45,267 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8510 tokens (最大允许: 1808)
2025-12-25 13:15:45,283 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:15:45,299 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8544 tokens (最大允许: 1808)
2025-12-25 13:15:45,315 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8562 tokens (最大允许: 1808)
2025-12-25 13:15:45,330 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8510 tokens (最大允许: 1808)
2025-12-25 13:15:45,345 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8510 tokens (最大允许: 1808)
2025-12-25 13:15:45,361 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8534 tokens (最大允许: 1808)
2025-12-25 13:15:45,374 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8589 tokens (最大允许: 1808)
2025-12-25 13:15:45,389 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8523 tokens (最大允许: 1808)
2025-12-25 13:15:45,404 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8554 tokens (最大允许: 1808)
2025-12-25 13:15:45,422 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8594 tokens (最大允许: 1808)
2025-12-25 13:15:45,437 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:15:45,452 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8560 tokens (最大允许: 1808)
2025-12-25 13:15:45,467 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8516 tokens (最大允许: 1808)
2025-12-25 13:15:45,482 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8539 tokens (最大允许: 1808)
2025-12-25 13:15:45,497 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8541 tokens (最大允许: 1808)
2025-12-25 13:15:45,512 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:45,527 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8543 tokens (最大允许: 1808)
2025-12-25 13:15:45,542 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8545 tokens (最大允许: 1808)
2025-12-25 13:15:45,557 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8529 tokens (最大允许: 1808)
2025-12-25 13:15:45,572 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8515 tokens (最大允许: 1808)
2025-12-25 13:15:45,587 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8586 tokens (最大允许: 1808)
2025-12-25 13:15:45,603 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8556 tokens (最大允许: 1808)
2025-12-25 13:15:45,619 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8496 tokens (最大允许: 1808)
2025-12-25 13:15:45,635 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:45,651 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8502 tokens (最大允许: 1808)
2025-12-25 13:15:45,666 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:15:45,682 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8510 tokens (最大允许: 1808)
2025-12-25 13:15:45,697 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8500 tokens (最大允许: 1808)
2025-12-25 13:15:45,712 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:15:45,727 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8484 tokens (最大允许: 1808)
2025-12-25 13:15:45,731 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 2034 tokens (最大允许: 1808)
2025-12-25 13:15:45,745 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8526 tokens (最大允许: 1808)
2025-12-25 13:15:45,760 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8520 tokens (最大允许: 1808)
2025-12-25 13:15:45,775 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:15:45,789 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8511 tokens (最大允许: 1808)
2025-12-25 13:15:45,805 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8600 tokens (最大允许: 1808)
2025-12-25 13:15:45,820 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8533 tokens (最大允许: 1808)
2025-12-25 13:15:45,834 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8571 tokens (最大允许: 1808)
2025-12-25 13:15:45,850 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:15:45,865 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8533 tokens (最大允许: 1808)
2025-12-25 13:15:45,881 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8537 tokens (最大允许: 1808)
2025-12-25 13:15:45,897 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:45,913 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8536 tokens (最大允许: 1808)
2025-12-25 13:15:45,929 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8544 tokens (最大允许: 1808)
2025-12-25 13:15:45,945 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:45,960 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8564 tokens (最大允许: 1808)
2025-12-25 13:15:45,975 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8548 tokens (最大允许: 1808)
2025-12-25 13:15:45,990 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:15:46,004 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8517 tokens (最大允许: 1808)
2025-12-25 13:15:46,020 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8524 tokens (最大允许: 1808)
2025-12-25 13:15:46,035 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8506 tokens (最大允许: 1808)
2025-12-25 13:15:46,051 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8543 tokens (最大允许: 1808)
2025-12-25 13:15:46,067 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8559 tokens (最大允许: 1808)
2025-12-25 13:15:46,082 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8559 tokens (最大允许: 1808)
2025-12-25 13:15:46,098 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8526 tokens (最大允许: 1808)
2025-12-25 13:15:46,115 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8503 tokens (最大允许: 1808)
2025-12-25 13:15:46,131 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8526 tokens (最大允许: 1808)
2025-12-25 13:15:46,148 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:15:46,163 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8592 tokens (最大允许: 1808)
2025-12-25 13:15:46,179 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8526 tokens (最大允许: 1808)
2025-12-25 13:15:46,194 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8520 tokens (最大允许: 1808)
2025-12-25 13:15:46,209 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8557 tokens (最大允许: 1808)
2025-12-25 13:15:46,225 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:15:46,238 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8565 tokens (最大允许: 1808)
2025-12-25 13:15:46,253 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8529 tokens (最大允许: 1808)
2025-12-25 13:15:46,268 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8549 tokens (最大允许: 1808)
2025-12-25 13:15:46,284 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8497 tokens (最大允许: 1808)
2025-12-25 13:15:46,299 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8516 tokens (最大允许: 1808)
2025-12-25 13:15:46,315 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8534 tokens (最大允许: 1808)
2025-12-25 13:15:46,331 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8522 tokens (最大允许: 1808)
2025-12-25 13:15:46,346 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8504 tokens (最大允许: 1808)
2025-12-25 13:15:46,362 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8554 tokens (最大允许: 1808)
2025-12-25 13:15:46,377 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8553 tokens (最大允许: 1808)
2025-12-25 13:15:46,392 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8521 tokens (最大允许: 1808)
2025-12-25 13:15:46,407 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8592 tokens (最大允许: 1808)
2025-12-25 13:15:46,422 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:46,437 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8549 tokens (最大允许: 1808)
2025-12-25 13:15:46,452 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8539 tokens (最大允许: 1808)
2025-12-25 13:15:46,468 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8520 tokens (最大允许: 1808)
2025-12-25 13:15:46,482 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8502 tokens (最大允许: 1808)
2025-12-25 13:15:46,497 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8513 tokens (最大允许: 1808)
2025-12-25 13:15:46,513 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8535 tokens (最大允许: 1808)
2025-12-25 13:15:46,528 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8517 tokens (最大允许: 1808)
2025-12-25 13:15:46,542 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:15:46,557 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:15:46,575 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8517 tokens (最大允许: 1808)
2025-12-25 13:15:46,590 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8514 tokens (最大允许: 1808)
2025-12-25 13:15:46,604 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8548 tokens (最大允许: 1808)
2025-12-25 13:15:46,619 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:15:46,634 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:15:46,651 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8544 tokens (最大允许: 1808)
2025-12-25 13:15:46,659 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 4934 tokens (最大允许: 1808)
2025-12-25 13:15:46,674 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8522 tokens (最大允许: 1808)
2025-12-25 13:15:46,690 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8515 tokens (最大允许: 1808)
2025-12-25 13:15:46,704 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8540 tokens (最大允许: 1808)
2025-12-25 13:15:46,719 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8553 tokens (最大允许: 1808)
2025-12-25 13:15:46,734 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:15:46,749 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8516 tokens (最大允许: 1808)
2025-12-25 13:15:46,763 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8472 tokens (最大允许: 1808)
2025-12-25 13:15:46,778 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8504 tokens (最大允许: 1808)
2025-12-25 13:15:46,793 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8536 tokens (最大允许: 1808)
2025-12-25 13:15:46,808 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8571 tokens (最大允许: 1808)
2025-12-25 13:15:46,823 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8506 tokens (最大允许: 1808)
2025-12-25 13:15:46,838 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8513 tokens (最大允许: 1808)
2025-12-25 13:15:46,839 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 13:17:55,320 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 13:17:55,321 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 13:17:55,322 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 13:17:55,322 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 13:18:18,249 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 13:18:18,250 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 13:18:39,439 - __main__ - INFO - 加载数据集: data/dpo_by_level/level1.jsonl
2025-12-25 13:18:39,444 - __main__ - INFO - 数据集加载成功（JSONL格式），共 404 条数据
2025-12-25 13:18:39,444 - __main__ - INFO - 数据字段: ['messages', 'rejected_response']
2025-12-25 13:18:39,444 - __main__ - INFO - ============================================================
2025-12-25 13:18:39,444 - __main__ - INFO - Step 3: 开始推理（批处理模式）
2025-12-25 13:18:39,444 - __main__ - INFO - ============================================================
2025-12-25 13:18:39,446 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: /home/metanew2/em_model/all-MiniLM-L6-v2
2025-12-25 13:18:40,106 - __main__ - INFO - MemoryManager 初始化完成
2025-12-25 13:18:40,106 - __main__ - INFO - 批处理大小: 64
2025-12-25 13:18:40,106 - __main__ - INFO - ============================================================
2025-12-25 13:18:40,106 - __main__ - INFO - 步骤 1/3: 批量生成任务描述
2025-12-25 13:18:40,106 - __main__ - INFO - ============================================================
2025-12-25 13:18:40,108 - __main__ - INFO - 有效数据: 404 条
2025-12-25 13:18:40,108 - __main__ - INFO - 将分 7 批处理（每批 64 条）
2025-12-25 13:18:40,917 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-25 13:18:40,917 - inference.local_inference - INFO - ============================================================
2025-12-25 13:18:40,917 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 13:18:40,917 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 13:18:40,917 - inference.local_inference - INFO - ============================================================
2025-12-25 13:19:58,694 - inference.local_inference - ERROR - vLLM模型初始化失败: top_p must be in (0, 1], got 25.0.
Traceback (most recent call last):
  File "/home/metanew2/inference/local_inference.py", line 61, in get_vllm_model
    _sampling_params = SamplingParams(
                       ^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/sampling_params.py", line 364, in __post_init__
    self._verify_args()
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/sampling_params.py", line 395, in _verify_args
    raise ValueError(f"top_p must be in (0, 1], got {self.top_p}.")
ValueError: top_p must be in (0, 1], got 25.0.
2025-12-25 13:19:58,698 - __main__ - ERROR - 推理过程发生错误: top_p must be in (0, 1], got 25.0.
Traceback (most recent call last):
  File "/home/metanew2/stage_infer.py", line 216, in inference_with_memory
    batch_task_descs = batch_generate_task_descriptions(batch_questions)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/module/execute_module.py", line 130, in batch_generate_task_descriptions
    return batch_inference(prompts)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/metanew2/inference/local_inference.py", line 102, in batch_inference
    model, default_params = get_vllm_model()
                            ^^^^^^^^^^^^^^^^
  File "/home/metanew2/inference/local_inference.py", line 61, in get_vllm_model
    _sampling_params = SamplingParams(
                       ^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/sampling_params.py", line 364, in __post_init__
    self._verify_args()
  File "/root/miniconda3/envs/llm/lib/python3.11/site-packages/vllm/sampling_params.py", line 395, in _verify_args
    raise ValueError(f"top_p must be in (0, 1], got {self.top_p}.")
ValueError: top_p must be in (0, 1], got 25.0.
2025-12-25 13:20:02,094 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 13:20:02,121 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 13:23:04,585 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 13:23:04,585 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 13:23:04,611 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:23:04,630 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8486 tokens (最大允许: 1808)
2025-12-25 13:23:04,649 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8433 tokens (最大允许: 1808)
2025-12-25 13:23:04,666 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8448 tokens (最大允许: 1808)
2025-12-25 13:23:04,682 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8527 tokens (最大允许: 1808)
2025-12-25 13:23:04,698 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:23:04,717 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8484 tokens (最大允许: 1808)
2025-12-25 13:23:04,733 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:23:04,749 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:23:04,753 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 2238 tokens (最大允许: 1808)
2025-12-25 13:23:04,771 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8867 tokens (最大允许: 1808)
2025-12-25 13:23:04,787 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:23:04,805 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8494 tokens (最大允许: 1808)
2025-12-25 13:23:04,821 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:23:04,838 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8502 tokens (最大允许: 1808)
2025-12-25 13:23:04,854 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:23:04,871 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:23:04,886 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8495 tokens (最大允许: 1808)
2025-12-25 13:23:04,903 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8433 tokens (最大允许: 1808)
2025-12-25 13:23:04,919 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:23:04,935 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:23:04,951 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:23:04,968 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:23:04,983 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:23:04,998 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:23:05,014 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:23:05,030 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:23:05,046 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:23:05,055 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 4726 tokens (最大允许: 1808)
2025-12-25 13:23:05,071 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:23:05,087 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:23:05,104 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:23:05,122 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:23:05,139 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:23:05,156 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:23:05,174 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:23:05,190 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:23:05,206 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:23:05,221 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:23:05,239 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:23:05,256 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:23:05,275 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:23:05,291 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:23:05,308 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8504 tokens (最大允许: 1808)
2025-12-25 13:23:05,324 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:23:05,340 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:23:05,356 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:23:05,373 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:23:05,390 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:23:05,407 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8495 tokens (最大允许: 1808)
2025-12-25 13:23:05,427 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:23:05,444 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:23:05,459 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:23:05,475 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:23:05,491 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:23:05,508 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8468 tokens (最大允许: 1808)
2025-12-25 13:23:05,524 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8508 tokens (最大允许: 1808)
2025-12-25 13:23:05,527 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 1824 tokens (最大允许: 1808)
2025-12-25 13:23:05,543 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:23:05,559 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8515 tokens (最大允许: 1808)
2025-12-25 13:23:05,575 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8579 tokens (最大允许: 1808)
2025-12-25 13:23:05,592 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:23:05,609 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:23:05,623 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:23:05,638 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:23:05,654 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8476 tokens (最大允许: 1808)
2025-12-25 13:23:05,671 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:23:05,687 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:23:05,703 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:23:05,720 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8434 tokens (最大允许: 1808)
2025-12-25 13:23:05,724 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 1930 tokens (最大允许: 1808)
2025-12-25 13:23:05,741 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8447 tokens (最大允许: 1808)
2025-12-25 13:23:05,758 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:23:05,773 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:23:05,790 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8504 tokens (最大允许: 1808)
2025-12-25 13:23:05,817 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:23:05,835 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:23:05,851 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:23:05,867 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8493 tokens (最大允许: 1808)
2025-12-25 13:23:05,883 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:23:05,899 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:23:05,914 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:23:05,919 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 2113 tokens (最大允许: 1808)
2025-12-25 13:23:05,934 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8523 tokens (最大允许: 1808)
2025-12-25 13:23:05,950 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:23:05,965 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:23:05,981 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8489 tokens (最大允许: 1808)
2025-12-25 13:23:05,997 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:23:06,013 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:23:06,029 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8508 tokens (最大允许: 1808)
2025-12-25 13:23:06,045 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8452 tokens (最大允许: 1808)
2025-12-25 13:23:06,061 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:23:06,077 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8452 tokens (最大允许: 1808)
2025-12-25 13:23:06,093 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:23:06,111 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8460 tokens (最大允许: 1808)
2025-12-25 13:23:06,127 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:23:06,143 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8430 tokens (最大允许: 1808)
2025-12-25 13:23:06,159 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8434 tokens (最大允许: 1808)
2025-12-25 13:23:06,175 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:23:06,190 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:23:06,207 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:23:06,224 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:23:06,240 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:23:06,257 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:23:06,272 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:23:06,288 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:23:06,303 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:23:06,319 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:23:06,336 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:23:06,352 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:23:06,367 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:23:06,382 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8497 tokens (最大允许: 1808)
2025-12-25 13:23:06,398 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:23:06,413 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8432 tokens (最大允许: 1808)
2025-12-25 13:23:06,430 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:23:06,447 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:23:06,464 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:23:06,480 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:23:06,497 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:23:06,512 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:23:06,528 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:23:06,543 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8488 tokens (最大允许: 1808)
2025-12-25 13:23:06,559 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:23:06,575 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8486 tokens (最大允许: 1808)
2025-12-25 13:23:06,592 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:23:06,609 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:23:06,610 - inference.local_inference - WARNING - 共跳过 126/128 条超长prompts
2025-12-25 13:24:05,706 - __main__ - INFO - 加载数据集: data/dpo_by_level/level1.jsonl
2025-12-25 13:24:05,711 - __main__ - INFO - 数据集加载成功（JSONL格式），共 404 条数据
2025-12-25 13:24:05,711 - __main__ - INFO - 数据字段: ['messages', 'rejected_response']
2025-12-25 13:24:05,711 - __main__ - INFO - ============================================================
2025-12-25 13:24:05,712 - __main__ - INFO - Step 3: 开始推理（批处理模式）
2025-12-25 13:24:05,712 - __main__ - INFO - ============================================================
2025-12-25 13:24:05,714 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: /home/metanew2/em_model/all-MiniLM-L6-v2
2025-12-25 13:24:06,283 - __main__ - INFO - MemoryManager 初始化完成
2025-12-25 13:24:06,284 - __main__ - INFO - 批处理大小: 64
2025-12-25 13:24:06,284 - __main__ - INFO - ============================================================
2025-12-25 13:24:06,284 - __main__ - INFO - 步骤 1/3: 批量生成任务描述
2025-12-25 13:24:06,284 - __main__ - INFO - ============================================================
2025-12-25 13:24:06,286 - __main__ - INFO - 有效数据: 404 条
2025-12-25 13:24:06,286 - __main__ - INFO - 将分 7 批处理（每批 64 条）
2025-12-25 13:24:07,096 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 4,5
2025-12-25 13:24:07,096 - inference.local_inference - INFO - ============================================================
2025-12-25 13:24:07,096 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 13:24:07,096 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 13:24:07,096 - inference.local_inference - INFO - ============================================================
2025-12-25 13:25:02,703 - __main__ - INFO - 批次 [1665-1792] 本地推理完成
2025-12-25 13:25:02,703 - __main__ - INFO - 处理批次 [1793-1920/99842]
2025-12-25 13:25:02,704 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 13:25:02,704 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 13:25:20,523 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 13:25:20,523 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 13:25:26,332 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 13:28:23,935 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 13:28:23,936 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 13:28:23,960 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8501 tokens (最大允许: 1808)
2025-12-25 13:28:23,979 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8507 tokens (最大允许: 1808)
2025-12-25 13:28:23,998 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8533 tokens (最大允许: 1808)
2025-12-25 13:28:24,016 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8526 tokens (最大允许: 1808)
2025-12-25 13:28:24,032 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8501 tokens (最大允许: 1808)
2025-12-25 13:28:24,037 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 3067 tokens (最大允许: 1808)
2025-12-25 13:28:24,053 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8495 tokens (最大允许: 1808)
2025-12-25 13:28:24,068 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8567 tokens (最大允许: 1808)
2025-12-25 13:28:24,084 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8488 tokens (最大允许: 1808)
2025-12-25 13:28:24,100 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 8503 tokens (最大允许: 1808)
2025-12-25 13:28:24,115 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8560 tokens (最大允许: 1808)
2025-12-25 13:28:24,132 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8514 tokens (最大允许: 1808)
2025-12-25 13:28:24,147 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8527 tokens (最大允许: 1808)
2025-12-25 13:28:24,152 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 2814 tokens (最大允许: 1808)
2025-12-25 13:28:24,168 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8553 tokens (最大允许: 1808)
2025-12-25 13:28:24,183 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8529 tokens (最大允许: 1808)
2025-12-25 13:28:24,199 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8578 tokens (最大允许: 1808)
2025-12-25 13:28:24,205 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 2729 tokens (最大允许: 1808)
2025-12-25 13:28:24,220 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8524 tokens (最大允许: 1808)
2025-12-25 13:28:24,236 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8484 tokens (最大允许: 1808)
2025-12-25 13:28:24,251 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8552 tokens (最大允许: 1808)
2025-12-25 13:28:24,266 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:28:24,281 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8571 tokens (最大允许: 1808)
2025-12-25 13:28:24,296 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8539 tokens (最大允许: 1808)
2025-12-25 13:28:24,312 - inference.local_inference - WARNING - 跳过超长prompt [25/122]: 8510 tokens (最大允许: 1808)
2025-12-25 13:28:24,326 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8537 tokens (最大允许: 1808)
2025-12-25 13:28:24,342 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8536 tokens (最大允许: 1808)
2025-12-25 13:28:24,357 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8583 tokens (最大允许: 1808)
2025-12-25 13:28:24,374 - inference.local_inference - WARNING - 跳过超长prompt [29/122]: 8529 tokens (最大允许: 1808)
2025-12-25 13:28:24,391 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8513 tokens (最大允许: 1808)
2025-12-25 13:28:24,407 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8522 tokens (最大允许: 1808)
2025-12-25 13:28:24,423 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8483 tokens (最大允许: 1808)
2025-12-25 13:28:24,438 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8518 tokens (最大允许: 1808)
2025-12-25 13:28:24,454 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8522 tokens (最大允许: 1808)
2025-12-25 13:28:24,469 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8504 tokens (最大允许: 1808)
2025-12-25 13:28:24,486 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:28:24,502 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8542 tokens (最大允许: 1808)
2025-12-25 13:28:24,518 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8531 tokens (最大允许: 1808)
2025-12-25 13:28:24,534 - inference.local_inference - WARNING - 跳过超长prompt [39/122]: 8566 tokens (最大允许: 1808)
2025-12-25 13:28:24,550 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8550 tokens (最大允许: 1808)
2025-12-25 13:28:24,566 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:28:24,582 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:28:24,599 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 8513 tokens (最大允许: 1808)
2025-12-25 13:28:24,615 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8527 tokens (最大允许: 1808)
2025-12-25 13:28:24,631 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:28:24,646 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8545 tokens (最大允许: 1808)
2025-12-25 13:28:24,662 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8536 tokens (最大允许: 1808)
2025-12-25 13:28:24,678 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8526 tokens (最大允许: 1808)
2025-12-25 13:28:24,694 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8544 tokens (最大允许: 1808)
2025-12-25 13:28:24,709 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8511 tokens (最大允许: 1808)
2025-12-25 13:28:24,724 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8543 tokens (最大允许: 1808)
2025-12-25 13:28:24,740 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8550 tokens (最大允许: 1808)
2025-12-25 13:28:24,755 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8472 tokens (最大允许: 1808)
2025-12-25 13:28:24,770 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8546 tokens (最大允许: 1808)
2025-12-25 13:28:24,786 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8547 tokens (最大允许: 1808)
2025-12-25 13:28:24,801 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:28:24,815 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8493 tokens (最大允许: 1808)
2025-12-25 13:28:24,830 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8488 tokens (最大允许: 1808)
2025-12-25 13:28:24,846 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:28:24,861 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8586 tokens (最大允许: 1808)
2025-12-25 13:28:24,876 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8505 tokens (最大允许: 1808)
2025-12-25 13:28:24,891 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8503 tokens (最大允许: 1808)
2025-12-25 13:28:24,906 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8558 tokens (最大允许: 1808)
2025-12-25 13:28:24,922 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 8488 tokens (最大允许: 1808)
2025-12-25 13:28:24,939 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8540 tokens (最大允许: 1808)
2025-12-25 13:28:24,955 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8506 tokens (最大允许: 1808)
2025-12-25 13:28:24,970 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8499 tokens (最大允许: 1808)
2025-12-25 13:28:24,985 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8559 tokens (最大允许: 1808)
2025-12-25 13:28:25,001 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8532 tokens (最大允许: 1808)
2025-12-25 13:28:25,016 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8509 tokens (最大允许: 1808)
2025-12-25 13:28:25,032 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8535 tokens (最大允许: 1808)
2025-12-25 13:28:25,047 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8543 tokens (最大允许: 1808)
2025-12-25 13:28:25,062 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8565 tokens (最大允许: 1808)
2025-12-25 13:28:25,078 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8519 tokens (最大允许: 1808)
2025-12-25 13:28:25,094 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8539 tokens (最大允许: 1808)
2025-12-25 13:28:25,110 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8469 tokens (最大允许: 1808)
2025-12-25 13:28:25,127 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8505 tokens (最大允许: 1808)
2025-12-25 13:28:25,144 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8598 tokens (最大允许: 1808)
2025-12-25 13:28:25,160 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8572 tokens (最大允许: 1808)
2025-12-25 13:28:25,176 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 8507 tokens (最大允许: 1808)
2025-12-25 13:28:25,190 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8548 tokens (最大允许: 1808)
2025-12-25 13:28:25,207 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8527 tokens (最大允许: 1808)
2025-12-25 13:28:25,222 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8514 tokens (最大允许: 1808)
2025-12-25 13:28:25,236 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 8507 tokens (最大允许: 1808)
2025-12-25 13:28:25,252 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8521 tokens (最大允许: 1808)
2025-12-25 13:28:25,268 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8505 tokens (最大允许: 1808)
2025-12-25 13:28:25,284 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 8502 tokens (最大允许: 1808)
2025-12-25 13:28:25,302 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8536 tokens (最大允许: 1808)
2025-12-25 13:28:25,317 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8516 tokens (最大允许: 1808)
2025-12-25 13:28:25,332 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8516 tokens (最大允许: 1808)
2025-12-25 13:28:25,346 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8509 tokens (最大允许: 1808)
2025-12-25 13:28:25,362 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8534 tokens (最大允许: 1808)
2025-12-25 13:28:25,377 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:28:25,392 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8577 tokens (最大允许: 1808)
2025-12-25 13:28:25,407 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8530 tokens (最大允许: 1808)
2025-12-25 13:28:25,422 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8487 tokens (最大允许: 1808)
2025-12-25 13:28:25,438 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:28:25,454 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:28:25,468 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8556 tokens (最大允许: 1808)
2025-12-25 13:28:25,484 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8537 tokens (最大允许: 1808)
2025-12-25 13:28:25,500 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8567 tokens (最大允许: 1808)
2025-12-25 13:28:25,515 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 8499 tokens (最大允许: 1808)
2025-12-25 13:28:25,530 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8544 tokens (最大允许: 1808)
2025-12-25 13:28:25,545 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8517 tokens (最大允许: 1808)
2025-12-25 13:28:25,561 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8534 tokens (最大允许: 1808)
2025-12-25 13:28:25,577 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8503 tokens (最大允许: 1808)
2025-12-25 13:28:25,594 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8520 tokens (最大允许: 1808)
2025-12-25 13:28:25,611 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8526 tokens (最大允许: 1808)
2025-12-25 13:28:25,628 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:28:25,647 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8550 tokens (最大允许: 1808)
2025-12-25 13:28:25,663 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8525 tokens (最大允许: 1808)
2025-12-25 13:28:25,679 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8537 tokens (最大允许: 1808)
2025-12-25 13:28:25,694 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:28:25,709 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8498 tokens (最大允许: 1808)
2025-12-25 13:28:25,724 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8517 tokens (最大允许: 1808)
2025-12-25 13:28:25,742 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 8558 tokens (最大允许: 1808)
2025-12-25 13:28:25,758 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8478 tokens (最大允许: 1808)
2025-12-25 13:28:25,775 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8522 tokens (最大允许: 1808)
2025-12-25 13:28:25,791 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8507 tokens (最大允许: 1808)
2025-12-25 13:28:25,791 - inference.local_inference - WARNING - 共跳过 119/122 条超长prompts
2025-12-25 13:30:30,002 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 13:30:30,002 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 13:30:30,003 - __main__ - WARNING - ⚠️  243/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 13:30:30,003 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 13:30:30,090 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 13:30:30,090 - __main__ - INFO - ============================================================
2025-12-25 13:30:30,090 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 13:30:30,090 - __main__ - INFO - ============================================================
2025-12-25 13:30:30,090 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 13:30:30,090 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 13:30:30,090 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:30:51,810 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 13:30:51,811 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 13:30:51,811 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:31:16,698 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 13:31:16,699 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 13:31:16,699 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:31:37,628 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 13:31:37,629 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 13:31:37,629 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:32:34,484 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 13:32:34,485 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 13:32:34,485 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:33:12,461 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 13:33:12,462 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 13:33:12,462 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:33:35,764 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 13:33:35,765 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 13:33:35,765 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:34:00,940 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 13:34:00,941 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 13:34:00,941 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:34:48,057 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 13:34:48,058 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 13:34:48,058 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 13:35:13,726 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 13:35:13,726 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 13:35:13,754 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8489 tokens (最大允许: 1808)
2025-12-25 13:35:13,774 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8467 tokens (最大允许: 1808)
2025-12-25 13:35:13,792 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:35:13,810 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:35:13,816 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 3291 tokens (最大允许: 1808)
2025-12-25 13:35:13,832 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8504 tokens (最大允许: 1808)
2025-12-25 13:35:13,849 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8439 tokens (最大允许: 1808)
2025-12-25 13:35:13,866 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:35:13,884 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:35:13,901 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:35:13,918 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:35:13,936 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:35:13,953 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:35:13,970 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8452 tokens (最大允许: 1808)
2025-12-25 13:35:13,988 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:35:14,006 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8512 tokens (最大允许: 1808)
2025-12-25 13:35:14,023 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8490 tokens (最大允许: 1808)
2025-12-25 13:35:14,041 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:35:14,059 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:35:14,075 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:35:14,079 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 2130 tokens (最大允许: 1808)
2025-12-25 13:35:14,096 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:35:14,114 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8489 tokens (最大允许: 1808)
2025-12-25 13:35:14,132 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:35:14,151 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:35:14,169 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:35:14,187 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:35:14,203 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8469 tokens (最大允许: 1808)
2025-12-25 13:35:14,220 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:35:14,237 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8484 tokens (最大允许: 1808)
2025-12-25 13:35:14,255 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:35:14,272 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:35:14,281 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 4472 tokens (最大允许: 1808)
2025-12-25 13:35:14,299 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:35:14,316 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:35:14,334 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8447 tokens (最大允许: 1808)
2025-12-25 13:35:14,350 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:35:14,368 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:35:14,385 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:35:14,404 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:35:14,422 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8452 tokens (最大允许: 1808)
2025-12-25 13:35:14,440 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:35:14,458 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8520 tokens (最大允许: 1808)
2025-12-25 13:35:14,476 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:35:14,493 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8493 tokens (最大允许: 1808)
2025-12-25 13:35:14,510 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:35:14,527 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:35:14,533 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 3217 tokens (最大允许: 1808)
2025-12-25 13:35:14,550 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:35:14,563 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 5858 tokens (最大允许: 1808)
2025-12-25 13:35:14,580 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:35:14,598 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8479 tokens (最大允许: 1808)
2025-12-25 13:35:14,614 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8493 tokens (最大允许: 1808)
2025-12-25 13:35:14,633 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:35:14,650 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:35:14,667 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:35:14,684 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:35:14,703 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:35:14,720 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8512 tokens (最大允许: 1808)
2025-12-25 13:35:14,736 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8489 tokens (最大允许: 1808)
2025-12-25 13:35:14,754 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:35:14,771 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:35:14,788 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8493 tokens (最大允许: 1808)
2025-12-25 13:35:14,806 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:35:14,824 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:35:14,841 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:35:14,858 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:35:14,875 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:35:14,891 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8469 tokens (最大允许: 1808)
2025-12-25 13:35:14,908 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:35:14,926 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:35:14,944 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:35:14,960 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8490 tokens (最大允许: 1808)
2025-12-25 13:35:14,977 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8523 tokens (最大允许: 1808)
2025-12-25 13:35:14,994 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:35:15,014 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:35:15,031 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:35:15,048 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:35:15,065 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:35:15,081 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:35:15,098 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:35:15,114 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:35:15,130 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8469 tokens (最大允许: 1808)
2025-12-25 13:35:15,146 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:35:15,163 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:35:15,181 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:35:15,198 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:35:15,216 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:35:15,234 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:35:15,249 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 7392 tokens (最大允许: 1808)
2025-12-25 13:35:15,266 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:35:15,283 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8468 tokens (最大允许: 1808)
2025-12-25 13:35:15,306 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8488 tokens (最大允许: 1808)
2025-12-25 13:35:15,323 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8461 tokens (最大允许: 1808)
2025-12-25 13:35:15,340 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8479 tokens (最大允许: 1808)
2025-12-25 13:35:15,357 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:35:15,374 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:35:15,391 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:35:15,408 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:35:15,427 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:35:15,445 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8461 tokens (最大允许: 1808)
2025-12-25 13:35:15,462 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:35:15,481 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:35:15,498 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:35:15,515 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:35:15,533 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:35:15,550 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:35:15,568 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8483 tokens (最大允许: 1808)
2025-12-25 13:35:15,584 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:35:15,601 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:35:15,609 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 3671 tokens (最大允许: 1808)
2025-12-25 13:35:15,626 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:35:15,644 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:35:15,663 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:35:15,681 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:35:15,699 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:35:15,716 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:35:15,734 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:35:15,752 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:35:15,770 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:35:15,787 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:35:15,804 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:35:15,822 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:35:15,841 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8494 tokens (最大允许: 1808)
2025-12-25 13:35:15,859 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:35:15,859 - inference.local_inference - WARNING - 共跳过 125/128 条超长prompts
2025-12-25 13:35:30,253 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 13:35:30,254 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 13:35:30,254 - __main__ - INFO - 开始数据质量检查...
2025-12-25 13:35:30,254 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 13:35:30,254 - __main__ - INFO - ============================================================
2025-12-25 13:35:30,254 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 13:35:30,254 - __main__ - INFO - ============================================================
2025-12-25 13:35:30,255 - __main__ - INFO - 预检查数据完整性...
2025-12-25 13:35:30,255 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 13:35:30,255 - __main__ - INFO - Rejected非空率: 7/250 (2.8%)
2025-12-25 13:35:30,255 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 13:35:30,277 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 13:35:30,293 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 13:35:30,309 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 13:35:30,328 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 13:35:30,344 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 13:35:30,361 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_formal_fallacies.jsonl
2025-12-25 13:35:30,361 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 13:35:34,095 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 13:35:34,130 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 13:35:35,165 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,165 - __main__ - INFO - 数据集名称: bbh
2025-12-25 13:35:35,165 - __main__ - INFO - 数据集路径: dataset/bbh/geometric_shapes.json
2025-12-25 13:35:35,165 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,165 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 13:35:35,165 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,165 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 13:35:35,165 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/geometric_shapes.json
2025-12-25 13:35:35,165 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,166 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 13:35:35,166 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 13:35:35,166 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 13:35:35,166 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 13:35:35,166 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,166 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 13:35:35,166 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,166 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 13:35:35,166 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,167 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 13:35:35,167 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 13:35:35,167 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,167 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 13:35:35,167 - __main__ - INFO - ============================================================
2025-12-25 13:35:35,167 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 13:35:35,167 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 13:35:35,167 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 13:35:39,570 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 13:35:39,571 - inference.local_inference - INFO - ============================================================
2025-12-25 13:35:39,571 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 13:35:39,571 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 13:35:39,571 - inference.local_inference - INFO - ============================================================
2025-12-25 13:36:55,969 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 13:37:12,177 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 13:37:12,178 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 13:37:20,997 - __main__ - INFO - 批次 [1793-1920] 本地推理完成
2025-12-25 13:37:20,997 - __main__ - INFO - 处理批次 [1921-2048/99842]
2025-12-25 13:37:20,997 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 13:37:20,997 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 13:37:35,235 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 13:37:35,235 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 13:47:28,516 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 13:47:28,516 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 13:47:28,542 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:47:28,562 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:47:28,582 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:47:28,588 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 2532 tokens (最大允许: 1808)
2025-12-25 13:47:28,593 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 2389 tokens (最大允许: 1808)
2025-12-25 13:47:28,611 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8503 tokens (最大允许: 1808)
2025-12-25 13:47:28,629 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8460 tokens (最大允许: 1808)
2025-12-25 13:47:28,648 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:47:28,665 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8499 tokens (最大允许: 1808)
2025-12-25 13:47:28,684 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:47:28,702 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8483 tokens (最大允许: 1808)
2025-12-25 13:47:28,720 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:47:28,737 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8448 tokens (最大允许: 1808)
2025-12-25 13:47:28,755 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8467 tokens (最大允许: 1808)
2025-12-25 13:47:28,772 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:47:28,791 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:47:28,809 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8430 tokens (最大允许: 1808)
2025-12-25 13:47:28,829 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:47:28,847 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:47:28,866 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:47:28,890 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:47:28,908 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8490 tokens (最大允许: 1808)
2025-12-25 13:47:28,927 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8447 tokens (最大允许: 1808)
2025-12-25 13:47:28,944 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8468 tokens (最大允许: 1808)
2025-12-25 13:47:28,962 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:47:28,979 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:47:28,996 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:47:29,014 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:47:29,030 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:47:29,035 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 2005 tokens (最大允许: 1808)
2025-12-25 13:47:29,052 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:47:29,070 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:47:29,087 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:47:29,104 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:47:29,121 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8496 tokens (最大允许: 1808)
2025-12-25 13:47:29,138 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:47:29,157 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:47:29,175 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:47:29,193 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:47:29,210 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:47:29,228 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8468 tokens (最大允许: 1808)
2025-12-25 13:47:29,246 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:47:29,265 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:47:29,282 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:29,300 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8452 tokens (最大允许: 1808)
2025-12-25 13:47:29,315 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 5617 tokens (最大允许: 1808)
2025-12-25 13:47:29,332 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:47:29,351 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:47:29,371 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:47:29,389 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8461 tokens (最大允许: 1808)
2025-12-25 13:47:29,407 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:47:29,425 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8460 tokens (最大允许: 1808)
2025-12-25 13:47:29,441 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:47:29,459 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:29,476 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:47:29,495 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:29,513 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8484 tokens (最大允许: 1808)
2025-12-25 13:47:29,531 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:47:29,549 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:47:29,568 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8432 tokens (最大允许: 1808)
2025-12-25 13:47:29,586 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8515 tokens (最大允许: 1808)
2025-12-25 13:47:29,602 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8472 tokens (最大允许: 1808)
2025-12-25 13:47:29,621 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:47:29,640 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:47:29,659 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8467 tokens (最大允许: 1808)
2025-12-25 13:47:29,679 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8472 tokens (最大允许: 1808)
2025-12-25 13:47:29,698 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:47:29,716 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:47:29,736 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8469 tokens (最大允许: 1808)
2025-12-25 13:47:29,754 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:47:29,771 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:47:29,789 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:47:29,808 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:47:29,827 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:47:29,845 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8493 tokens (最大允许: 1808)
2025-12-25 13:47:29,863 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:47:29,881 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:47:29,899 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8472 tokens (最大允许: 1808)
2025-12-25 13:47:29,917 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:47:29,936 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8495 tokens (最大允许: 1808)
2025-12-25 13:47:29,955 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:47:29,960 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 2461 tokens (最大允许: 1808)
2025-12-25 13:47:29,980 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:47:29,998 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:47:30,016 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:30,034 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8472 tokens (最大允许: 1808)
2025-12-25 13:47:30,051 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:47:30,055 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 2052 tokens (最大允许: 1808)
2025-12-25 13:47:30,073 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:47:30,091 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:47:30,110 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:47:30,128 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:47:30,146 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8525 tokens (最大允许: 1808)
2025-12-25 13:47:30,163 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8496 tokens (最大允许: 1808)
2025-12-25 13:47:30,180 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8455 tokens (最大允许: 1808)
2025-12-25 13:47:30,197 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8476 tokens (最大允许: 1808)
2025-12-25 13:47:30,216 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8501 tokens (最大允许: 1808)
2025-12-25 13:47:30,235 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8481 tokens (最大允许: 1808)
2025-12-25 13:47:30,254 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8446 tokens (最大允许: 1808)
2025-12-25 13:47:30,272 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:47:30,290 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8539 tokens (最大允许: 1808)
2025-12-25 13:47:30,308 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:47:30,325 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:47:30,343 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8448 tokens (最大允许: 1808)
2025-12-25 13:47:30,360 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:47:30,377 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:47:30,394 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:47:30,412 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8478 tokens (最大允许: 1808)
2025-12-25 13:47:30,429 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8450 tokens (最大允许: 1808)
2025-12-25 13:47:30,447 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8490 tokens (最大允许: 1808)
2025-12-25 13:47:30,464 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8529 tokens (最大允许: 1808)
2025-12-25 13:47:30,482 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8502 tokens (最大允许: 1808)
2025-12-25 13:47:30,500 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:47:30,518 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:47:30,534 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8479 tokens (最大允许: 1808)
2025-12-25 13:47:30,553 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8519 tokens (最大允许: 1808)
2025-12-25 13:47:30,570 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:47:30,589 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:47:30,607 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:47:30,626 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8525 tokens (最大允许: 1808)
2025-12-25 13:47:30,631 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 2573 tokens (最大允许: 1808)
2025-12-25 13:47:30,649 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8526 tokens (最大允许: 1808)
2025-12-25 13:47:30,667 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:47:30,684 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8493 tokens (最大允许: 1808)
2025-12-25 13:47:30,703 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8441 tokens (最大允许: 1808)
2025-12-25 13:47:30,721 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8471 tokens (最大允许: 1808)
2025-12-25 13:47:30,738 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:47:30,738 - inference.local_inference - WARNING - 共跳过 127/128 条超长prompts
2025-12-25 13:47:33,737 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 13:47:33,737 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 13:47:33,763 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8609 tokens (最大允许: 1808)
2025-12-25 13:47:33,783 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8530 tokens (最大允许: 1808)
2025-12-25 13:47:33,800 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8537 tokens (最大允许: 1808)
2025-12-25 13:47:33,816 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:33,830 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8563 tokens (最大允许: 1808)
2025-12-25 13:47:33,844 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8581 tokens (最大允许: 1808)
2025-12-25 13:47:33,860 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8516 tokens (最大允许: 1808)
2025-12-25 13:47:33,875 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8593 tokens (最大允许: 1808)
2025-12-25 13:47:33,891 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8535 tokens (最大允许: 1808)
2025-12-25 13:47:33,907 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8544 tokens (最大允许: 1808)
2025-12-25 13:47:33,922 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8596 tokens (最大允许: 1808)
2025-12-25 13:47:33,938 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:47:33,954 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8555 tokens (最大允许: 1808)
2025-12-25 13:47:33,970 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8551 tokens (最大允许: 1808)
2025-12-25 13:47:33,984 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8548 tokens (最大允许: 1808)
2025-12-25 13:47:34,000 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8554 tokens (最大允许: 1808)
2025-12-25 13:47:34,014 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8583 tokens (最大允许: 1808)
2025-12-25 13:47:34,030 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8648 tokens (最大允许: 1808)
2025-12-25 13:47:34,045 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8563 tokens (最大允许: 1808)
2025-12-25 13:47:34,060 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:47:34,074 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8557 tokens (最大允许: 1808)
2025-12-25 13:47:34,089 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8622 tokens (最大允许: 1808)
2025-12-25 13:47:34,105 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:47:34,122 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8622 tokens (最大允许: 1808)
2025-12-25 13:47:34,138 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8557 tokens (最大允许: 1808)
2025-12-25 13:47:34,153 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:47:34,168 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8569 tokens (最大允许: 1808)
2025-12-25 13:47:34,184 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8569 tokens (最大允许: 1808)
2025-12-25 13:47:34,198 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8536 tokens (最大允许: 1808)
2025-12-25 13:47:34,203 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 2643 tokens (最大允许: 1808)
2025-12-25 13:47:34,219 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8556 tokens (最大允许: 1808)
2025-12-25 13:47:34,234 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8552 tokens (最大允许: 1808)
2025-12-25 13:47:34,249 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8554 tokens (最大允许: 1808)
2025-12-25 13:47:34,265 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8569 tokens (最大允许: 1808)
2025-12-25 13:47:34,280 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8541 tokens (最大允许: 1808)
2025-12-25 13:47:34,295 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8596 tokens (最大允许: 1808)
2025-12-25 13:47:34,310 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:47:34,326 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8540 tokens (最大允许: 1808)
2025-12-25 13:47:34,341 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:34,357 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8583 tokens (最大允许: 1808)
2025-12-25 13:47:34,372 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8543 tokens (最大允许: 1808)
2025-12-25 13:47:34,387 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8539 tokens (最大允许: 1808)
2025-12-25 13:47:34,401 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:34,417 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:47:34,433 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8551 tokens (最大允许: 1808)
2025-12-25 13:47:34,449 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8555 tokens (最大允许: 1808)
2025-12-25 13:47:34,467 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:47:34,483 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8583 tokens (最大允许: 1808)
2025-12-25 13:47:34,500 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8582 tokens (最大允许: 1808)
2025-12-25 13:47:34,515 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8619 tokens (最大允许: 1808)
2025-12-25 13:47:34,530 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8582 tokens (最大允许: 1808)
2025-12-25 13:47:34,545 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:47:34,557 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8569 tokens (最大允许: 1808)
2025-12-25 13:47:34,572 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:47:34,591 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:34,608 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:47:34,624 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8583 tokens (最大允许: 1808)
2025-12-25 13:47:34,641 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8549 tokens (最大允许: 1808)
2025-12-25 13:47:34,657 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:47:34,672 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8542 tokens (最大允许: 1808)
2025-12-25 13:47:34,688 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:47:34,704 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8556 tokens (最大允许: 1808)
2025-12-25 13:47:34,719 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:47:34,735 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8554 tokens (最大允许: 1808)
2025-12-25 13:47:34,750 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8549 tokens (最大允许: 1808)
2025-12-25 13:47:34,766 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8555 tokens (最大允许: 1808)
2025-12-25 13:47:34,781 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:34,796 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8539 tokens (最大允许: 1808)
2025-12-25 13:47:34,812 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8529 tokens (最大允许: 1808)
2025-12-25 13:47:34,828 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8555 tokens (最大允许: 1808)
2025-12-25 13:47:34,845 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:47:34,860 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:34,876 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:34,890 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:34,905 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8539 tokens (最大允许: 1808)
2025-12-25 13:47:34,921 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8544 tokens (最大允许: 1808)
2025-12-25 13:47:34,936 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8540 tokens (最大允许: 1808)
2025-12-25 13:47:34,951 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:34,967 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8549 tokens (最大允许: 1808)
2025-12-25 13:47:34,983 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8622 tokens (最大允许: 1808)
2025-12-25 13:47:34,999 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:47:35,014 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8518 tokens (最大允许: 1808)
2025-12-25 13:47:35,030 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8525 tokens (最大允许: 1808)
2025-12-25 13:47:35,045 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:35,061 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8541 tokens (最大允许: 1808)
2025-12-25 13:47:35,077 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8536 tokens (最大允许: 1808)
2025-12-25 13:47:35,093 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8609 tokens (最大允许: 1808)
2025-12-25 13:47:35,108 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8557 tokens (最大允许: 1808)
2025-12-25 13:47:35,124 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8567 tokens (最大允许: 1808)
2025-12-25 13:47:35,139 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8582 tokens (最大允许: 1808)
2025-12-25 13:47:35,154 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8515 tokens (最大允许: 1808)
2025-12-25 13:47:35,169 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:47:35,185 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8570 tokens (最大允许: 1808)
2025-12-25 13:47:35,201 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8554 tokens (最大允许: 1808)
2025-12-25 13:47:35,216 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8583 tokens (最大允许: 1808)
2025-12-25 13:47:35,231 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8544 tokens (最大允许: 1808)
2025-12-25 13:47:35,247 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:47:35,262 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8582 tokens (最大允许: 1808)
2025-12-25 13:47:35,277 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8583 tokens (最大允许: 1808)
2025-12-25 13:47:35,293 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8515 tokens (最大允许: 1808)
2025-12-25 13:47:35,308 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8568 tokens (最大允许: 1808)
2025-12-25 13:47:35,323 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8594 tokens (最大允许: 1808)
2025-12-25 13:47:35,339 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8550 tokens (最大允许: 1808)
2025-12-25 13:47:35,354 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8618 tokens (最大允许: 1808)
2025-12-25 13:47:35,370 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:47:35,386 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8492 tokens (最大允许: 1808)
2025-12-25 13:47:35,401 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8582 tokens (最大允许: 1808)
2025-12-25 13:47:35,417 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8553 tokens (最大允许: 1808)
2025-12-25 13:47:35,433 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8551 tokens (最大允许: 1808)
2025-12-25 13:47:35,448 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:47:35,463 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8569 tokens (最大允许: 1808)
2025-12-25 13:47:35,478 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8594 tokens (最大允许: 1808)
2025-12-25 13:47:35,493 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8538 tokens (最大允许: 1808)
2025-12-25 13:47:35,509 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:47:35,524 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8517 tokens (最大允许: 1808)
2025-12-25 13:47:35,540 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8634 tokens (最大允许: 1808)
2025-12-25 13:47:35,557 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8551 tokens (最大允许: 1808)
2025-12-25 13:47:35,572 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:35,587 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8564 tokens (最大允许: 1808)
2025-12-25 13:47:35,603 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8582 tokens (最大允许: 1808)
2025-12-25 13:47:35,619 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8568 tokens (最大允许: 1808)
2025-12-25 13:47:35,634 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8491 tokens (最大允许: 1808)
2025-12-25 13:47:35,650 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8553 tokens (最大允许: 1808)
2025-12-25 13:47:35,666 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8609 tokens (最大允许: 1808)
2025-12-25 13:47:35,681 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8609 tokens (最大允许: 1808)
2025-12-25 13:47:35,698 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8531 tokens (最大允许: 1808)
2025-12-25 13:47:35,698 - inference.local_inference - WARNING - 共跳过 126/128 条超长prompts
2025-12-25 13:49:27,133 - __main__ - INFO - 批次 [1921-2048] 本地推理完成
2025-12-25 13:49:27,134 - __main__ - INFO - 处理批次 [2049-2176/99842]
2025-12-25 13:49:27,134 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 13:49:27,134 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 13:49:31,165 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 13:49:31,165 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 13:49:31,166 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 13:49:31,166 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 13:49:40,243 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 13:49:40,244 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 13:49:46,836 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 13:49:46,837 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 13:50:13,181 - __main__ - INFO - 任务描述生成完成: 404 条
2025-12-25 13:50:13,239 - __main__ - INFO - 任务描述已保存到: /home/metanew2/output/task_descriptions.json
2025-12-25 13:50:13,239 - __main__ - INFO - ============================================================
2025-12-25 13:50:13,239 - __main__ - INFO - 步骤 2/3: 解析任务描述并检索原则
2025-12-25 13:50:13,239 - __main__ - INFO - ============================================================
2025-12-25 13:50:15,135 - __main__ - WARNING - 第 2 项: JSON解析失败
2025-12-25 13:50:15,135 - __main__ - WARNING -   候选JSON数量: 4
2025-12-25 13:50:15,135 - __main__ - WARNING -   最后一个候选: {{
  "taskDescription": {{
    "description": "Simplify a trigonometric expression."
  }}
}}...
2025-12-25 13:50:23,059 - __main__ - WARNING - 第 8 项: JSON解析失败
2025-12-25 13:50:23,059 - __main__ - WARNING -   候选JSON数量: 3
2025-12-25 13:50:23,059 - __main__ - WARNING -   最后一个候选: {{
  "taskDescription": {{
    "description": "Determine the tangent of an angle in a triangle given the cosine of another angle and the lengths of tw...
2025-12-25 13:50:34,135 - __main__ - WARNING - 第 16 项: JSON解析失败
2025-12-25 13:50:34,136 - __main__ - WARNING -   候选JSON数量: 3
2025-12-25 13:50:34,136 - __main__ - WARNING -   最后一个候选: {{
  "taskDescription": {{
    "description": "Find the length of a side in a quadrilateral using given angles and one side length."
  }}
}}...
2025-12-25 13:59:27,117 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 13:59:27,117 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 13:59:27,145 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:59:27,165 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:59:27,185 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:59:27,202 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:59:27,220 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:59:27,238 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:59:27,256 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:59:27,274 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:59:27,291 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8472 tokens (最大允许: 1808)
2025-12-25 13:59:27,308 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8494 tokens (最大允许: 1808)
2025-12-25 13:59:27,327 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:59:27,344 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8445 tokens (最大允许: 1808)
2025-12-25 13:59:27,361 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:59:27,383 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:59:27,402 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:59:27,422 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:59:27,440 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:59:27,447 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 2823 tokens (最大允许: 1808)
2025-12-25 13:59:27,466 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:59:27,495 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:59:27,520 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8460 tokens (最大允许: 1808)
2025-12-25 13:59:27,540 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:59:27,559 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:59:27,577 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8438 tokens (最大允许: 1808)
2025-12-25 13:59:27,594 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:59:27,612 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:59:27,631 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:59:27,648 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:59:27,669 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8481 tokens (最大允许: 1808)
2025-12-25 13:59:27,688 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8433 tokens (最大允许: 1808)
2025-12-25 13:59:27,692 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 2166 tokens (最大允许: 1808)
2025-12-25 13:59:27,715 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8477 tokens (最大允许: 1808)
2025-12-25 13:59:27,734 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:59:27,753 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:59:27,775 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8431 tokens (最大允许: 1808)
2025-12-25 13:59:27,793 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:59:27,817 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:59:27,842 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8467 tokens (最大允许: 1808)
2025-12-25 13:59:27,860 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8490 tokens (最大允许: 1808)
2025-12-25 13:59:27,878 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:59:27,897 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:59:27,915 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:59:27,936 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:59:27,953 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:59:27,971 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:59:27,988 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 7579 tokens (最大允许: 1808)
2025-12-25 13:59:28,006 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8479 tokens (最大允许: 1808)
2025-12-25 13:59:28,024 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8498 tokens (最大允许: 1808)
2025-12-25 13:59:28,042 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:59:28,058 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8469 tokens (最大允许: 1808)
2025-12-25 13:59:28,078 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:59:28,097 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8469 tokens (最大允许: 1808)
2025-12-25 13:59:28,115 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8464 tokens (最大允许: 1808)
2025-12-25 13:59:28,134 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:59:28,153 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:59:28,172 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8461 tokens (最大允许: 1808)
2025-12-25 13:59:28,192 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8435 tokens (最大允许: 1808)
2025-12-25 13:59:28,212 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:59:28,231 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8486 tokens (最大允许: 1808)
2025-12-25 13:59:28,251 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8462 tokens (最大允许: 1808)
2025-12-25 13:59:28,269 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8457 tokens (最大允许: 1808)
2025-12-25 13:59:28,289 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:59:28,308 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:59:28,327 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8458 tokens (最大允许: 1808)
2025-12-25 13:59:28,345 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 7665 tokens (最大允许: 1808)
2025-12-25 13:59:28,364 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8468 tokens (最大允许: 1808)
2025-12-25 13:59:28,384 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8463 tokens (最大允许: 1808)
2025-12-25 13:59:28,404 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:59:28,422 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:59:28,441 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:59:28,462 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:59:28,480 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8516 tokens (最大允许: 1808)
2025-12-25 13:59:28,498 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:59:28,521 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:59:28,544 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8569 tokens (最大允许: 1808)
2025-12-25 13:59:28,561 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:59:28,577 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:59:28,595 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:59:28,612 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8524 tokens (最大允许: 1808)
2025-12-25 13:59:28,628 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8456 tokens (最大允许: 1808)
2025-12-25 13:59:28,645 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8482 tokens (最大允许: 1808)
2025-12-25 13:59:28,661 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8488 tokens (最大允许: 1808)
2025-12-25 13:59:28,677 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8451 tokens (最大允许: 1808)
2025-12-25 13:59:28,694 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8476 tokens (最大允许: 1808)
2025-12-25 13:59:28,712 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:59:28,729 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8551 tokens (最大允许: 1808)
2025-12-25 13:59:28,745 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8485 tokens (最大允许: 1808)
2025-12-25 13:59:28,763 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8480 tokens (最大允许: 1808)
2025-12-25 13:59:28,779 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:59:28,796 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8475 tokens (最大允许: 1808)
2025-12-25 13:59:28,812 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8487 tokens (最大允许: 1808)
2025-12-25 13:59:28,829 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:59:28,846 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8454 tokens (最大允许: 1808)
2025-12-25 13:59:28,864 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8437 tokens (最大允许: 1808)
2025-12-25 13:59:28,885 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8453 tokens (最大允许: 1808)
2025-12-25 13:59:28,902 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8443 tokens (最大允许: 1808)
2025-12-25 13:59:28,919 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:59:28,936 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8546 tokens (最大允许: 1808)
2025-12-25 13:59:28,954 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:59:28,972 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8470 tokens (最大允许: 1808)
2025-12-25 13:59:28,989 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:59:29,007 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:59:29,024 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:59:29,042 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8459 tokens (最大允许: 1808)
2025-12-25 13:59:29,061 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8479 tokens (最大允许: 1808)
2025-12-25 13:59:29,081 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:59:29,101 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8440 tokens (最大允许: 1808)
2025-12-25 13:59:29,120 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8447 tokens (最大允许: 1808)
2025-12-25 13:59:29,136 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8481 tokens (最大允许: 1808)
2025-12-25 13:59:29,153 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:59:29,169 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8467 tokens (最大允许: 1808)
2025-12-25 13:59:29,186 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8449 tokens (最大允许: 1808)
2025-12-25 13:59:29,203 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8442 tokens (最大允许: 1808)
2025-12-25 13:59:29,219 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8444 tokens (最大允许: 1808)
2025-12-25 13:59:29,236 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8466 tokens (最大允许: 1808)
2025-12-25 13:59:29,253 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8465 tokens (最大允许: 1808)
2025-12-25 13:59:29,270 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8473 tokens (最大允许: 1808)
2025-12-25 13:59:29,287 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8526 tokens (最大允许: 1808)
2025-12-25 13:59:29,304 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8474 tokens (最大允许: 1808)
2025-12-25 13:59:29,321 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8448 tokens (最大允许: 1808)
2025-12-25 13:59:29,337 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8447 tokens (最大允许: 1808)
2025-12-25 13:59:29,355 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8436 tokens (最大允许: 1808)
2025-12-25 13:59:29,356 - inference.local_inference - WARNING - 共跳过 122/128 条超长prompts
2025-12-25 13:59:48,516 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 13:59:48,517 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 13:59:48,555 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:59:48,588 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8616 tokens (最大允许: 1808)
2025-12-25 13:59:48,616 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8566 tokens (最大允许: 1808)
2025-12-25 13:59:48,646 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8661 tokens (最大允许: 1808)
2025-12-25 13:59:48,675 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:59:48,691 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8531 tokens (最大允许: 1808)
2025-12-25 13:59:48,709 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:59:48,723 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8491 tokens (最大允许: 1808)
2025-12-25 13:59:48,740 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 8530 tokens (最大允许: 1808)
2025-12-25 13:59:48,758 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8608 tokens (最大允许: 1808)
2025-12-25 13:59:48,774 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:59:48,791 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:48,806 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 8491 tokens (最大允许: 1808)
2025-12-25 13:59:48,822 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8550 tokens (最大允许: 1808)
2025-12-25 13:59:48,837 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8570 tokens (最大允许: 1808)
2025-12-25 13:59:48,853 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8582 tokens (最大允许: 1808)
2025-12-25 13:59:48,869 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8553 tokens (最大允许: 1808)
2025-12-25 13:59:48,886 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:48,902 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:59:48,918 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:59:48,934 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8539 tokens (最大允许: 1808)
2025-12-25 13:59:48,948 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:59:48,965 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:59:48,981 - inference.local_inference - WARNING - 跳过超长prompt [25/122]: 8570 tokens (最大允许: 1808)
2025-12-25 13:59:48,997 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:59:49,013 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8518 tokens (最大允许: 1808)
2025-12-25 13:59:49,029 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:49,045 - inference.local_inference - WARNING - 跳过超长prompt [29/122]: 8531 tokens (最大允许: 1808)
2025-12-25 13:59:49,061 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:59:49,077 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8581 tokens (最大允许: 1808)
2025-12-25 13:59:49,094 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8609 tokens (最大允许: 1808)
2025-12-25 13:59:49,110 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8540 tokens (最大允许: 1808)
2025-12-25 13:59:49,126 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:49,142 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8635 tokens (最大允许: 1808)
2025-12-25 13:59:49,158 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8576 tokens (最大允许: 1808)
2025-12-25 13:59:49,176 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:59:49,193 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8544 tokens (最大允许: 1808)
2025-12-25 13:59:49,210 - inference.local_inference - WARNING - 跳过超长prompt [39/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:49,227 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8622 tokens (最大允许: 1808)
2025-12-25 13:59:49,244 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8583 tokens (最大允许: 1808)
2025-12-25 13:59:49,262 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8541 tokens (最大允许: 1808)
2025-12-25 13:59:49,280 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 8554 tokens (最大允许: 1808)
2025-12-25 13:59:49,297 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8582 tokens (最大允许: 1808)
2025-12-25 13:59:49,314 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8596 tokens (最大允许: 1808)
2025-12-25 13:59:49,331 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8609 tokens (最大允许: 1808)
2025-12-25 13:59:49,347 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8531 tokens (最大允许: 1808)
2025-12-25 13:59:49,363 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8570 tokens (最大允许: 1808)
2025-12-25 13:59:49,379 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8531 tokens (最大允许: 1808)
2025-12-25 13:59:49,395 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8570 tokens (最大允许: 1808)
2025-12-25 13:59:49,411 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8594 tokens (最大允许: 1808)
2025-12-25 13:59:49,427 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8554 tokens (最大允许: 1808)
2025-12-25 13:59:49,443 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8541 tokens (最大允许: 1808)
2025-12-25 13:59:49,459 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8553 tokens (最大允许: 1808)
2025-12-25 13:59:49,474 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:59:49,489 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8531 tokens (最大允许: 1808)
2025-12-25 13:59:49,505 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8491 tokens (最大允许: 1808)
2025-12-25 13:59:49,521 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8582 tokens (最大允许: 1808)
2025-12-25 13:59:49,537 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8554 tokens (最大允许: 1808)
2025-12-25 13:59:49,553 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8491 tokens (最大允许: 1808)
2025-12-25 13:59:49,568 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:59:49,583 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8583 tokens (最大允许: 1808)
2025-12-25 13:59:49,599 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8622 tokens (最大允许: 1808)
2025-12-25 13:59:49,615 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 8622 tokens (最大允许: 1808)
2025-12-25 13:59:49,631 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8607 tokens (最大允许: 1808)
2025-12-25 13:59:49,647 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:59:49,662 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8547 tokens (最大允许: 1808)
2025-12-25 13:59:49,677 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8609 tokens (最大允许: 1808)
2025-12-25 13:59:49,693 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8530 tokens (最大允许: 1808)
2025-12-25 13:59:49,709 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:49,725 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8541 tokens (最大允许: 1808)
2025-12-25 13:59:49,741 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:59:49,757 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8553 tokens (最大允许: 1808)
2025-12-25 13:59:49,773 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:59:49,789 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8528 tokens (最大允许: 1808)
2025-12-25 13:59:49,804 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:59:49,820 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:59:49,836 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8593 tokens (最大允许: 1808)
2025-12-25 13:59:49,852 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8580 tokens (最大允许: 1808)
2025-12-25 13:59:49,867 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8609 tokens (最大允许: 1808)
2025-12-25 13:59:49,883 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 8539 tokens (最大允许: 1808)
2025-12-25 13:59:49,899 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8567 tokens (最大允许: 1808)
2025-12-25 13:59:49,915 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8552 tokens (最大允许: 1808)
2025-12-25 13:59:49,930 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8577 tokens (最大允许: 1808)
2025-12-25 13:59:49,946 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 8596 tokens (最大允许: 1808)
2025-12-25 13:59:49,961 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8531 tokens (最大允许: 1808)
2025-12-25 13:59:49,978 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8583 tokens (最大允许: 1808)
2025-12-25 13:59:49,993 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:59:50,009 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8540 tokens (最大允许: 1808)
2025-12-25 13:59:50,024 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:59:50,040 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8530 tokens (最大允许: 1808)
2025-12-25 13:59:50,056 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8516 tokens (最大允许: 1808)
2025-12-25 13:59:50,073 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:59:50,088 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:50,106 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8551 tokens (最大允许: 1808)
2025-12-25 13:59:50,120 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8537 tokens (最大允许: 1808)
2025-12-25 13:59:50,136 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8596 tokens (最大允许: 1808)
2025-12-25 13:59:50,152 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8537 tokens (最大允许: 1808)
2025-12-25 13:59:50,169 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8528 tokens (最大允许: 1808)
2025-12-25 13:59:50,187 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8581 tokens (最大允许: 1808)
2025-12-25 13:59:50,204 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8516 tokens (最大允许: 1808)
2025-12-25 13:59:50,221 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8541 tokens (最大允许: 1808)
2025-12-25 13:59:50,237 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 8544 tokens (最大允许: 1808)
2025-12-25 13:59:50,254 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8492 tokens (最大允许: 1808)
2025-12-25 13:59:50,270 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8582 tokens (最大允许: 1808)
2025-12-25 13:59:50,286 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8544 tokens (最大允许: 1808)
2025-12-25 13:59:50,301 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8557 tokens (最大允许: 1808)
2025-12-25 13:59:50,317 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8596 tokens (最大允许: 1808)
2025-12-25 13:59:50,334 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8540 tokens (最大允许: 1808)
2025-12-25 13:59:50,352 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:59:50,367 - inference.local_inference - WARNING - 跳过超长prompt [112/122]: 8543 tokens (最大允许: 1808)
2025-12-25 13:59:50,382 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8583 tokens (最大允许: 1808)
2025-12-25 13:59:50,398 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8596 tokens (最大允许: 1808)
2025-12-25 13:59:50,414 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8555 tokens (最大允许: 1808)
2025-12-25 13:59:50,430 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8570 tokens (最大允许: 1808)
2025-12-25 13:59:50,447 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8570 tokens (最大允许: 1808)
2025-12-25 13:59:50,462 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8539 tokens (最大允许: 1808)
2025-12-25 13:59:50,480 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8547 tokens (最大允许: 1808)
2025-12-25 13:59:50,495 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8538 tokens (最大允许: 1808)
2025-12-25 13:59:50,511 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8549 tokens (最大允许: 1808)
2025-12-25 13:59:50,512 - inference.local_inference - WARNING - 共跳过 119/122 条超长prompts
2025-12-25 13:59:54,999 - __main__ - INFO - 成功解析任务描述: 367 条
2025-12-25 13:59:54,999 - __main__ - INFO -   - 找到原则: 358 条
2025-12-25 13:59:54,999 - __main__ - INFO -   - 未找到原则（将直接回答）: 9 条
2025-12-25 13:59:54,999 - __main__ - INFO - 解析失败: 37 条
2025-12-25 13:59:54,999 - __main__ - INFO -   - 空响应: 0 条
2025-12-25 13:59:54,999 - __main__ - INFO -   - JSON解析失败: 37 条
2025-12-25 13:59:54,999 - __main__ - INFO - ============================================================
2025-12-25 13:59:54,999 - __main__ - INFO - 步骤 3/3: 批量生成答案
2025-12-25 13:59:54,999 - __main__ - INFO - ============================================================
2025-12-25 13:59:54,999 - __main__ - INFO - 将分 6 批处理（每批 64 条）
2025-12-25 14:01:07,331 - __main__ - INFO - 答案生成完成: 367 条
2025-12-25 14:01:07,331 - __main__ - INFO - ============================================================
2025-12-25 14:01:07,332 - __main__ - INFO - 组装结果
2025-12-25 14:01:07,332 - __main__ - INFO - ============================================================
2025-12-25 14:01:07,350 - __main__ - INFO - ============================================================
2025-12-25 14:01:07,350 - __main__ - INFO - 开始计算准确率
2025-12-25 14:01:07,350 - __main__ - INFO - ============================================================
2025-12-25 14:01:07,369 - __main__ - INFO - 
============================================================
2025-12-25 14:01:07,369 - __main__ - INFO - 准确率报告
2025-12-25 14:01:07,369 - __main__ - INFO - ============================================================
2025-12-25 14:01:07,369 - __main__ - INFO - 总体准确率: 0/367 = 0.00%
2025-12-25 14:01:07,369 - __main__ - INFO - 
结果已保存:
2025-12-25 14:01:07,369 - __main__ - INFO -   - 推理结果: /home/metanew2/output/local_inference.json
2025-12-25 14:01:07,369 - __main__ - INFO -   - 带准确率标注: /home/metanew2/output/local_inference_with_accuracy.json
2025-12-25 14:01:07,369 - __main__ - INFO -   - 准确率统计: /home/metanew2/output/accuracy_stats.json
2025-12-25 14:01:07,369 - __main__ - INFO - 
推理完成!
2025-12-25 14:01:07,369 - __main__ - INFO -   - 成功推理: 367 项
2025-12-25 14:01:07,369 - __main__ - INFO -   - 未找到原则: 37 项
2025-12-25 14:01:07,369 - __main__ - INFO -   - 总数据量: 404 项
2025-12-25 14:01:10,982 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 14:01:11,023 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 14:01:48,073 - __main__ - INFO - 批次 [2049-2176] 本地推理完成
2025-12-25 14:01:48,074 - __main__ - INFO - 处理批次 [2177-2304/99842]
2025-12-25 14:01:48,074 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 14:01:48,075 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 14:01:58,535 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 14:01:58,536 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 14:01:58,536 - __main__ - WARNING - ⚠️  245/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 14:01:58,537 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 14:01:58,616 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 14:01:58,616 - __main__ - INFO - ============================================================
2025-12-25 14:01:58,616 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 14:01:58,616 - __main__ - INFO - ============================================================
2025-12-25 14:01:58,616 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 14:01:58,616 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 14:01:58,616 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:02:11,192 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 14:02:11,193 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 14:03:19,570 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 14:03:19,571 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 14:03:19,571 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:03:49,394 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 14:03:49,395 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 14:03:49,395 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:04:24,346 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 14:04:24,347 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 14:04:24,347 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:05:27,402 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 14:05:27,403 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 14:05:27,403 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:05:59,703 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 14:05:59,704 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 14:05:59,704 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:07:19,759 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 14:07:19,760 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 14:07:19,761 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:08:07,576 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 14:08:07,577 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 14:08:07,577 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:08:46,158 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 14:08:46,158 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 14:08:46,159 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:09:15,045 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 14:09:15,045 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 14:09:15,045 - __main__ - INFO - 开始数据质量检查...
2025-12-25 14:09:15,046 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 14:09:15,046 - __main__ - INFO - ============================================================
2025-12-25 14:09:15,046 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 14:09:15,046 - __main__ - INFO - ============================================================
2025-12-25 14:09:15,046 - __main__ - INFO - 预检查数据完整性...
2025-12-25 14:09:15,046 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 14:09:15,046 - __main__ - INFO - Rejected非空率: 5/250 (2.0%)
2025-12-25 14:09:15,046 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 14:09:15,068 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 14:09:15,084 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 14:09:15,102 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 14:09:15,117 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 14:09:15,135 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 14:09:15,156 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_geometric_shapes.jsonl
2025-12-25 14:09:15,156 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 14:09:18,751 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 14:09:18,785 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 14:09:19,839 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,839 - __main__ - INFO - 数据集名称: bbh
2025-12-25 14:09:19,839 - __main__ - INFO - 数据集路径: dataset/bbh/hyperbaton.json
2025-12-25 14:09:19,839 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,839 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 14:09:19,839 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,839 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 14:09:19,839 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/hyperbaton.json
2025-12-25 14:09:19,839 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,840 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 14:09:19,840 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 14:09:19,840 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 14:09:19,840 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 14:09:19,840 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,840 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 14:09:19,840 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,840 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 14:09:19,840 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,841 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 14:09:19,841 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 14:09:19,841 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,841 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 14:09:19,841 - __main__ - INFO - ============================================================
2025-12-25 14:09:19,841 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 14:09:19,841 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 14:09:19,841 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 14:09:24,399 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 14:09:24,400 - inference.local_inference - INFO - ============================================================
2025-12-25 14:09:24,400 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 14:09:24,400 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 14:09:24,400 - inference.local_inference - INFO - ============================================================
2025-12-25 14:10:39,815 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 14:10:50,079 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 14:10:50,080 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 14:12:00,577 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 14:12:00,577 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 14:12:00,607 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:12:00,629 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8495 tokens (最大允许: 1808)
2025-12-25 14:12:00,648 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8507 tokens (最大允许: 1808)
2025-12-25 14:12:00,666 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8489 tokens (最大允许: 1808)
2025-12-25 14:12:00,683 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8471 tokens (最大允许: 1808)
2025-12-25 14:12:00,700 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8482 tokens (最大允许: 1808)
2025-12-25 14:12:00,717 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8464 tokens (最大允许: 1808)
2025-12-25 14:12:00,733 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:12:00,749 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:12:00,766 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8442 tokens (最大允许: 1808)
2025-12-25 14:12:00,782 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:12:00,800 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:12:00,817 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:12:00,833 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:12:00,855 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:12:00,872 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8495 tokens (最大允许: 1808)
2025-12-25 14:12:00,888 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:12:00,904 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:12:00,921 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:12:00,938 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8512 tokens (最大允许: 1808)
2025-12-25 14:12:00,954 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8470 tokens (最大允许: 1808)
2025-12-25 14:12:00,972 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8454 tokens (最大允许: 1808)
2025-12-25 14:12:00,988 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:12:01,006 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8509 tokens (最大允许: 1808)
2025-12-25 14:12:01,022 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:12:01,039 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:12:01,055 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8464 tokens (最大允许: 1808)
2025-12-25 14:12:01,071 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:12:01,087 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:12:01,105 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:12:01,122 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8479 tokens (最大允许: 1808)
2025-12-25 14:12:01,140 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:12:01,158 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8442 tokens (最大允许: 1808)
2025-12-25 14:12:01,168 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 5423 tokens (最大允许: 1808)
2025-12-25 14:12:01,185 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:12:01,202 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:12:01,220 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8485 tokens (最大允许: 1808)
2025-12-25 14:12:01,236 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8462 tokens (最大允许: 1808)
2025-12-25 14:12:01,255 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8491 tokens (最大允许: 1808)
2025-12-25 14:12:01,272 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:12:01,288 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8462 tokens (最大允许: 1808)
2025-12-25 14:12:01,304 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8461 tokens (最大允许: 1808)
2025-12-25 14:12:01,322 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:12:01,338 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8483 tokens (最大允许: 1808)
2025-12-25 14:12:01,354 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:12:01,371 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:12:01,388 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:12:01,406 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8476 tokens (最大允许: 1808)
2025-12-25 14:12:01,423 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:12:01,440 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:12:01,457 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:12:01,475 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8513 tokens (最大允许: 1808)
2025-12-25 14:12:01,490 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8557 tokens (最大允许: 1808)
2025-12-25 14:12:01,508 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8476 tokens (最大允许: 1808)
2025-12-25 14:12:01,526 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8454 tokens (最大允许: 1808)
2025-12-25 14:12:01,545 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:12:01,566 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8487 tokens (最大允许: 1808)
2025-12-25 14:12:01,590 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8461 tokens (最大允许: 1808)
2025-12-25 14:12:01,612 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8476 tokens (最大允许: 1808)
2025-12-25 14:12:01,630 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8493 tokens (最大允许: 1808)
2025-12-25 14:12:01,646 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8469 tokens (最大允许: 1808)
2025-12-25 14:12:01,663 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:12:01,681 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:12:01,699 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:12:01,717 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:12:01,736 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8520 tokens (最大允许: 1808)
2025-12-25 14:12:01,753 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:12:01,770 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:12:01,786 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8481 tokens (最大允许: 1808)
2025-12-25 14:12:01,803 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:12:01,822 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:12:01,841 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:12:01,858 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8486 tokens (最大允许: 1808)
2025-12-25 14:12:01,875 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8495 tokens (最大允许: 1808)
2025-12-25 14:12:01,883 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 3623 tokens (最大允许: 1808)
2025-12-25 14:12:01,900 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:12:01,906 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 2804 tokens (最大允许: 1808)
2025-12-25 14:12:01,925 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:12:01,945 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8527 tokens (最大允许: 1808)
2025-12-25 14:12:01,952 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 3438 tokens (最大允许: 1808)
2025-12-25 14:12:01,969 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8452 tokens (最大允许: 1808)
2025-12-25 14:12:01,987 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:12:02,004 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8464 tokens (最大允许: 1808)
2025-12-25 14:12:02,021 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8454 tokens (最大允许: 1808)
2025-12-25 14:12:02,037 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:12:02,054 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:12:02,071 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8484 tokens (最大允许: 1808)
2025-12-25 14:12:02,087 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:12:02,105 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8490 tokens (最大允许: 1808)
2025-12-25 14:12:02,111 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 2628 tokens (最大允许: 1808)
2025-12-25 14:12:02,127 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:12:02,148 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:12:02,167 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:12:02,186 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:12:02,203 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8464 tokens (最大允许: 1808)
2025-12-25 14:12:02,219 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:12:02,235 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8483 tokens (最大允许: 1808)
2025-12-25 14:12:02,251 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8495 tokens (最大允许: 1808)
2025-12-25 14:12:02,268 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8488 tokens (最大允许: 1808)
2025-12-25 14:12:02,286 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:12:02,304 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:12:02,328 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:12:02,344 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:12:02,362 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:12:02,378 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8485 tokens (最大允许: 1808)
2025-12-25 14:12:02,394 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:12:02,411 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8482 tokens (最大允许: 1808)
2025-12-25 14:12:02,430 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:12:02,447 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:12:02,464 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8490 tokens (最大允许: 1808)
2025-12-25 14:12:02,480 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:12:02,499 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8477 tokens (最大允许: 1808)
2025-12-25 14:12:02,516 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:12:02,533 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:12:02,549 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:12:02,566 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:12:02,588 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8488 tokens (最大允许: 1808)
2025-12-25 14:12:02,605 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:12:02,626 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:12:02,649 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8442 tokens (最大允许: 1808)
2025-12-25 14:12:02,671 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8477 tokens (最大允许: 1808)
2025-12-25 14:12:02,688 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:12:02,705 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:12:02,722 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:12:02,723 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 14:14:10,636 - __main__ - INFO - 批次 [2177-2304] 本地推理完成
2025-12-25 14:14:10,637 - __main__ - INFO - 处理批次 [2305-2432/99842]
2025-12-25 14:14:10,638 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 14:14:10,638 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 14:14:26,114 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 14:14:26,115 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 14:21:01,706 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 14:21:01,706 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 14:21:01,732 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:01,752 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:01,769 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:01,787 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:01,803 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:01,821 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:01,838 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:01,856 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:01,873 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:21:01,890 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8430 tokens (最大允许: 1808)
2025-12-25 14:21:01,907 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:21:01,925 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:01,941 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:01,959 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:01,976 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:01,994 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:02,011 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:02,028 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,045 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:21:02,063 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,080 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,098 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:21:02,115 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,132 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:02,149 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,167 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,185 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:02,203 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,222 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,239 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:21:02,257 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,274 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,292 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8428 tokens (最大允许: 1808)
2025-12-25 14:21:02,309 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,326 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:02,344 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:02,360 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,378 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,396 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:02,414 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:02,432 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:02,449 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,466 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:02,483 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,501 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,521 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:21:02,539 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:02,557 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:21:02,574 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,592 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:21:02,610 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:02,627 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:02,644 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:02,661 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:21:02,678 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:02,693 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:02,711 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,727 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:21:02,743 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,760 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:02,777 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:21:02,792 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:02,809 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:02,826 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:02,842 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,859 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:02,875 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:02,892 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:02,910 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:02,926 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:21:02,943 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:02,960 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:02,977 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:02,994 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:03,011 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:03,028 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:03,045 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,062 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:03,080 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:03,098 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:03,115 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,132 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,150 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:21:03,167 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:21:03,184 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:21:03,201 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:21:03,220 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:03,237 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:03,254 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:21:03,272 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,289 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:03,306 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:03,324 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,343 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:21:03,361 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,379 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:03,397 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:21:03,414 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:21:03,432 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:03,450 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:21:03,468 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,486 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:21:03,504 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,522 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,541 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:21:03,558 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:21:03,576 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:03,593 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,611 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8430 tokens (最大允许: 1808)
2025-12-25 14:21:03,628 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,646 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:03,663 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,681 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,699 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:21:03,716 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:21:03,732 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:03,750 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,766 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:21:03,783 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,799 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:21:03,815 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8430 tokens (最大允许: 1808)
2025-12-25 14:21:03,832 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,848 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:21:03,865 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:21:03,882 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,899 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8429 tokens (最大允许: 1808)
2025-12-25 14:21:03,916 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:21:03,933 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:21:03,933 - inference.local_inference - WARNING - 共跳过 128/128 条超长prompts
2025-12-25 14:21:03,933 - inference.local_inference - ERROR - 所有prompts都超长，返回空列表
2025-12-25 14:21:03,934 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 14:21:03,934 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 14:21:03,934 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 14:21:03,934 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 14:21:15,703 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 14:21:15,704 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 14:24:11,288 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 14:24:11,288 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 14:24:11,315 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8469 tokens (最大允许: 1808)
2025-12-25 14:24:11,335 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:24:11,353 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8471 tokens (最大允许: 1808)
2025-12-25 14:24:11,371 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8528 tokens (最大允许: 1808)
2025-12-25 14:24:11,389 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8497 tokens (最大允许: 1808)
2025-12-25 14:24:11,408 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:24:11,428 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8482 tokens (最大允许: 1808)
2025-12-25 14:24:11,447 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8486 tokens (最大允许: 1808)
2025-12-25 14:24:11,465 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8488 tokens (最大允许: 1808)
2025-12-25 14:24:11,483 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:24:11,501 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8469 tokens (最大允许: 1808)
2025-12-25 14:24:11,518 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:24:11,536 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8489 tokens (最大允许: 1808)
2025-12-25 14:24:11,555 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8491 tokens (最大允许: 1808)
2025-12-25 14:24:11,572 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:24:11,589 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8481 tokens (最大允许: 1808)
2025-12-25 14:24:11,607 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8479 tokens (最大允许: 1808)
2025-12-25 14:24:11,625 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:24:11,643 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:24:11,662 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8473 tokens (最大允许: 1808)
2025-12-25 14:24:11,680 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8477 tokens (最大允许: 1808)
2025-12-25 14:24:11,699 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:24:11,719 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:24:11,739 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:24:11,759 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8479 tokens (最大允许: 1808)
2025-12-25 14:24:11,778 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:24:11,797 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:24:11,815 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:24:11,834 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:24:11,852 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:24:11,870 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8491 tokens (最大允许: 1808)
2025-12-25 14:24:11,889 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8496 tokens (最大允许: 1808)
2025-12-25 14:24:11,907 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:24:11,926 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:24:11,943 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:24:11,962 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:24:11,979 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:24:11,985 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 2741 tokens (最大允许: 1808)
2025-12-25 14:24:12,004 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:24:12,022 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:24:12,044 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:24:12,062 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8487 tokens (最大允许: 1808)
2025-12-25 14:24:12,079 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:24:12,097 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:24:12,115 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:24:12,134 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:24:12,152 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8469 tokens (最大允许: 1808)
2025-12-25 14:24:12,171 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8452 tokens (最大允许: 1808)
2025-12-25 14:24:12,189 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:24:12,206 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:24:12,224 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:24:12,229 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 2501 tokens (最大允许: 1808)
2025-12-25 14:24:12,247 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:24:12,265 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:24:12,283 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:24:12,300 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:24:12,318 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:24:12,335 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8555 tokens (最大允许: 1808)
2025-12-25 14:24:12,357 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8443 tokens (最大允许: 1808)
2025-12-25 14:24:12,375 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:24:12,393 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8513 tokens (最大允许: 1808)
2025-12-25 14:24:12,411 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:24:12,429 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8509 tokens (最大允许: 1808)
2025-12-25 14:24:12,447 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:24:12,465 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8469 tokens (最大允许: 1808)
2025-12-25 14:24:12,484 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:24:12,502 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8471 tokens (最大允许: 1808)
2025-12-25 14:24:12,520 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:24:12,537 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:24:12,542 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 2292 tokens (最大允许: 1808)
2025-12-25 14:24:12,561 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:24:12,580 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:24:12,598 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:24:12,617 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8482 tokens (最大允许: 1808)
2025-12-25 14:24:12,635 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:24:12,652 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8499 tokens (最大允许: 1808)
2025-12-25 14:24:12,669 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:24:12,688 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8502 tokens (最大允许: 1808)
2025-12-25 14:24:12,693 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 2372 tokens (最大允许: 1808)
2025-12-25 14:24:12,713 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:24:12,731 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8437 tokens (最大允许: 1808)
2025-12-25 14:24:12,749 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:24:12,768 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:24:12,786 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:24:12,803 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:24:12,821 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8454 tokens (最大允许: 1808)
2025-12-25 14:24:12,841 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:24:12,859 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:24:12,863 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 1831 tokens (最大允许: 1808)
2025-12-25 14:24:12,880 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:24:12,898 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8464 tokens (最大允许: 1808)
2025-12-25 14:24:12,917 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8487 tokens (最大允许: 1808)
2025-12-25 14:24:12,936 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8484 tokens (最大允许: 1808)
2025-12-25 14:24:12,954 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:24:12,971 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:24:12,989 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8521 tokens (最大允许: 1808)
2025-12-25 14:24:13,007 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8495 tokens (最大允许: 1808)
2025-12-25 14:24:13,027 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:24:13,045 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:24:13,062 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:24:13,079 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:24:13,097 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8462 tokens (最大允许: 1808)
2025-12-25 14:24:13,115 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8534 tokens (最大允许: 1808)
2025-12-25 14:24:13,133 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:24:13,152 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8483 tokens (最大允许: 1808)
2025-12-25 14:24:13,171 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8589 tokens (最大允许: 1808)
2025-12-25 14:24:13,187 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:24:13,205 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8473 tokens (最大允许: 1808)
2025-12-25 14:24:13,222 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:24:13,240 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8495 tokens (最大允许: 1808)
2025-12-25 14:24:13,258 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:24:13,264 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 2685 tokens (最大允许: 1808)
2025-12-25 14:24:13,281 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8485 tokens (最大允许: 1808)
2025-12-25 14:24:13,309 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8327 tokens (最大允许: 1808)
2025-12-25 14:24:13,328 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:24:13,346 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8430 tokens (最大允许: 1808)
2025-12-25 14:24:13,363 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:24:13,382 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:24:13,399 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:24:13,420 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:24:13,438 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8471 tokens (最大允许: 1808)
2025-12-25 14:24:13,456 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:24:13,474 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8526 tokens (最大允许: 1808)
2025-12-25 14:24:13,491 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:24:13,492 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 14:26:25,730 - __main__ - INFO - 批次 [2305-2432] 本地推理完成
2025-12-25 14:26:25,731 - __main__ - INFO - 处理批次 [2433-2560/99842]
2025-12-25 14:26:25,731 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 14:26:25,731 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 14:26:38,504 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 14:26:38,504 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 14:31:10,688 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 14:31:10,689 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 14:31:10,714 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8428 tokens (最大允许: 1808)
2025-12-25 14:31:10,734 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:10,752 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:10,769 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8441 tokens (最大允许: 1808)
2025-12-25 14:31:10,787 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:10,804 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:10,822 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8442 tokens (最大允许: 1808)
2025-12-25 14:31:10,840 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:10,857 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:10,875 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:10,894 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:10,913 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:10,932 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:10,950 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:10,969 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:10,987 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:11,004 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:11,022 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8436 tokens (最大允许: 1808)
2025-12-25 14:31:11,040 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:11,058 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8436 tokens (最大允许: 1808)
2025-12-25 14:31:11,077 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,095 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,115 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8441 tokens (最大允许: 1808)
2025-12-25 14:31:11,133 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:11,152 - inference.local_inference - WARNING - 跳过超长prompt [25/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:11,170 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,189 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:11,207 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:11,225 - inference.local_inference - WARNING - 跳过超长prompt [29/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:11,244 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:11,262 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8447 tokens (最大允许: 1808)
2025-12-25 14:31:11,280 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:11,298 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:11,316 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8441 tokens (最大允许: 1808)
2025-12-25 14:31:11,334 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,352 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:11,371 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:11,390 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:11,409 - inference.local_inference - WARNING - 跳过超长prompt [39/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:11,427 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:11,445 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:11,463 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:11,480 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:11,498 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,516 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:11,533 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:11,551 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:11,570 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8440 tokens (最大允许: 1808)
2025-12-25 14:31:11,588 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,606 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:11,624 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:11,642 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:11,660 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8432 tokens (最大允许: 1808)
2025-12-25 14:31:11,678 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8438 tokens (最大允许: 1808)
2025-12-25 14:31:11,694 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:11,712 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:11,730 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8436 tokens (最大允许: 1808)
2025-12-25 14:31:11,748 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:11,766 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8438 tokens (最大允许: 1808)
2025-12-25 14:31:11,785 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:11,804 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,821 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:11,839 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8430 tokens (最大允许: 1808)
2025-12-25 14:31:11,857 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:11,877 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8432 tokens (最大允许: 1808)
2025-12-25 14:31:11,895 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:11,914 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:11,931 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:11,950 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:11,969 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8432 tokens (最大允许: 1808)
2025-12-25 14:31:11,986 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:12,003 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:12,022 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8436 tokens (最大允许: 1808)
2025-12-25 14:31:12,040 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:12,059 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8442 tokens (最大允许: 1808)
2025-12-25 14:31:12,077 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8444 tokens (最大允许: 1808)
2025-12-25 14:31:12,094 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:12,112 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,130 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8441 tokens (最大允许: 1808)
2025-12-25 14:31:12,149 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,166 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,185 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:12,204 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8441 tokens (最大允许: 1808)
2025-12-25 14:31:12,222 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:12,240 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,258 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,277 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,294 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,311 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:12,330 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,347 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:12,364 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:12,383 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8430 tokens (最大允许: 1808)
2025-12-25 14:31:12,401 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:12,419 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,438 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:12,455 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8443 tokens (最大允许: 1808)
2025-12-25 14:31:12,474 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:12,491 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:12,509 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:12,528 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:12,547 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8441 tokens (最大允许: 1808)
2025-12-25 14:31:12,566 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:12,584 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,601 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:12,619 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:12,637 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:12,655 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8433 tokens (最大允许: 1808)
2025-12-25 14:31:12,672 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8429 tokens (最大允许: 1808)
2025-12-25 14:31:12,690 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:12,709 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:12,727 - inference.local_inference - WARNING - 跳过超长prompt [112/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,745 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:12,762 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:12,779 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8437 tokens (最大允许: 1808)
2025-12-25 14:31:12,797 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,815 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8443 tokens (最大允许: 1808)
2025-12-25 14:31:12,833 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8430 tokens (最大允许: 1808)
2025-12-25 14:31:12,852 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 8431 tokens (最大允许: 1808)
2025-12-25 14:31:12,869 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8435 tokens (最大允许: 1808)
2025-12-25 14:31:12,887 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8434 tokens (最大允许: 1808)
2025-12-25 14:31:12,904 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8439 tokens (最大允许: 1808)
2025-12-25 14:31:12,905 - inference.local_inference - WARNING - 共跳过 122/122 条超长prompts
2025-12-25 14:31:12,905 - inference.local_inference - ERROR - 所有prompts都超长，返回空列表
2025-12-25 14:31:12,905 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 14:31:12,905 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 14:31:12,905 - __main__ - WARNING - ⚠️  250/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 14:31:12,905 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 14:31:12,978 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 14:31:12,978 - __main__ - INFO - ============================================================
2025-12-25 14:31:12,978 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 14:31:12,978 - __main__ - INFO - ============================================================
2025-12-25 14:31:12,978 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 14:31:12,978 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 14:31:12,978 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:32:06,376 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 14:32:06,376 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 14:32:06,377 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:32:55,215 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 14:32:55,223 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 14:32:55,223 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:33:52,671 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 14:33:52,671 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 14:33:52,672 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:34:33,747 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 14:34:33,747 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 14:34:33,747 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:36:14,942 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 14:36:14,942 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 14:36:14,970 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8470 tokens (最大允许: 1808)
2025-12-25 14:36:14,992 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:36:15,010 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:36:15,028 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:36:15,047 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8461 tokens (最大允许: 1808)
2025-12-25 14:36:15,064 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:36:15,082 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:36:15,100 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:36:15,119 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:36:15,137 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:36:15,154 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8514 tokens (最大允许: 1808)
2025-12-25 14:36:15,160 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 2930 tokens (最大允许: 1808)
2025-12-25 14:36:15,176 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8483 tokens (最大允许: 1808)
2025-12-25 14:36:15,193 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:36:15,211 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8447 tokens (最大允许: 1808)
2025-12-25 14:36:15,215 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 1994 tokens (最大允许: 1808)
2025-12-25 14:36:15,235 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:36:15,253 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:36:15,272 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:36:15,289 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8491 tokens (最大允许: 1808)
2025-12-25 14:36:15,294 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 2634 tokens (最大允许: 1808)
2025-12-25 14:36:15,312 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8473 tokens (最大允许: 1808)
2025-12-25 14:36:15,329 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:36:15,348 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:36:15,353 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 2073 tokens (最大允许: 1808)
2025-12-25 14:36:15,371 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8495 tokens (最大允许: 1808)
2025-12-25 14:36:15,390 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:36:15,407 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:36:15,425 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8476 tokens (最大允许: 1808)
2025-12-25 14:36:15,443 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8484 tokens (最大允许: 1808)
2025-12-25 14:36:15,461 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:36:15,479 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:36:15,497 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:36:15,514 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8492 tokens (最大允许: 1808)
2025-12-25 14:36:15,532 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8517 tokens (最大允许: 1808)
2025-12-25 14:36:15,549 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:36:15,567 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:36:15,584 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:36:15,604 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8488 tokens (最大允许: 1808)
2025-12-25 14:36:15,623 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8522 tokens (最大允许: 1808)
2025-12-25 14:36:15,643 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8514 tokens (最大允许: 1808)
2025-12-25 14:36:15,663 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8461 tokens (最大允许: 1808)
2025-12-25 14:36:15,682 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:36:15,700 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8471 tokens (最大允许: 1808)
2025-12-25 14:36:15,718 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:36:15,736 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8497 tokens (最大允许: 1808)
2025-12-25 14:36:15,754 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8493 tokens (最大允许: 1808)
2025-12-25 14:36:15,774 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:36:15,792 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8500 tokens (最大允许: 1808)
2025-12-25 14:36:15,811 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:36:15,829 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:36:15,846 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:36:15,867 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8494 tokens (最大允许: 1808)
2025-12-25 14:36:15,885 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:36:15,904 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:36:15,924 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:36:15,942 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:36:15,962 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:36:15,980 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:36:15,997 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8504 tokens (最大允许: 1808)
2025-12-25 14:36:16,013 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8487 tokens (最大允许: 1808)
2025-12-25 14:36:16,032 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8485 tokens (最大允许: 1808)
2025-12-25 14:36:16,050 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8461 tokens (最大允许: 1808)
2025-12-25 14:36:16,068 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:36:16,086 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:36:16,106 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:36:16,123 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8452 tokens (最大允许: 1808)
2025-12-25 14:36:16,143 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8530 tokens (最大允许: 1808)
2025-12-25 14:36:16,162 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:36:16,180 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:36:16,185 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 2577 tokens (最大允许: 1808)
2025-12-25 14:36:16,193 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 3795 tokens (最大允许: 1808)
2025-12-25 14:36:16,211 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:36:16,229 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:36:16,233 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 1907 tokens (最大允许: 1808)
2025-12-25 14:36:16,251 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:36:16,269 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:36:16,287 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:36:16,306 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8502 tokens (最大允许: 1808)
2025-12-25 14:36:16,324 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:36:16,342 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:36:16,364 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8497 tokens (最大允许: 1808)
2025-12-25 14:36:16,382 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:36:16,400 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8435 tokens (最大允许: 1808)
2025-12-25 14:36:16,418 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8507 tokens (最大允许: 1808)
2025-12-25 14:36:16,437 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8473 tokens (最大允许: 1808)
2025-12-25 14:36:16,456 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:36:16,475 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:36:16,493 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8479 tokens (最大允许: 1808)
2025-12-25 14:36:16,512 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:36:16,531 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:36:16,549 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:36:16,555 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 2922 tokens (最大允许: 1808)
2025-12-25 14:36:16,572 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:36:16,590 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:36:16,608 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:36:16,626 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:36:16,644 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8485 tokens (最大允许: 1808)
2025-12-25 14:36:16,662 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:36:16,681 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8491 tokens (最大允许: 1808)
2025-12-25 14:36:16,700 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8514 tokens (最大允许: 1808)
2025-12-25 14:36:16,718 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:36:16,737 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8571 tokens (最大允许: 1808)
2025-12-25 14:36:16,754 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8439 tokens (最大允许: 1808)
2025-12-25 14:36:16,775 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:36:16,795 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8481 tokens (最大允许: 1808)
2025-12-25 14:36:16,813 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:36:16,831 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:36:16,849 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:36:16,867 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:36:16,885 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:36:16,903 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:36:16,908 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 2119 tokens (最大允许: 1808)
2025-12-25 14:36:16,925 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:36:16,929 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 1965 tokens (最大允许: 1808)
2025-12-25 14:36:16,946 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8491 tokens (最大允许: 1808)
2025-12-25 14:36:16,964 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:36:16,983 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:36:17,000 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:36:17,018 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8494 tokens (最大允许: 1808)
2025-12-25 14:36:17,038 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:36:17,056 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8492 tokens (最大允许: 1808)
2025-12-25 14:36:17,075 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:36:17,095 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8497 tokens (最大允许: 1808)
2025-12-25 14:36:17,095 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 14:36:21,236 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 14:36:21,237 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 14:36:21,237 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:37:03,612 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 14:37:03,613 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 14:37:03,613 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:37:59,635 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 14:37:59,636 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 14:37:59,636 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:38:29,126 - __main__ - INFO - 批次 [2433-2560] 本地推理完成
2025-12-25 14:38:29,126 - __main__ - INFO - 处理批次 [2561-2688/99842]
2025-12-25 14:38:29,127 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 14:38:29,127 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 14:38:36,642 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 14:38:36,643 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 14:38:36,643 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 14:38:45,860 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 14:38:45,860 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 14:39:05,589 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 14:39:05,589 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 14:39:05,589 - __main__ - INFO - 开始数据质量检查...
2025-12-25 14:39:05,589 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 14:39:05,589 - __main__ - INFO - ============================================================
2025-12-25 14:39:05,589 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 14:39:05,589 - __main__ - INFO - ============================================================
2025-12-25 14:39:05,589 - __main__ - INFO - 预检查数据完整性...
2025-12-25 14:39:05,589 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 14:39:05,589 - __main__ - INFO - Rejected非空率: 0/250 (0.0%)
2025-12-25 14:39:05,589 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 14:39:05,611 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 14:39:05,633 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 14:39:05,656 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 14:39:05,678 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 14:39:05,699 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 14:39:05,716 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_hyperbaton.jsonl
2025-12-25 14:39:05,716 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 14:39:09,735 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 14:39:09,769 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 14:39:10,918 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,918 - __main__ - INFO - 数据集名称: bbh
2025-12-25 14:39:10,918 - __main__ - INFO - 数据集路径: dataset/bbh/logical_deduction_five_objects.json
2025-12-25 14:39:10,918 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,918 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 14:39:10,918 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,918 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 14:39:10,918 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/logical_deduction_five_objects.json
2025-12-25 14:39:10,918 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,919 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 14:39:10,919 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 14:39:10,919 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 14:39:10,919 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 14:39:10,919 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,919 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 14:39:10,919 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,919 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 14:39:10,919 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,919 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 14:39:10,921 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 14:39:10,921 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,921 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 14:39:10,921 - __main__ - INFO - ============================================================
2025-12-25 14:39:10,921 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 14:39:10,921 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 14:39:10,921 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 14:39:15,520 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 14:39:15,520 - inference.local_inference - INFO - ============================================================
2025-12-25 14:39:15,520 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 14:39:15,520 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 14:39:15,520 - inference.local_inference - INFO - ============================================================
2025-12-25 14:40:35,891 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 14:40:52,270 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 14:40:52,271 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 14:48:40,424 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 14:48:40,425 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 14:48:40,454 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8491 tokens (最大允许: 1808)
2025-12-25 14:48:40,474 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8462 tokens (最大允许: 1808)
2025-12-25 14:48:40,495 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:48:40,513 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:48:40,531 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:48:40,551 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:48:40,570 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8476 tokens (最大允许: 1808)
2025-12-25 14:48:40,589 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8499 tokens (最大允许: 1808)
2025-12-25 14:48:40,608 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8520 tokens (最大允许: 1808)
2025-12-25 14:48:40,626 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8472 tokens (最大允许: 1808)
2025-12-25 14:48:40,631 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 1830 tokens (最大允许: 1808)
2025-12-25 14:48:40,647 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8442 tokens (最大允许: 1808)
2025-12-25 14:48:40,668 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:48:40,687 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8470 tokens (最大允许: 1808)
2025-12-25 14:48:40,708 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:48:40,726 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:48:40,744 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8476 tokens (最大允许: 1808)
2025-12-25 14:48:40,763 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8535 tokens (最大允许: 1808)
2025-12-25 14:48:40,782 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:48:40,800 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8516 tokens (最大允许: 1808)
2025-12-25 14:48:40,818 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8489 tokens (最大允许: 1808)
2025-12-25 14:48:40,836 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8470 tokens (最大允许: 1808)
2025-12-25 14:48:40,853 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:48:40,871 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8438 tokens (最大允许: 1808)
2025-12-25 14:48:40,888 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8469 tokens (最大允许: 1808)
2025-12-25 14:48:40,906 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:48:40,924 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:48:40,942 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:48:40,959 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:48:40,977 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8535 tokens (最大允许: 1808)
2025-12-25 14:48:40,995 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8463 tokens (最大允许: 1808)
2025-12-25 14:48:41,012 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:48:41,030 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:48:41,047 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8461 tokens (最大允许: 1808)
2025-12-25 14:48:41,064 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8432 tokens (最大允许: 1808)
2025-12-25 14:48:41,082 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8445 tokens (最大允许: 1808)
2025-12-25 14:48:41,101 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8483 tokens (最大允许: 1808)
2025-12-25 14:48:41,119 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8506 tokens (最大允许: 1808)
2025-12-25 14:48:41,137 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:48:41,155 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:48:41,177 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:48:41,182 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 2603 tokens (最大允许: 1808)
2025-12-25 14:48:41,201 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8499 tokens (最大允许: 1808)
2025-12-25 14:48:41,219 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8451 tokens (最大允许: 1808)
2025-12-25 14:48:41,238 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8506 tokens (最大允许: 1808)
2025-12-25 14:48:41,256 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8462 tokens (最大允许: 1808)
2025-12-25 14:48:41,274 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:48:41,294 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8469 tokens (最大允许: 1808)
2025-12-25 14:48:41,313 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:48:41,331 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:48:41,350 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8484 tokens (最大允许: 1808)
2025-12-25 14:48:41,366 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:48:41,385 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8470 tokens (最大允许: 1808)
2025-12-25 14:48:41,403 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:48:41,421 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:48:41,439 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:48:41,458 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8441 tokens (最大允许: 1808)
2025-12-25 14:48:41,475 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8475 tokens (最大允许: 1808)
2025-12-25 14:48:41,494 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:48:41,512 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:48:41,529 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8485 tokens (最大允许: 1808)
2025-12-25 14:48:41,549 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:48:41,568 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8455 tokens (最大允许: 1808)
2025-12-25 14:48:41,587 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:48:41,606 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8497 tokens (最大允许: 1808)
2025-12-25 14:48:41,625 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:48:41,644 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8447 tokens (最大允许: 1808)
2025-12-25 14:48:41,663 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8464 tokens (最大允许: 1808)
2025-12-25 14:48:41,682 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8448 tokens (最大允许: 1808)
2025-12-25 14:48:41,691 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 2967 tokens (最大允许: 1808)
2025-12-25 14:48:41,711 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8496 tokens (最大允许: 1808)
2025-12-25 14:48:41,729 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8436 tokens (最大允许: 1808)
2025-12-25 14:48:41,747 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:48:41,764 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8452 tokens (最大允许: 1808)
2025-12-25 14:48:41,783 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:48:41,803 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:48:41,820 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:48:41,838 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:48:41,856 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8484 tokens (最大允许: 1808)
2025-12-25 14:48:41,873 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:48:41,891 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8454 tokens (最大允许: 1808)
2025-12-25 14:48:41,910 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8482 tokens (最大允许: 1808)
2025-12-25 14:48:41,927 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:48:41,945 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:48:41,963 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8447 tokens (最大允许: 1808)
2025-12-25 14:48:41,981 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:48:41,999 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8434 tokens (最大允许: 1808)
2025-12-25 14:48:42,019 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:48:42,036 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8450 tokens (最大允许: 1808)
2025-12-25 14:48:42,053 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:48:42,070 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8440 tokens (最大允许: 1808)
2025-12-25 14:48:42,087 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8460 tokens (最大允许: 1808)
2025-12-25 14:48:42,105 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8431 tokens (最大允许: 1808)
2025-12-25 14:48:42,123 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:48:42,141 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8446 tokens (最大允许: 1808)
2025-12-25 14:48:42,159 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8465 tokens (最大允许: 1808)
2025-12-25 14:48:42,176 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:48:42,193 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8461 tokens (最大允许: 1808)
2025-12-25 14:48:42,211 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:48:42,230 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8453 tokens (最大允许: 1808)
2025-12-25 14:48:42,248 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8500 tokens (最大允许: 1808)
2025-12-25 14:48:42,266 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8474 tokens (最大允许: 1808)
2025-12-25 14:48:42,283 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:48:42,305 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8459 tokens (最大允许: 1808)
2025-12-25 14:48:42,324 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8456 tokens (最大允许: 1808)
2025-12-25 14:48:42,341 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:48:42,360 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8484 tokens (最大允许: 1808)
2025-12-25 14:48:42,379 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8484 tokens (最大允许: 1808)
2025-12-25 14:48:42,398 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8449 tokens (最大允许: 1808)
2025-12-25 14:48:42,416 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8466 tokens (最大允许: 1808)
2025-12-25 14:48:42,433 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8468 tokens (最大允许: 1808)
2025-12-25 14:48:42,452 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8513 tokens (最大允许: 1808)
2025-12-25 14:48:42,471 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8478 tokens (最大允许: 1808)
2025-12-25 14:48:42,489 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8433 tokens (最大允许: 1808)
2025-12-25 14:48:42,507 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8457 tokens (最大允许: 1808)
2025-12-25 14:48:42,526 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8477 tokens (最大允许: 1808)
2025-12-25 14:48:42,544 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8467 tokens (最大允许: 1808)
2025-12-25 14:48:42,562 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8442 tokens (最大允许: 1808)
2025-12-25 14:48:42,580 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8444 tokens (最大允许: 1808)
2025-12-25 14:48:42,597 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:48:42,614 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8458 tokens (最大允许: 1808)
2025-12-25 14:48:42,632 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8480 tokens (最大允许: 1808)
2025-12-25 14:48:42,651 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8523 tokens (最大允许: 1808)
2025-12-25 14:48:42,651 - inference.local_inference - WARNING - 共跳过 123/128 条超长prompts
2025-12-25 14:51:00,347 - __main__ - INFO - 批次 [2561-2688] 本地推理完成
2025-12-25 14:51:00,348 - __main__ - INFO - 处理批次 [2689-2816/99842]
2025-12-25 14:51:00,348 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 14:51:00,348 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 14:51:12,550 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 14:51:12,551 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 14:51:30,337 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 14:51:30,338 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 14:51:30,367 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8546 tokens (最大允许: 1808)
2025-12-25 14:51:30,388 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8555 tokens (最大允许: 1808)
2025-12-25 14:51:30,409 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8557 tokens (最大允许: 1808)
2025-12-25 14:51:30,428 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8557 tokens (最大允许: 1808)
2025-12-25 14:51:30,449 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8568 tokens (最大允许: 1808)
2025-12-25 14:51:30,468 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8570 tokens (最大允许: 1808)
2025-12-25 14:51:30,488 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8534 tokens (最大允许: 1808)
2025-12-25 14:51:30,508 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:51:30,528 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8560 tokens (最大允许: 1808)
2025-12-25 14:51:30,546 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8557 tokens (最大允许: 1808)
2025-12-25 14:51:30,565 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:30,583 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8553 tokens (最大允许: 1808)
2025-12-25 14:51:30,604 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8566 tokens (最大允许: 1808)
2025-12-25 14:51:30,624 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:51:30,643 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8546 tokens (最大允许: 1808)
2025-12-25 14:51:30,663 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8562 tokens (最大允许: 1808)
2025-12-25 14:51:30,682 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8559 tokens (最大允许: 1808)
2025-12-25 14:51:30,702 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:30,722 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8504 tokens (最大允许: 1808)
2025-12-25 14:51:30,742 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:51:30,761 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8561 tokens (最大允许: 1808)
2025-12-25 14:51:30,780 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8545 tokens (最大允许: 1808)
2025-12-25 14:51:30,801 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8506 tokens (最大允许: 1808)
2025-12-25 14:51:30,821 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8546 tokens (最大允许: 1808)
2025-12-25 14:51:30,841 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8565 tokens (最大允许: 1808)
2025-12-25 14:51:30,862 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8552 tokens (最大允许: 1808)
2025-12-25 14:51:30,882 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:51:30,902 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8518 tokens (最大允许: 1808)
2025-12-25 14:51:30,922 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:51:30,942 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8504 tokens (最大允许: 1808)
2025-12-25 14:51:30,962 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8551 tokens (最大允许: 1808)
2025-12-25 14:51:30,982 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:31,001 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8513 tokens (最大允许: 1808)
2025-12-25 14:51:31,021 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8568 tokens (最大允许: 1808)
2025-12-25 14:51:31,040 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8519 tokens (最大允许: 1808)
2025-12-25 14:51:31,059 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8568 tokens (最大允许: 1808)
2025-12-25 14:51:31,078 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8539 tokens (最大允许: 1808)
2025-12-25 14:51:31,098 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8565 tokens (最大允许: 1808)
2025-12-25 14:51:31,117 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8508 tokens (最大允许: 1808)
2025-12-25 14:51:31,135 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8558 tokens (最大允许: 1808)
2025-12-25 14:51:31,153 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8544 tokens (最大允许: 1808)
2025-12-25 14:51:31,173 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:51:31,190 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8548 tokens (最大允许: 1808)
2025-12-25 14:51:31,210 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:31,230 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8554 tokens (最大允许: 1808)
2025-12-25 14:51:31,248 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8550 tokens (最大允许: 1808)
2025-12-25 14:51:31,268 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8567 tokens (最大允许: 1808)
2025-12-25 14:51:31,287 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8550 tokens (最大允许: 1808)
2025-12-25 14:51:31,306 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8545 tokens (最大允许: 1808)
2025-12-25 14:51:31,326 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8548 tokens (最大允许: 1808)
2025-12-25 14:51:31,345 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8565 tokens (最大允许: 1808)
2025-12-25 14:51:31,365 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8570 tokens (最大允许: 1808)
2025-12-25 14:51:31,385 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8553 tokens (最大允许: 1808)
2025-12-25 14:51:31,409 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8557 tokens (最大允许: 1808)
2025-12-25 14:51:31,430 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8558 tokens (最大允许: 1808)
2025-12-25 14:51:31,449 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8546 tokens (最大允许: 1808)
2025-12-25 14:51:31,469 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8507 tokens (最大允许: 1808)
2025-12-25 14:51:31,489 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8555 tokens (最大允许: 1808)
2025-12-25 14:51:31,509 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8546 tokens (最大允许: 1808)
2025-12-25 14:51:31,530 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8557 tokens (最大允许: 1808)
2025-12-25 14:51:31,550 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8554 tokens (最大允许: 1808)
2025-12-25 14:51:31,569 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8539 tokens (最大允许: 1808)
2025-12-25 14:51:31,589 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8568 tokens (最大允许: 1808)
2025-12-25 14:51:31,608 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8546 tokens (最大允许: 1808)
2025-12-25 14:51:31,628 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8560 tokens (最大允许: 1808)
2025-12-25 14:51:31,648 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8567 tokens (最大允许: 1808)
2025-12-25 14:51:31,666 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8543 tokens (最大允许: 1808)
2025-12-25 14:51:31,686 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8561 tokens (最大允许: 1808)
2025-12-25 14:51:31,705 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8540 tokens (最大允许: 1808)
2025-12-25 14:51:31,724 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8545 tokens (最大允许: 1808)
2025-12-25 14:51:31,745 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8558 tokens (最大允许: 1808)
2025-12-25 14:51:31,763 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8555 tokens (最大允许: 1808)
2025-12-25 14:51:31,782 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8507 tokens (最大允许: 1808)
2025-12-25 14:51:31,802 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8541 tokens (最大允许: 1808)
2025-12-25 14:51:31,820 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8566 tokens (最大允许: 1808)
2025-12-25 14:51:31,838 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8566 tokens (最大允许: 1808)
2025-12-25 14:51:31,858 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8561 tokens (最大允许: 1808)
2025-12-25 14:51:31,878 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8542 tokens (最大允许: 1808)
2025-12-25 14:51:31,896 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8514 tokens (最大允许: 1808)
2025-12-25 14:51:31,916 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8560 tokens (最大允许: 1808)
2025-12-25 14:51:31,936 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8568 tokens (最大允许: 1808)
2025-12-25 14:51:31,955 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8566 tokens (最大允许: 1808)
2025-12-25 14:51:31,975 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8561 tokens (最大允许: 1808)
2025-12-25 14:51:31,993 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8504 tokens (最大允许: 1808)
2025-12-25 14:51:32,011 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8553 tokens (最大允许: 1808)
2025-12-25 14:51:32,031 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8544 tokens (最大允许: 1808)
2025-12-25 14:51:32,050 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8544 tokens (最大允许: 1808)
2025-12-25 14:51:32,068 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8555 tokens (最大允许: 1808)
2025-12-25 14:51:32,087 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8549 tokens (最大允许: 1808)
2025-12-25 14:51:32,106 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8566 tokens (最大允许: 1808)
2025-12-25 14:51:32,125 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8568 tokens (最大允许: 1808)
2025-12-25 14:51:32,143 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8554 tokens (最大允许: 1808)
2025-12-25 14:51:32,163 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8508 tokens (最大允许: 1808)
2025-12-25 14:51:32,183 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8505 tokens (最大允许: 1808)
2025-12-25 14:51:32,202 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8564 tokens (最大允许: 1808)
2025-12-25 14:51:32,227 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8559 tokens (最大允许: 1808)
2025-12-25 14:51:32,246 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8545 tokens (最大允许: 1808)
2025-12-25 14:51:32,265 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8548 tokens (最大允许: 1808)
2025-12-25 14:51:32,284 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8544 tokens (最大允许: 1808)
2025-12-25 14:51:32,302 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8547 tokens (最大允许: 1808)
2025-12-25 14:51:32,321 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8507 tokens (最大允许: 1808)
2025-12-25 14:51:32,339 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8565 tokens (最大允许: 1808)
2025-12-25 14:51:32,359 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8508 tokens (最大允许: 1808)
2025-12-25 14:51:32,376 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8570 tokens (最大允许: 1808)
2025-12-25 14:51:32,396 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:32,416 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8560 tokens (最大允许: 1808)
2025-12-25 14:51:32,436 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8558 tokens (最大允许: 1808)
2025-12-25 14:51:32,454 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8559 tokens (最大允许: 1808)
2025-12-25 14:51:32,474 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8558 tokens (最大允许: 1808)
2025-12-25 14:51:32,493 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8557 tokens (最大允许: 1808)
2025-12-25 14:51:32,514 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8568 tokens (最大允许: 1808)
2025-12-25 14:51:32,532 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8554 tokens (最大允许: 1808)
2025-12-25 14:51:32,552 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:32,570 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8563 tokens (最大允许: 1808)
2025-12-25 14:51:32,588 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8561 tokens (最大允许: 1808)
2025-12-25 14:51:32,607 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8545 tokens (最大允许: 1808)
2025-12-25 14:51:32,627 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8549 tokens (最大允许: 1808)
2025-12-25 14:51:32,646 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:32,665 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8567 tokens (最大允许: 1808)
2025-12-25 14:51:32,685 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8506 tokens (最大允许: 1808)
2025-12-25 14:51:32,705 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8565 tokens (最大允许: 1808)
2025-12-25 14:51:32,724 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8509 tokens (最大允许: 1808)
2025-12-25 14:51:32,744 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8549 tokens (最大允许: 1808)
2025-12-25 14:51:32,762 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8517 tokens (最大允许: 1808)
2025-12-25 14:51:32,781 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8508 tokens (最大允许: 1808)
2025-12-25 14:51:32,799 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:32,819 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8506 tokens (最大允许: 1808)
2025-12-25 14:51:32,838 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8556 tokens (最大允许: 1808)
2025-12-25 14:51:32,838 - inference.local_inference - WARNING - 共跳过 128/128 条超长prompts
2025-12-25 14:51:32,838 - inference.local_inference - ERROR - 所有prompts都超长，返回空列表
2025-12-25 14:51:32,838 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 14:51:32,838 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 14:51:32,838 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 14:51:32,838 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 14:51:50,998 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 14:51:50,999 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 15:01:12,464 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 15:01:12,465 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 15:01:12,502 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8477 tokens (最大允许: 1808)
2025-12-25 15:01:12,531 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8446 tokens (最大允许: 1808)
2025-12-25 15:01:12,558 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8446 tokens (最大允许: 1808)
2025-12-25 15:01:12,592 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8479 tokens (最大允许: 1808)
2025-12-25 15:01:12,620 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8458 tokens (最大允许: 1808)
2025-12-25 15:01:12,649 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8468 tokens (最大允许: 1808)
2025-12-25 15:01:12,670 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8455 tokens (最大允许: 1808)
2025-12-25 15:01:12,688 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8442 tokens (最大允许: 1808)
2025-12-25 15:01:12,709 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8525 tokens (最大允许: 1808)
2025-12-25 15:01:12,729 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8484 tokens (最大允许: 1808)
2025-12-25 15:01:12,748 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8488 tokens (最大允许: 1808)
2025-12-25 15:01:12,768 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8441 tokens (最大允许: 1808)
2025-12-25 15:01:12,781 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 5307 tokens (最大允许: 1808)
2025-12-25 15:01:12,801 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8438 tokens (最大允许: 1808)
2025-12-25 15:01:12,820 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8445 tokens (最大允许: 1808)
2025-12-25 15:01:12,839 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8488 tokens (最大允许: 1808)
2025-12-25 15:01:12,859 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8439 tokens (最大允许: 1808)
2025-12-25 15:01:12,879 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8445 tokens (最大允许: 1808)
2025-12-25 15:01:12,898 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8444 tokens (最大允许: 1808)
2025-12-25 15:01:12,917 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8458 tokens (最大允许: 1808)
2025-12-25 15:01:12,936 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8459 tokens (最大允许: 1808)
2025-12-25 15:01:12,955 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8436 tokens (最大允许: 1808)
2025-12-25 15:01:12,976 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8461 tokens (最大允许: 1808)
2025-12-25 15:01:12,999 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8474 tokens (最大允许: 1808)
2025-12-25 15:01:13,020 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8444 tokens (最大允许: 1808)
2025-12-25 15:01:13,045 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8463 tokens (最大允许: 1808)
2025-12-25 15:01:13,065 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8459 tokens (最大允许: 1808)
2025-12-25 15:01:13,085 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8478 tokens (最大允许: 1808)
2025-12-25 15:01:13,103 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8471 tokens (最大允许: 1808)
2025-12-25 15:01:13,120 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8454 tokens (最大允许: 1808)
2025-12-25 15:01:13,140 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8440 tokens (最大允许: 1808)
2025-12-25 15:01:13,145 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 2156 tokens (最大允许: 1808)
2025-12-25 15:01:13,163 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8468 tokens (最大允许: 1808)
2025-12-25 15:01:13,182 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8468 tokens (最大允许: 1808)
2025-12-25 15:01:13,201 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8483 tokens (最大允许: 1808)
2025-12-25 15:01:13,221 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8487 tokens (最大允许: 1808)
2025-12-25 15:01:13,239 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8451 tokens (最大允许: 1808)
2025-12-25 15:01:13,257 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8439 tokens (最大允许: 1808)
2025-12-25 15:01:13,275 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8465 tokens (最大允许: 1808)
2025-12-25 15:01:13,293 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8444 tokens (最大允许: 1808)
2025-12-25 15:01:13,311 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8452 tokens (最大允许: 1808)
2025-12-25 15:01:13,329 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8462 tokens (最大允许: 1808)
2025-12-25 15:01:13,347 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8451 tokens (最大允许: 1808)
2025-12-25 15:01:13,366 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8471 tokens (最大允许: 1808)
2025-12-25 15:01:13,384 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8493 tokens (最大允许: 1808)
2025-12-25 15:01:13,402 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8447 tokens (最大允许: 1808)
2025-12-25 15:01:13,422 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8505 tokens (最大允许: 1808)
2025-12-25 15:01:13,440 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8476 tokens (最大允许: 1808)
2025-12-25 15:01:13,458 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8432 tokens (最大允许: 1808)
2025-12-25 15:01:13,476 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8455 tokens (最大允许: 1808)
2025-12-25 15:01:13,495 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8438 tokens (最大允许: 1808)
2025-12-25 15:01:13,513 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8452 tokens (最大允许: 1808)
2025-12-25 15:01:13,531 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8434 tokens (最大允许: 1808)
2025-12-25 15:01:13,550 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8470 tokens (最大允许: 1808)
2025-12-25 15:01:13,571 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8445 tokens (最大允许: 1808)
2025-12-25 15:01:13,590 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8473 tokens (最大允许: 1808)
2025-12-25 15:01:13,609 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8436 tokens (最大允许: 1808)
2025-12-25 15:01:13,631 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8469 tokens (最大允许: 1808)
2025-12-25 15:01:13,651 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8471 tokens (最大允许: 1808)
2025-12-25 15:01:13,671 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8478 tokens (最大允许: 1808)
2025-12-25 15:01:13,689 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8439 tokens (最大允许: 1808)
2025-12-25 15:01:13,707 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8447 tokens (最大允许: 1808)
2025-12-25 15:01:13,726 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8449 tokens (最大允许: 1808)
2025-12-25 15:01:13,745 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8444 tokens (最大允许: 1808)
2025-12-25 15:01:13,764 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8467 tokens (最大允许: 1808)
2025-12-25 15:01:13,782 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8450 tokens (最大允许: 1808)
2025-12-25 15:01:13,800 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8438 tokens (最大允许: 1808)
2025-12-25 15:01:13,820 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8452 tokens (最大允许: 1808)
2025-12-25 15:01:13,838 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8452 tokens (最大允许: 1808)
2025-12-25 15:01:13,856 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8472 tokens (最大允许: 1808)
2025-12-25 15:01:13,874 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8480 tokens (最大允许: 1808)
2025-12-25 15:01:13,892 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8490 tokens (最大允许: 1808)
2025-12-25 15:01:13,910 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8458 tokens (最大允许: 1808)
2025-12-25 15:01:13,927 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8477 tokens (最大允许: 1808)
2025-12-25 15:01:13,946 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8463 tokens (最大允许: 1808)
2025-12-25 15:01:13,964 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8457 tokens (最大允许: 1808)
2025-12-25 15:01:13,982 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8443 tokens (最大允许: 1808)
2025-12-25 15:01:14,002 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8512 tokens (最大允许: 1808)
2025-12-25 15:01:14,022 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8473 tokens (最大允许: 1808)
2025-12-25 15:01:14,040 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8445 tokens (最大允许: 1808)
2025-12-25 15:01:14,045 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 1976 tokens (最大允许: 1808)
2025-12-25 15:01:14,063 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8470 tokens (最大允许: 1808)
2025-12-25 15:01:14,084 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8482 tokens (最大允许: 1808)
2025-12-25 15:01:14,103 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8432 tokens (最大允许: 1808)
2025-12-25 15:01:14,121 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8491 tokens (最大允许: 1808)
2025-12-25 15:01:14,140 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8441 tokens (最大允许: 1808)
2025-12-25 15:01:14,158 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8491 tokens (最大允许: 1808)
2025-12-25 15:01:14,176 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8483 tokens (最大允许: 1808)
2025-12-25 15:01:14,195 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8493 tokens (最大允许: 1808)
2025-12-25 15:01:14,213 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8450 tokens (最大允许: 1808)
2025-12-25 15:01:14,231 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8453 tokens (最大允许: 1808)
2025-12-25 15:01:14,249 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8476 tokens (最大允许: 1808)
2025-12-25 15:01:14,266 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8436 tokens (最大允许: 1808)
2025-12-25 15:01:14,283 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8449 tokens (最大允许: 1808)
2025-12-25 15:01:14,302 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8466 tokens (最大允许: 1808)
2025-12-25 15:01:14,320 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8492 tokens (最大允许: 1808)
2025-12-25 15:01:14,338 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8503 tokens (最大允许: 1808)
2025-12-25 15:01:14,356 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8491 tokens (最大允许: 1808)
2025-12-25 15:01:14,374 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8442 tokens (最大允许: 1808)
2025-12-25 15:01:14,392 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8486 tokens (最大允许: 1808)
2025-12-25 15:01:14,410 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8455 tokens (最大允许: 1808)
2025-12-25 15:01:14,427 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8441 tokens (最大允许: 1808)
2025-12-25 15:01:14,445 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8446 tokens (最大允许: 1808)
2025-12-25 15:01:14,463 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8455 tokens (最大允许: 1808)
2025-12-25 15:01:14,482 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8461 tokens (最大允许: 1808)
2025-12-25 15:01:14,500 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8445 tokens (最大允许: 1808)
2025-12-25 15:01:14,520 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8464 tokens (最大允许: 1808)
2025-12-25 15:01:14,539 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8477 tokens (最大允许: 1808)
2025-12-25 15:01:14,545 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 2620 tokens (最大允许: 1808)
2025-12-25 15:01:14,563 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8457 tokens (最大允许: 1808)
2025-12-25 15:01:14,582 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8484 tokens (最大允许: 1808)
2025-12-25 15:01:14,601 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8460 tokens (最大允许: 1808)
2025-12-25 15:01:14,619 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8471 tokens (最大允许: 1808)
2025-12-25 15:01:14,638 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8459 tokens (最大允许: 1808)
2025-12-25 15:01:14,658 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8469 tokens (最大允许: 1808)
2025-12-25 15:01:14,675 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8453 tokens (最大允许: 1808)
2025-12-25 15:01:14,693 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8453 tokens (最大允许: 1808)
2025-12-25 15:01:14,712 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8466 tokens (最大允许: 1808)
2025-12-25 15:01:14,731 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8476 tokens (最大允许: 1808)
2025-12-25 15:01:14,750 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8472 tokens (最大允许: 1808)
2025-12-25 15:01:14,756 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 2692 tokens (最大允许: 1808)
2025-12-25 15:01:14,774 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8462 tokens (最大允许: 1808)
2025-12-25 15:01:14,793 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8495 tokens (最大允许: 1808)
2025-12-25 15:01:14,810 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8447 tokens (最大允许: 1808)
2025-12-25 15:01:14,829 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8469 tokens (最大允许: 1808)
2025-12-25 15:01:14,847 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8433 tokens (最大允许: 1808)
2025-12-25 15:01:14,847 - inference.local_inference - WARNING - 共跳过 126/128 条超长prompts
2025-12-25 15:02:06,748 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 15:02:06,748 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 15:02:06,777 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:06,797 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8545 tokens (最大允许: 1808)
2025-12-25 15:02:06,816 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8554 tokens (最大允许: 1808)
2025-12-25 15:02:06,836 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8570 tokens (最大允许: 1808)
2025-12-25 15:02:06,856 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8570 tokens (最大允许: 1808)
2025-12-25 15:02:06,874 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:06,891 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8516 tokens (最大允许: 1808)
2025-12-25 15:02:06,910 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8568 tokens (最大允许: 1808)
2025-12-25 15:02:06,929 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8514 tokens (最大允许: 1808)
2025-12-25 15:02:06,948 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 8543 tokens (最大允许: 1808)
2025-12-25 15:02:06,968 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8566 tokens (最大允许: 1808)
2025-12-25 15:02:06,987 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8550 tokens (最大允许: 1808)
2025-12-25 15:02:07,005 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8567 tokens (最大允许: 1808)
2025-12-25 15:02:07,024 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 8542 tokens (最大允许: 1808)
2025-12-25 15:02:07,042 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8566 tokens (最大允许: 1808)
2025-12-25 15:02:07,061 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8546 tokens (最大允许: 1808)
2025-12-25 15:02:07,078 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8553 tokens (最大允许: 1808)
2025-12-25 15:02:07,097 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:07,115 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8564 tokens (最大允许: 1808)
2025-12-25 15:02:07,135 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8504 tokens (最大允许: 1808)
2025-12-25 15:02:07,154 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8508 tokens (最大允许: 1808)
2025-12-25 15:02:07,174 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8553 tokens (最大允许: 1808)
2025-12-25 15:02:07,193 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8515 tokens (最大允许: 1808)
2025-12-25 15:02:07,212 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8543 tokens (最大允许: 1808)
2025-12-25 15:02:07,229 - inference.local_inference - WARNING - 跳过超长prompt [25/122]: 8547 tokens (最大允许: 1808)
2025-12-25 15:02:07,247 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8508 tokens (最大允许: 1808)
2025-12-25 15:02:07,274 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8551 tokens (最大允许: 1808)
2025-12-25 15:02:07,295 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8550 tokens (最大允许: 1808)
2025-12-25 15:02:07,315 - inference.local_inference - WARNING - 跳过超长prompt [29/122]: 8544 tokens (最大允许: 1808)
2025-12-25 15:02:07,334 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8570 tokens (最大允许: 1808)
2025-12-25 15:02:07,354 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8552 tokens (最大允许: 1808)
2025-12-25 15:02:07,372 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:07,391 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8544 tokens (最大允许: 1808)
2025-12-25 15:02:07,410 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8517 tokens (最大允许: 1808)
2025-12-25 15:02:07,428 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8507 tokens (最大允许: 1808)
2025-12-25 15:02:07,447 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8506 tokens (最大允许: 1808)
2025-12-25 15:02:07,465 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:07,483 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8543 tokens (最大允许: 1808)
2025-12-25 15:02:07,502 - inference.local_inference - WARNING - 跳过超长prompt [39/122]: 8542 tokens (最大允许: 1808)
2025-12-25 15:02:07,521 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8521 tokens (最大允许: 1808)
2025-12-25 15:02:07,540 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:07,557 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8557 tokens (最大允许: 1808)
2025-12-25 15:02:07,576 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 8550 tokens (最大允许: 1808)
2025-12-25 15:02:07,594 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8511 tokens (最大允许: 1808)
2025-12-25 15:02:07,613 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:07,632 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8560 tokens (最大允许: 1808)
2025-12-25 15:02:07,652 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8560 tokens (最大允许: 1808)
2025-12-25 15:02:07,676 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:07,695 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8504 tokens (最大允许: 1808)
2025-12-25 15:02:07,713 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:07,731 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8554 tokens (最大允许: 1808)
2025-12-25 15:02:07,750 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8548 tokens (最大允许: 1808)
2025-12-25 15:02:07,769 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8507 tokens (最大允许: 1808)
2025-12-25 15:02:07,787 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:07,806 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8503 tokens (最大允许: 1808)
2025-12-25 15:02:07,824 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8550 tokens (最大允许: 1808)
2025-12-25 15:02:07,842 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:07,862 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8566 tokens (最大允许: 1808)
2025-12-25 15:02:07,882 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8559 tokens (最大允许: 1808)
2025-12-25 15:02:07,901 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:07,920 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8570 tokens (最大允许: 1808)
2025-12-25 15:02:07,940 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:07,958 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8548 tokens (最大允许: 1808)
2025-12-25 15:02:07,978 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 8515 tokens (最大允许: 1808)
2025-12-25 15:02:07,996 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8549 tokens (最大允许: 1808)
2025-12-25 15:02:08,015 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8562 tokens (最大允许: 1808)
2025-12-25 15:02:08,034 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8544 tokens (最大允许: 1808)
2025-12-25 15:02:08,053 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8506 tokens (最大允许: 1808)
2025-12-25 15:02:08,072 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8568 tokens (最大允许: 1808)
2025-12-25 15:02:08,091 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8561 tokens (最大允许: 1808)
2025-12-25 15:02:08,110 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8561 tokens (最大允许: 1808)
2025-12-25 15:02:08,128 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 8560 tokens (最大允许: 1808)
2025-12-25 15:02:08,147 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8508 tokens (最大允许: 1808)
2025-12-25 15:02:08,166 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8504 tokens (最大允许: 1808)
2025-12-25 15:02:08,185 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8540 tokens (最大允许: 1808)
2025-12-25 15:02:08,204 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8557 tokens (最大允许: 1808)
2025-12-25 15:02:08,223 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8507 tokens (最大允许: 1808)
2025-12-25 15:02:08,242 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8552 tokens (最大允许: 1808)
2025-12-25 15:02:08,260 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8559 tokens (最大允许: 1808)
2025-12-25 15:02:08,280 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:08,300 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 8514 tokens (最大允许: 1808)
2025-12-25 15:02:08,319 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8566 tokens (最大允许: 1808)
2025-12-25 15:02:08,337 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:08,356 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8545 tokens (最大允许: 1808)
2025-12-25 15:02:08,374 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 8563 tokens (最大允许: 1808)
2025-12-25 15:02:08,393 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8517 tokens (最大允许: 1808)
2025-12-25 15:02:08,412 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8553 tokens (最大允许: 1808)
2025-12-25 15:02:08,432 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 8551 tokens (最大允许: 1808)
2025-12-25 15:02:08,450 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8506 tokens (最大允许: 1808)
2025-12-25 15:02:08,468 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8552 tokens (最大允许: 1808)
2025-12-25 15:02:08,487 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:08,507 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8566 tokens (最大允许: 1808)
2025-12-25 15:02:08,527 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8504 tokens (最大允许: 1808)
2025-12-25 15:02:08,546 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8545 tokens (最大允许: 1808)
2025-12-25 15:02:08,565 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8566 tokens (最大允许: 1808)
2025-12-25 15:02:08,585 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8564 tokens (最大允许: 1808)
2025-12-25 15:02:08,604 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:08,622 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8550 tokens (最大允许: 1808)
2025-12-25 15:02:08,641 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:08,661 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:08,680 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:08,699 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8540 tokens (最大允许: 1808)
2025-12-25 15:02:08,718 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8550 tokens (最大允许: 1808)
2025-12-25 15:02:08,737 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 8547 tokens (最大允许: 1808)
2025-12-25 15:02:08,756 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8504 tokens (最大允许: 1808)
2025-12-25 15:02:08,776 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8558 tokens (最大允许: 1808)
2025-12-25 15:02:08,794 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8552 tokens (最大允许: 1808)
2025-12-25 15:02:08,812 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8550 tokens (最大允许: 1808)
2025-12-25 15:02:08,830 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8557 tokens (最大允许: 1808)
2025-12-25 15:02:08,848 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8545 tokens (最大允许: 1808)
2025-12-25 15:02:08,866 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8555 tokens (最大允许: 1808)
2025-12-25 15:02:08,884 - inference.local_inference - WARNING - 跳过超长prompt [112/122]: 8506 tokens (最大允许: 1808)
2025-12-25 15:02:08,902 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:08,921 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8568 tokens (最大允许: 1808)
2025-12-25 15:02:08,939 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8545 tokens (最大允许: 1808)
2025-12-25 15:02:08,958 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8505 tokens (最大允许: 1808)
2025-12-25 15:02:08,976 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8504 tokens (最大允许: 1808)
2025-12-25 15:02:08,995 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8509 tokens (最大允许: 1808)
2025-12-25 15:02:09,015 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 8572 tokens (最大允许: 1808)
2025-12-25 15:02:09,033 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8556 tokens (最大允许: 1808)
2025-12-25 15:02:09,052 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8553 tokens (最大允许: 1808)
2025-12-25 15:02:09,071 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8552 tokens (最大允许: 1808)
2025-12-25 15:02:09,071 - inference.local_inference - WARNING - 共跳过 122/122 条超长prompts
2025-12-25 15:02:09,071 - inference.local_inference - ERROR - 所有prompts都超长，返回空列表
2025-12-25 15:02:09,072 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 15:02:09,072 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 15:02:09,072 - __main__ - WARNING - ⚠️  250/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 15:02:09,072 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 15:02:09,148 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 15:02:09,148 - __main__ - INFO - ============================================================
2025-12-25 15:02:09,148 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 15:02:09,148 - __main__ - INFO - ============================================================
2025-12-25 15:02:09,148 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 15:02:09,148 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 15:02:09,148 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:02:45,641 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 15:02:45,641 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 15:02:45,642 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:03:20,153 - __main__ - INFO - 批次 [2689-2816] 本地推理完成
2025-12-25 15:03:20,154 - __main__ - INFO - 处理批次 [2817-2944/99842]
2025-12-25 15:03:20,154 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 15:03:20,154 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 15:03:30,345 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 15:03:30,345 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 15:03:56,224 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 15:03:56,225 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 15:03:56,225 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:05:05,756 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 15:05:05,757 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 15:05:05,757 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:06:23,601 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 15:06:23,601 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 15:06:23,602 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:06:54,708 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 15:06:54,709 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 15:06:54,709 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:07:28,500 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 15:07:28,500 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 15:07:28,501 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:08:03,141 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 15:08:03,142 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 15:08:03,142 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:08:41,161 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 15:08:41,162 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 15:08:41,162 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:09:10,165 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 15:09:10,165 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 15:09:10,165 - __main__ - INFO - 开始数据质量检查...
2025-12-25 15:09:10,165 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 15:09:10,165 - __main__ - INFO - ============================================================
2025-12-25 15:09:10,166 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 15:09:10,166 - __main__ - INFO - ============================================================
2025-12-25 15:09:10,166 - __main__ - INFO - 预检查数据完整性...
2025-12-25 15:09:10,166 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 15:09:10,166 - __main__ - INFO - Rejected非空率: 0/250 (0.0%)
2025-12-25 15:09:10,166 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 15:09:10,189 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 15:09:10,206 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 15:09:10,231 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 15:09:10,249 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 15:09:10,263 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 15:09:10,280 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_logical_deduction_five_objects.jsonl
2025-12-25 15:09:10,280 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 15:09:14,407 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 15:09:14,442 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 15:09:15,610 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,610 - __main__ - INFO - 数据集名称: bbh
2025-12-25 15:09:15,610 - __main__ - INFO - 数据集路径: dataset/bbh/logical_deduction_seven_objects.json
2025-12-25 15:09:15,610 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,610 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 15:09:15,610 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,610 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 15:09:15,610 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/logical_deduction_seven_objects.json
2025-12-25 15:09:15,610 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,611 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 15:09:15,611 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 15:09:15,611 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 15:09:15,611 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 15:09:15,611 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,611 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 15:09:15,611 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,611 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 15:09:15,611 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,612 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 15:09:15,613 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 15:09:15,613 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,613 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 15:09:15,613 - __main__ - INFO - ============================================================
2025-12-25 15:09:15,613 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 15:09:15,613 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 15:09:15,613 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 15:09:20,158 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 15:09:20,158 - inference.local_inference - INFO - ============================================================
2025-12-25 15:09:20,158 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 15:09:20,158 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 15:09:20,158 - inference.local_inference - INFO - ============================================================
2025-12-25 15:10:40,010 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 15:11:05,212 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 15:11:05,213 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 15:13:25,375 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 15:13:25,376 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 15:13:25,407 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8475 tokens (最大允许: 1808)
2025-12-25 15:13:25,427 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8456 tokens (最大允许: 1808)
2025-12-25 15:13:25,445 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8485 tokens (最大允许: 1808)
2025-12-25 15:13:25,462 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8447 tokens (最大允许: 1808)
2025-12-25 15:13:25,481 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8489 tokens (最大允许: 1808)
2025-12-25 15:13:25,499 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8455 tokens (最大允许: 1808)
2025-12-25 15:13:25,517 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8488 tokens (最大允许: 1808)
2025-12-25 15:13:25,535 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8436 tokens (最大允许: 1808)
2025-12-25 15:13:25,552 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8442 tokens (最大允许: 1808)
2025-12-25 15:13:25,570 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8442 tokens (最大允许: 1808)
2025-12-25 15:13:25,588 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8521 tokens (最大允许: 1808)
2025-12-25 15:13:25,606 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8465 tokens (最大允许: 1808)
2025-12-25 15:13:25,623 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8504 tokens (最大允许: 1808)
2025-12-25 15:13:25,641 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8436 tokens (最大允许: 1808)
2025-12-25 15:13:25,659 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8460 tokens (最大允许: 1808)
2025-12-25 15:13:25,664 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 2296 tokens (最大允许: 1808)
2025-12-25 15:13:25,682 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8467 tokens (最大允许: 1808)
2025-12-25 15:13:25,694 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 5775 tokens (最大允许: 1808)
2025-12-25 15:13:25,712 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8607 tokens (最大允许: 1808)
2025-12-25 15:13:25,730 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8602 tokens (最大允许: 1808)
2025-12-25 15:13:25,747 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:13:25,764 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8602 tokens (最大允许: 1808)
2025-12-25 15:13:25,781 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8601 tokens (最大允许: 1808)
2025-12-25 15:13:25,799 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8607 tokens (最大允许: 1808)
2025-12-25 15:13:25,817 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:13:25,835 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8625 tokens (最大允许: 1808)
2025-12-25 15:13:25,853 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8712 tokens (最大允许: 1808)
2025-12-25 15:13:25,870 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8706 tokens (最大允许: 1808)
2025-12-25 15:13:25,887 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8716 tokens (最大允许: 1808)
2025-12-25 15:13:25,905 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8707 tokens (最大允许: 1808)
2025-12-25 15:13:25,923 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8662 tokens (最大允许: 1808)
2025-12-25 15:13:25,941 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8668 tokens (最大允许: 1808)
2025-12-25 15:13:25,960 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8655 tokens (最大允许: 1808)
2025-12-25 15:13:25,979 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8652 tokens (最大允许: 1808)
2025-12-25 15:13:25,997 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8703 tokens (最大允许: 1808)
2025-12-25 15:13:26,015 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8683 tokens (最大允许: 1808)
2025-12-25 15:13:26,036 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8728 tokens (最大允许: 1808)
2025-12-25 15:13:26,054 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8613 tokens (最大允许: 1808)
2025-12-25 15:13:26,073 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8633 tokens (最大允许: 1808)
2025-12-25 15:13:26,091 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:13:26,109 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:13:26,127 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8730 tokens (最大允许: 1808)
2025-12-25 15:13:26,145 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8708 tokens (最大允许: 1808)
2025-12-25 15:13:26,163 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8740 tokens (最大允许: 1808)
2025-12-25 15:13:26,181 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8714 tokens (最大允许: 1808)
2025-12-25 15:13:26,199 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8688 tokens (最大允许: 1808)
2025-12-25 15:13:26,217 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8675 tokens (最大允许: 1808)
2025-12-25 15:13:26,235 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8672 tokens (最大允许: 1808)
2025-12-25 15:13:26,258 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8527 tokens (最大允许: 1808)
2025-12-25 15:13:26,279 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8523 tokens (最大允许: 1808)
2025-12-25 15:13:26,297 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8527 tokens (最大允许: 1808)
2025-12-25 15:13:26,316 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8609 tokens (最大允许: 1808)
2025-12-25 15:13:26,333 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8614 tokens (最大允许: 1808)
2025-12-25 15:13:26,351 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8615 tokens (最大允许: 1808)
2025-12-25 15:13:26,370 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8618 tokens (最大允许: 1808)
2025-12-25 15:13:26,389 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8679 tokens (最大允许: 1808)
2025-12-25 15:13:26,410 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8686 tokens (最大允许: 1808)
2025-12-25 15:13:26,428 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8657 tokens (最大允许: 1808)
2025-12-25 15:13:26,446 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8679 tokens (最大允许: 1808)
2025-12-25 15:13:26,465 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8600 tokens (最大允许: 1808)
2025-12-25 15:13:26,483 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8602 tokens (最大允许: 1808)
2025-12-25 15:13:26,500 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8603 tokens (最大允许: 1808)
2025-12-25 15:13:26,518 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8601 tokens (最大允许: 1808)
2025-12-25 15:13:26,536 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8762 tokens (最大允许: 1808)
2025-12-25 15:13:26,554 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8766 tokens (最大允许: 1808)
2025-12-25 15:13:26,572 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8743 tokens (最大允许: 1808)
2025-12-25 15:13:26,590 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8745 tokens (最大允许: 1808)
2025-12-25 15:13:26,608 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8645 tokens (最大允许: 1808)
2025-12-25 15:13:26,627 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8646 tokens (最大允许: 1808)
2025-12-25 15:13:26,646 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8680 tokens (最大允许: 1808)
2025-12-25 15:13:26,664 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8648 tokens (最大允许: 1808)
2025-12-25 15:13:26,682 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8677 tokens (最大允许: 1808)
2025-12-25 15:13:26,701 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8692 tokens (最大允许: 1808)
2025-12-25 15:13:26,723 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8682 tokens (最大允许: 1808)
2025-12-25 15:13:26,741 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8581 tokens (最大允许: 1808)
2025-12-25 15:13:26,759 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8576 tokens (最大允许: 1808)
2025-12-25 15:13:26,777 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8581 tokens (最大允许: 1808)
2025-12-25 15:13:26,795 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8575 tokens (最大允许: 1808)
2025-12-25 15:13:26,814 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8626 tokens (最大允许: 1808)
2025-12-25 15:13:26,831 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8625 tokens (最大允许: 1808)
2025-12-25 15:13:26,849 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:13:26,867 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8625 tokens (最大允许: 1808)
2025-12-25 15:13:26,885 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:13:26,903 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8631 tokens (最大允许: 1808)
2025-12-25 15:13:26,922 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8642 tokens (最大允许: 1808)
2025-12-25 15:13:26,939 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8637 tokens (最大允许: 1808)
2025-12-25 15:13:26,958 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8742 tokens (最大允许: 1808)
2025-12-25 15:13:26,977 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8738 tokens (最大允许: 1808)
2025-12-25 15:13:26,995 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8741 tokens (最大允许: 1808)
2025-12-25 15:13:27,013 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8747 tokens (最大允许: 1808)
2025-12-25 15:13:27,031 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8898 tokens (最大允许: 1808)
2025-12-25 15:13:27,049 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8910 tokens (最大允许: 1808)
2025-12-25 15:13:27,068 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8895 tokens (最大允许: 1808)
2025-12-25 15:13:27,087 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8887 tokens (最大允许: 1808)
2025-12-25 15:13:27,106 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8688 tokens (最大允许: 1808)
2025-12-25 15:13:27,124 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8675 tokens (最大允许: 1808)
2025-12-25 15:13:27,143 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8696 tokens (最大允许: 1808)
2025-12-25 15:13:27,162 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8666 tokens (最大允许: 1808)
2025-12-25 15:13:27,180 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8649 tokens (最大允许: 1808)
2025-12-25 15:13:27,199 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8664 tokens (最大允许: 1808)
2025-12-25 15:13:27,217 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8664 tokens (最大允许: 1808)
2025-12-25 15:13:27,235 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8651 tokens (最大允许: 1808)
2025-12-25 15:13:27,252 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8727 tokens (最大允许: 1808)
2025-12-25 15:13:27,270 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8726 tokens (最大允许: 1808)
2025-12-25 15:13:27,288 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8721 tokens (最大允许: 1808)
2025-12-25 15:13:27,306 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8726 tokens (最大允许: 1808)
2025-12-25 15:13:27,324 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8639 tokens (最大允许: 1808)
2025-12-25 15:13:27,342 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8638 tokens (最大允许: 1808)
2025-12-25 15:13:27,358 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8627 tokens (最大允许: 1808)
2025-12-25 15:13:27,375 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:13:27,395 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8752 tokens (最大允许: 1808)
2025-12-25 15:13:27,415 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8767 tokens (最大允许: 1808)
2025-12-25 15:13:27,434 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8759 tokens (最大允许: 1808)
2025-12-25 15:13:27,453 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8785 tokens (最大允许: 1808)
2025-12-25 15:13:27,471 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8674 tokens (最大允许: 1808)
2025-12-25 15:13:27,489 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8675 tokens (最大允许: 1808)
2025-12-25 15:13:27,507 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8667 tokens (最大允许: 1808)
2025-12-25 15:13:27,526 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8672 tokens (最大允许: 1808)
2025-12-25 15:13:27,544 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8651 tokens (最大允许: 1808)
2025-12-25 15:13:27,549 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 1978 tokens (最大允许: 1808)
2025-12-25 15:13:27,553 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 2291 tokens (最大允许: 1808)
2025-12-25 15:13:27,570 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8652 tokens (最大允许: 1808)
2025-12-25 15:13:27,587 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8682 tokens (最大允许: 1808)
2025-12-25 15:13:27,606 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8687 tokens (最大允许: 1808)
2025-12-25 15:13:27,606 - inference.local_inference - WARNING - 共跳过 124/128 条超长prompts
2025-12-25 15:15:36,855 - __main__ - INFO - 批次 [2817-2944] 本地推理完成
2025-12-25 15:15:36,856 - __main__ - INFO - 处理批次 [2945-3072/99842]
2025-12-25 15:15:36,857 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 15:15:36,857 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 15:15:47,394 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 15:15:47,394 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 15:21:42,933 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 15:21:42,934 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 15:21:42,961 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:42,981 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:21:43,007 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8610 tokens (最大允许: 1808)
2025-12-25 15:21:43,027 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8609 tokens (最大允许: 1808)
2025-12-25 15:21:43,045 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8597 tokens (最大允许: 1808)
2025-12-25 15:21:43,065 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8548 tokens (最大允许: 1808)
2025-12-25 15:21:43,085 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8529 tokens (最大允许: 1808)
2025-12-25 15:21:43,103 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8593 tokens (最大允许: 1808)
2025-12-25 15:21:43,124 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8587 tokens (最大允许: 1808)
2025-12-25 15:21:43,144 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8602 tokens (最大允许: 1808)
2025-12-25 15:21:43,163 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8606 tokens (最大允许: 1808)
2025-12-25 15:21:43,184 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8620 tokens (最大允许: 1808)
2025-12-25 15:21:43,204 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8528 tokens (最大允许: 1808)
2025-12-25 15:21:43,223 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:21:43,247 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8618 tokens (最大允许: 1808)
2025-12-25 15:21:43,266 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8615 tokens (最大允许: 1808)
2025-12-25 15:21:43,285 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8610 tokens (最大允许: 1808)
2025-12-25 15:21:43,291 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 2444 tokens (最大允许: 1808)
2025-12-25 15:21:43,311 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8618 tokens (最大允许: 1808)
2025-12-25 15:21:43,330 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:21:43,350 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8603 tokens (最大允许: 1808)
2025-12-25 15:21:43,370 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:21:43,389 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8603 tokens (最大允许: 1808)
2025-12-25 15:21:43,409 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8603 tokens (最大允许: 1808)
2025-12-25 15:21:43,431 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:21:43,450 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:21:43,469 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:43,489 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:43,509 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:21:43,528 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8594 tokens (最大允许: 1808)
2025-12-25 15:21:43,534 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 2806 tokens (最大允许: 1808)
2025-12-25 15:21:43,555 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8531 tokens (最大允许: 1808)
2025-12-25 15:21:43,573 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8528 tokens (最大允许: 1808)
2025-12-25 15:21:43,591 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8597 tokens (最大允许: 1808)
2025-12-25 15:21:43,612 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:21:43,631 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:21:43,649 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:43,669 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8584 tokens (最大允许: 1808)
2025-12-25 15:21:43,688 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8551 tokens (最大允许: 1808)
2025-12-25 15:21:43,707 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8602 tokens (最大允许: 1808)
2025-12-25 15:21:43,726 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:43,745 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8586 tokens (最大允许: 1808)
2025-12-25 15:21:43,764 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8596 tokens (最大允许: 1808)
2025-12-25 15:21:43,785 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8584 tokens (最大允许: 1808)
2025-12-25 15:21:43,805 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8606 tokens (最大允许: 1808)
2025-12-25 15:21:43,824 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8533 tokens (最大允许: 1808)
2025-12-25 15:21:43,844 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8620 tokens (最大允许: 1808)
2025-12-25 15:21:43,864 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:43,883 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8590 tokens (最大允许: 1808)
2025-12-25 15:21:43,901 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:21:43,920 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:43,937 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8543 tokens (最大允许: 1808)
2025-12-25 15:21:43,956 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8599 tokens (最大允许: 1808)
2025-12-25 15:21:43,976 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8531 tokens (最大允许: 1808)
2025-12-25 15:21:43,995 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8599 tokens (最大允许: 1808)
2025-12-25 15:21:44,022 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8600 tokens (最大允许: 1808)
2025-12-25 15:21:44,042 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:21:44,059 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:44,081 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8623 tokens (最大允许: 1808)
2025-12-25 15:21:44,100 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8544 tokens (最大允许: 1808)
2025-12-25 15:21:44,119 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:21:44,139 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8606 tokens (最大允许: 1808)
2025-12-25 15:21:44,159 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8608 tokens (最大允许: 1808)
2025-12-25 15:21:44,177 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8535 tokens (最大允许: 1808)
2025-12-25 15:21:44,195 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8608 tokens (最大允许: 1808)
2025-12-25 15:21:44,214 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:44,232 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8533 tokens (最大允许: 1808)
2025-12-25 15:21:44,250 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8590 tokens (最大允许: 1808)
2025-12-25 15:21:44,270 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8620 tokens (最大允许: 1808)
2025-12-25 15:21:44,290 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8617 tokens (最大允许: 1808)
2025-12-25 15:21:44,310 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:21:44,330 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8586 tokens (最大允许: 1808)
2025-12-25 15:21:44,349 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8594 tokens (最大允许: 1808)
2025-12-25 15:21:44,369 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8595 tokens (最大允许: 1808)
2025-12-25 15:21:44,389 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8618 tokens (最大允许: 1808)
2025-12-25 15:21:44,407 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8619 tokens (最大允许: 1808)
2025-12-25 15:21:44,432 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8602 tokens (最大允许: 1808)
2025-12-25 15:21:44,452 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8617 tokens (最大允许: 1808)
2025-12-25 15:21:44,471 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8605 tokens (最大允许: 1808)
2025-12-25 15:21:44,492 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8533 tokens (最大允许: 1808)
2025-12-25 15:21:44,499 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 3259 tokens (最大允许: 1808)
2025-12-25 15:21:44,517 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:44,536 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8589 tokens (最大允许: 1808)
2025-12-25 15:21:44,555 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8532 tokens (最大允许: 1808)
2025-12-25 15:21:44,574 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8594 tokens (最大允许: 1808)
2025-12-25 15:21:44,593 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8609 tokens (最大允许: 1808)
2025-12-25 15:21:44,611 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8594 tokens (最大允许: 1808)
2025-12-25 15:21:44,630 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8614 tokens (最大允许: 1808)
2025-12-25 15:21:44,641 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 5171 tokens (最大允许: 1808)
2025-12-25 15:21:44,660 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:44,679 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:44,698 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8606 tokens (最大允许: 1808)
2025-12-25 15:21:44,717 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:21:44,737 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8532 tokens (最大允许: 1808)
2025-12-25 15:21:44,756 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8597 tokens (最大允许: 1808)
2025-12-25 15:21:44,776 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:21:44,794 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8529 tokens (最大允许: 1808)
2025-12-25 15:21:44,814 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:44,833 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8605 tokens (最大允许: 1808)
2025-12-25 15:21:44,852 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8590 tokens (最大允许: 1808)
2025-12-25 15:21:44,872 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:21:44,891 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:21:44,911 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8614 tokens (最大允许: 1808)
2025-12-25 15:21:44,915 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 1904 tokens (最大允许: 1808)
2025-12-25 15:21:44,934 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:21:44,952 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:21:44,972 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:21:44,992 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8531 tokens (最大允许: 1808)
2025-12-25 15:21:45,011 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:45,030 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:21:45,050 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:21:45,069 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8552 tokens (最大允许: 1808)
2025-12-25 15:21:45,089 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8601 tokens (最大允许: 1808)
2025-12-25 15:21:45,109 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:21:45,128 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8618 tokens (最大允许: 1808)
2025-12-25 15:21:45,147 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:45,166 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8608 tokens (最大允许: 1808)
2025-12-25 15:21:45,185 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:21:45,205 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8604 tokens (最大允许: 1808)
2025-12-25 15:21:45,223 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:21:45,242 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8548 tokens (最大允许: 1808)
2025-12-25 15:21:45,262 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8597 tokens (最大允许: 1808)
2025-12-25 15:21:45,282 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8545 tokens (最大允许: 1808)
2025-12-25 15:21:45,300 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:45,318 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8602 tokens (最大允许: 1808)
2025-12-25 15:21:45,337 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8530 tokens (最大允许: 1808)
2025-12-25 15:21:45,356 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8610 tokens (最大允许: 1808)
2025-12-25 15:21:45,357 - inference.local_inference - WARNING - 共跳过 127/128 条超长prompts
2025-12-25 15:23:42,066 - __main__ - INFO - 批次 [1-128] 本地推理完成
2025-12-25 15:23:42,067 - __main__ - INFO - 处理批次 [129-250/250]
2025-12-25 15:23:42,068 - __main__ - INFO -   → 生成Baseline答案 (122 条)...
2025-12-25 15:23:42,068 - __main__ - INFO - 批量生成Baseline答案: 122 条
2025-12-25 15:24:04,479 - __main__ - INFO -   → 生成差异分析 (122 条)...
2025-12-25 15:24:04,480 - __main__ - INFO - 批量生成差异分析: 122 条
2025-12-25 15:25:38,829 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 15:25:38,829 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 15:25:38,859 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8679 tokens (最大允许: 1808)
2025-12-25 15:25:38,879 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8679 tokens (最大允许: 1808)
2025-12-25 15:25:38,899 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8725 tokens (最大允许: 1808)
2025-12-25 15:25:38,918 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8720 tokens (最大允许: 1808)
2025-12-25 15:25:38,936 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8730 tokens (最大允许: 1808)
2025-12-25 15:25:38,954 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8728 tokens (最大允许: 1808)
2025-12-25 15:25:38,971 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8643 tokens (最大允许: 1808)
2025-12-25 15:25:38,988 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8637 tokens (最大允许: 1808)
2025-12-25 15:25:39,006 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8631 tokens (最大允许: 1808)
2025-12-25 15:25:39,024 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:25:39,043 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8800 tokens (最大允许: 1808)
2025-12-25 15:25:39,061 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8783 tokens (最大允许: 1808)
2025-12-25 15:25:39,080 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8811 tokens (最大允许: 1808)
2025-12-25 15:25:39,099 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8791 tokens (最大允许: 1808)
2025-12-25 15:25:39,117 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8638 tokens (最大允许: 1808)
2025-12-25 15:25:39,135 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8636 tokens (最大允许: 1808)
2025-12-25 15:25:39,153 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8653 tokens (最大允许: 1808)
2025-12-25 15:25:39,171 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8642 tokens (最大允许: 1808)
2025-12-25 15:25:39,189 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8771 tokens (最大允许: 1808)
2025-12-25 15:25:39,207 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8770 tokens (最大允许: 1808)
2025-12-25 15:25:39,226 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8771 tokens (最大允许: 1808)
2025-12-25 15:25:39,251 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8764 tokens (最大允许: 1808)
2025-12-25 15:25:39,271 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8757 tokens (最大允许: 1808)
2025-12-25 15:25:39,290 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8753 tokens (最大允许: 1808)
2025-12-25 15:25:39,309 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8755 tokens (最大允许: 1808)
2025-12-25 15:25:39,327 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:25:39,346 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8615 tokens (最大允许: 1808)
2025-12-25 15:25:39,365 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8626 tokens (最大允许: 1808)
2025-12-25 15:25:39,369 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 1969 tokens (最大允许: 1808)
2025-12-25 15:25:39,388 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8835 tokens (最大允许: 1808)
2025-12-25 15:25:39,406 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8838 tokens (最大允许: 1808)
2025-12-25 15:25:39,425 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8846 tokens (最大允许: 1808)
2025-12-25 15:25:39,443 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:25:39,461 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:25:39,479 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:25:39,497 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8609 tokens (最大允许: 1808)
2025-12-25 15:25:39,515 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8802 tokens (最大允许: 1808)
2025-12-25 15:25:39,533 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8796 tokens (最大允许: 1808)
2025-12-25 15:25:39,552 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8795 tokens (最大允许: 1808)
2025-12-25 15:25:39,573 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:25:39,590 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:25:39,607 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8639 tokens (最大允许: 1808)
2025-12-25 15:25:39,624 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8634 tokens (最大允许: 1808)
2025-12-25 15:25:39,642 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8645 tokens (最大允许: 1808)
2025-12-25 15:25:39,659 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8640 tokens (最大允许: 1808)
2025-12-25 15:25:39,679 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8643 tokens (最大允许: 1808)
2025-12-25 15:25:39,696 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8615 tokens (最大允许: 1808)
2025-12-25 15:25:39,714 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:25:39,731 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8613 tokens (最大允许: 1808)
2025-12-25 15:25:39,749 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:25:39,766 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8737 tokens (最大允许: 1808)
2025-12-25 15:25:39,783 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8734 tokens (最大允许: 1808)
2025-12-25 15:25:39,801 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8743 tokens (最大允许: 1808)
2025-12-25 15:25:39,819 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8739 tokens (最大允许: 1808)
2025-12-25 15:25:39,836 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8721 tokens (最大允许: 1808)
2025-12-25 15:25:39,854 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8731 tokens (最大允许: 1808)
2025-12-25 15:25:39,872 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8732 tokens (最大允许: 1808)
2025-12-25 15:25:39,890 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8731 tokens (最大允许: 1808)
2025-12-25 15:25:39,908 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8739 tokens (最大允许: 1808)
2025-12-25 15:25:39,926 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8733 tokens (最大允许: 1808)
2025-12-25 15:25:39,947 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8735 tokens (最大允许: 1808)
2025-12-25 15:25:39,965 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8689 tokens (最大允许: 1808)
2025-12-25 15:25:39,984 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8693 tokens (最大允许: 1808)
2025-12-25 15:25:40,003 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8688 tokens (最大允许: 1808)
2025-12-25 15:25:40,022 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8685 tokens (最大允许: 1808)
2025-12-25 15:25:40,041 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8664 tokens (最大允许: 1808)
2025-12-25 15:25:40,058 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8656 tokens (最大允许: 1808)
2025-12-25 15:25:40,078 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8653 tokens (最大允许: 1808)
2025-12-25 15:25:40,098 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8661 tokens (最大允许: 1808)
2025-12-25 15:25:40,117 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8827 tokens (最大允许: 1808)
2025-12-25 15:25:40,135 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8792 tokens (最大允许: 1808)
2025-12-25 15:25:40,153 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8800 tokens (最大允许: 1808)
2025-12-25 15:25:40,172 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8803 tokens (最大允许: 1808)
2025-12-25 15:25:40,191 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8733 tokens (最大允许: 1808)
2025-12-25 15:25:40,209 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8733 tokens (最大允许: 1808)
2025-12-25 15:25:40,227 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8728 tokens (最大允许: 1808)
2025-12-25 15:25:40,248 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8724 tokens (最大允许: 1808)
2025-12-25 15:25:40,268 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8688 tokens (最大允许: 1808)
2025-12-25 15:25:40,288 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8688 tokens (最大允许: 1808)
2025-12-25 15:25:40,306 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8681 tokens (最大允许: 1808)
2025-12-25 15:25:40,324 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8683 tokens (最大允许: 1808)
2025-12-25 15:25:40,344 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8735 tokens (最大允许: 1808)
2025-12-25 15:25:40,362 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8736 tokens (最大允许: 1808)
2025-12-25 15:25:40,381 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8744 tokens (最大允许: 1808)
2025-12-25 15:25:40,399 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8742 tokens (最大允许: 1808)
2025-12-25 15:25:40,420 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8682 tokens (最大允许: 1808)
2025-12-25 15:25:40,438 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8669 tokens (最大允许: 1808)
2025-12-25 15:25:40,455 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8681 tokens (最大允许: 1808)
2025-12-25 15:25:40,473 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8653 tokens (最大允许: 1808)
2025-12-25 15:25:40,490 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8649 tokens (最大允许: 1808)
2025-12-25 15:25:40,507 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8652 tokens (最大允许: 1808)
2025-12-25 15:25:40,525 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8652 tokens (最大允许: 1808)
2025-12-25 15:25:40,542 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8626 tokens (最大允许: 1808)
2025-12-25 15:25:40,559 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:25:40,577 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:25:40,594 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8626 tokens (最大允许: 1808)
2025-12-25 15:25:40,614 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8622 tokens (最大允许: 1808)
2025-12-25 15:25:40,633 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8694 tokens (最大允许: 1808)
2025-12-25 15:25:40,650 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8654 tokens (最大允许: 1808)
2025-12-25 15:25:40,667 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8774 tokens (最大允许: 1808)
2025-12-25 15:25:40,685 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8773 tokens (最大允许: 1808)
2025-12-25 15:25:40,703 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8759 tokens (最大允许: 1808)
2025-12-25 15:25:40,721 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8772 tokens (最大允许: 1808)
2025-12-25 15:25:40,740 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8627 tokens (最大允许: 1808)
2025-12-25 15:25:40,758 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8653 tokens (最大允许: 1808)
2025-12-25 15:25:40,778 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8680 tokens (最大允许: 1808)
2025-12-25 15:25:40,795 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8635 tokens (最大允许: 1808)
2025-12-25 15:25:40,813 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8682 tokens (最大允许: 1808)
2025-12-25 15:25:40,832 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8676 tokens (最大允许: 1808)
2025-12-25 15:25:40,850 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8670 tokens (最大允许: 1808)
2025-12-25 15:25:40,868 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8694 tokens (最大允许: 1808)
2025-12-25 15:25:40,887 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8811 tokens (最大允许: 1808)
2025-12-25 15:25:40,905 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8810 tokens (最大允许: 1808)
2025-12-25 15:25:40,924 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8827 tokens (最大允许: 1808)
2025-12-25 15:25:40,946 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8523 tokens (最大允许: 1808)
2025-12-25 15:25:40,963 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8526 tokens (最大允许: 1808)
2025-12-25 15:25:40,981 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8526 tokens (最大允许: 1808)
2025-12-25 15:25:41,000 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8730 tokens (最大允许: 1808)
2025-12-25 15:25:41,018 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8757 tokens (最大允许: 1808)
2025-12-25 15:25:41,036 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8715 tokens (最大允许: 1808)
2025-12-25 15:25:41,037 - inference.local_inference - WARNING - 共跳过 120/128 条超长prompts
2025-12-25 15:27:59,281 - __main__ - INFO - 批次 [2945-3072] 本地推理完成
2025-12-25 15:27:59,282 - __main__ - INFO - 处理批次 [3073-3200/99842]
2025-12-25 15:27:59,282 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 15:27:59,282 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 15:28:09,003 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 15:28:09,003 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 15:34:26,763 - __main__ - INFO -   → 生成Rejected原则 (122 条)...
2025-12-25 15:34:26,763 - __main__ - INFO - 批量生成原则（弱模型）: 122 条
2025-12-25 15:34:26,790 - inference.local_inference - WARNING - 跳过超长prompt [1/122]: 8604 tokens (最大允许: 1808)
2025-12-25 15:34:26,811 - inference.local_inference - WARNING - 跳过超长prompt [2/122]: 8611 tokens (最大允许: 1808)
2025-12-25 15:34:26,831 - inference.local_inference - WARNING - 跳过超长prompt [3/122]: 8540 tokens (最大允许: 1808)
2025-12-25 15:34:26,850 - inference.local_inference - WARNING - 跳过超长prompt [4/122]: 8531 tokens (最大允许: 1808)
2025-12-25 15:34:26,870 - inference.local_inference - WARNING - 跳过超长prompt [5/122]: 8615 tokens (最大允许: 1808)
2025-12-25 15:34:26,888 - inference.local_inference - WARNING - 跳过超长prompt [6/122]: 8611 tokens (最大允许: 1808)
2025-12-25 15:34:26,908 - inference.local_inference - WARNING - 跳过超长prompt [7/122]: 8530 tokens (最大允许: 1808)
2025-12-25 15:34:26,928 - inference.local_inference - WARNING - 跳过超长prompt [8/122]: 8587 tokens (最大允许: 1808)
2025-12-25 15:34:26,948 - inference.local_inference - WARNING - 跳过超长prompt [9/122]: 8532 tokens (最大允许: 1808)
2025-12-25 15:34:26,967 - inference.local_inference - WARNING - 跳过超长prompt [10/122]: 8619 tokens (最大允许: 1808)
2025-12-25 15:34:26,987 - inference.local_inference - WARNING - 跳过超长prompt [11/122]: 8617 tokens (最大允许: 1808)
2025-12-25 15:34:27,007 - inference.local_inference - WARNING - 跳过超长prompt [12/122]: 8534 tokens (最大允许: 1808)
2025-12-25 15:34:27,027 - inference.local_inference - WARNING - 跳过超长prompt [13/122]: 8610 tokens (最大允许: 1808)
2025-12-25 15:34:27,047 - inference.local_inference - WARNING - 跳过超长prompt [14/122]: 8610 tokens (最大允许: 1808)
2025-12-25 15:34:27,066 - inference.local_inference - WARNING - 跳过超长prompt [15/122]: 8615 tokens (最大允许: 1808)
2025-12-25 15:34:27,085 - inference.local_inference - WARNING - 跳过超长prompt [16/122]: 8616 tokens (最大允许: 1808)
2025-12-25 15:34:27,103 - inference.local_inference - WARNING - 跳过超长prompt [17/122]: 8533 tokens (最大允许: 1808)
2025-12-25 15:34:27,121 - inference.local_inference - WARNING - 跳过超长prompt [18/122]: 8599 tokens (最大允许: 1808)
2025-12-25 15:34:27,146 - inference.local_inference - WARNING - 跳过超长prompt [19/122]: 8534 tokens (最大允许: 1808)
2025-12-25 15:34:27,165 - inference.local_inference - WARNING - 跳过超长prompt [20/122]: 8599 tokens (最大允许: 1808)
2025-12-25 15:34:27,184 - inference.local_inference - WARNING - 跳过超长prompt [21/122]: 8599 tokens (最大允许: 1808)
2025-12-25 15:34:27,204 - inference.local_inference - WARNING - 跳过超长prompt [22/122]: 8623 tokens (最大允许: 1808)
2025-12-25 15:34:27,221 - inference.local_inference - WARNING - 跳过超长prompt [23/122]: 8600 tokens (最大允许: 1808)
2025-12-25 15:34:27,240 - inference.local_inference - WARNING - 跳过超长prompt [24/122]: 8598 tokens (最大允许: 1808)
2025-12-25 15:34:27,258 - inference.local_inference - WARNING - 跳过超长prompt [25/122]: 8595 tokens (最大允许: 1808)
2025-12-25 15:34:27,276 - inference.local_inference - WARNING - 跳过超长prompt [26/122]: 8545 tokens (最大允许: 1808)
2025-12-25 15:34:27,295 - inference.local_inference - WARNING - 跳过超长prompt [27/122]: 8620 tokens (最大允许: 1808)
2025-12-25 15:34:27,313 - inference.local_inference - WARNING - 跳过超长prompt [28/122]: 8607 tokens (最大允许: 1808)
2025-12-25 15:34:27,331 - inference.local_inference - WARNING - 跳过超长prompt [29/122]: 8620 tokens (最大允许: 1808)
2025-12-25 15:34:27,349 - inference.local_inference - WARNING - 跳过超长prompt [30/122]: 8534 tokens (最大允许: 1808)
2025-12-25 15:34:27,367 - inference.local_inference - WARNING - 跳过超长prompt [31/122]: 8610 tokens (最大允许: 1808)
2025-12-25 15:34:27,386 - inference.local_inference - WARNING - 跳过超长prompt [32/122]: 8609 tokens (最大允许: 1808)
2025-12-25 15:34:27,405 - inference.local_inference - WARNING - 跳过超长prompt [33/122]: 8604 tokens (最大允许: 1808)
2025-12-25 15:34:27,424 - inference.local_inference - WARNING - 跳过超长prompt [34/122]: 8541 tokens (最大允许: 1808)
2025-12-25 15:34:27,442 - inference.local_inference - WARNING - 跳过超长prompt [35/122]: 8611 tokens (最大允许: 1808)
2025-12-25 15:34:27,460 - inference.local_inference - WARNING - 跳过超长prompt [36/122]: 8597 tokens (最大允许: 1808)
2025-12-25 15:34:27,478 - inference.local_inference - WARNING - 跳过超长prompt [37/122]: 8614 tokens (最大允许: 1808)
2025-12-25 15:34:27,497 - inference.local_inference - WARNING - 跳过超长prompt [38/122]: 8530 tokens (最大允许: 1808)
2025-12-25 15:34:27,515 - inference.local_inference - WARNING - 跳过超长prompt [39/122]: 8600 tokens (最大允许: 1808)
2025-12-25 15:34:27,534 - inference.local_inference - WARNING - 跳过超长prompt [40/122]: 8542 tokens (最大允许: 1808)
2025-12-25 15:34:27,551 - inference.local_inference - WARNING - 跳过超长prompt [41/122]: 8605 tokens (最大允许: 1808)
2025-12-25 15:34:27,568 - inference.local_inference - WARNING - 跳过超长prompt [42/122]: 8602 tokens (最大允许: 1808)
2025-12-25 15:34:27,574 - inference.local_inference - WARNING - 跳过超长prompt [43/122]: 2615 tokens (最大允许: 1808)
2025-12-25 15:34:27,591 - inference.local_inference - WARNING - 跳过超长prompt [44/122]: 8600 tokens (最大允许: 1808)
2025-12-25 15:34:27,609 - inference.local_inference - WARNING - 跳过超长prompt [45/122]: 8538 tokens (最大允许: 1808)
2025-12-25 15:34:27,628 - inference.local_inference - WARNING - 跳过超长prompt [46/122]: 8534 tokens (最大允许: 1808)
2025-12-25 15:34:27,647 - inference.local_inference - WARNING - 跳过超长prompt [47/122]: 8597 tokens (最大允许: 1808)
2025-12-25 15:34:27,665 - inference.local_inference - WARNING - 跳过超长prompt [48/122]: 8610 tokens (最大允许: 1808)
2025-12-25 15:34:27,683 - inference.local_inference - WARNING - 跳过超长prompt [49/122]: 8596 tokens (最大允许: 1808)
2025-12-25 15:34:27,700 - inference.local_inference - WARNING - 跳过超长prompt [50/122]: 8609 tokens (最大允许: 1808)
2025-12-25 15:34:27,719 - inference.local_inference - WARNING - 跳过超长prompt [51/122]: 8529 tokens (最大允许: 1808)
2025-12-25 15:34:27,737 - inference.local_inference - WARNING - 跳过超长prompt [52/122]: 8599 tokens (最大允许: 1808)
2025-12-25 15:34:27,755 - inference.local_inference - WARNING - 跳过超长prompt [53/122]: 8598 tokens (最大允许: 1808)
2025-12-25 15:34:27,774 - inference.local_inference - WARNING - 跳过超长prompt [54/122]: 8546 tokens (最大允许: 1808)
2025-12-25 15:34:27,792 - inference.local_inference - WARNING - 跳过超长prompt [55/122]: 8534 tokens (最大允许: 1808)
2025-12-25 15:34:27,811 - inference.local_inference - WARNING - 跳过超长prompt [56/122]: 8528 tokens (最大允许: 1808)
2025-12-25 15:34:27,827 - inference.local_inference - WARNING - 跳过超长prompt [57/122]: 8622 tokens (最大允许: 1808)
2025-12-25 15:34:27,846 - inference.local_inference - WARNING - 跳过超长prompt [58/122]: 8606 tokens (最大允许: 1808)
2025-12-25 15:34:27,865 - inference.local_inference - WARNING - 跳过超长prompt [59/122]: 8547 tokens (最大允许: 1808)
2025-12-25 15:34:27,882 - inference.local_inference - WARNING - 跳过超长prompt [60/122]: 8610 tokens (最大允许: 1808)
2025-12-25 15:34:27,899 - inference.local_inference - WARNING - 跳过超长prompt [61/122]: 8548 tokens (最大允许: 1808)
2025-12-25 15:34:27,918 - inference.local_inference - WARNING - 跳过超长prompt [62/122]: 8628 tokens (最大允许: 1808)
2025-12-25 15:34:27,935 - inference.local_inference - WARNING - 跳过超长prompt [63/122]: 8598 tokens (最大允许: 1808)
2025-12-25 15:34:27,958 - inference.local_inference - WARNING - 跳过超长prompt [64/122]: 8594 tokens (最大允许: 1808)
2025-12-25 15:34:27,977 - inference.local_inference - WARNING - 跳过超长prompt [65/122]: 8534 tokens (最大允许: 1808)
2025-12-25 15:34:27,995 - inference.local_inference - WARNING - 跳过超长prompt [66/122]: 8608 tokens (最大允许: 1808)
2025-12-25 15:34:28,013 - inference.local_inference - WARNING - 跳过超长prompt [67/122]: 8620 tokens (最大允许: 1808)
2025-12-25 15:34:28,031 - inference.local_inference - WARNING - 跳过超长prompt [68/122]: 8594 tokens (最大允许: 1808)
2025-12-25 15:34:28,049 - inference.local_inference - WARNING - 跳过超长prompt [69/122]: 8596 tokens (最大允许: 1808)
2025-12-25 15:34:28,067 - inference.local_inference - WARNING - 跳过超长prompt [70/122]: 8585 tokens (最大允许: 1808)
2025-12-25 15:34:28,087 - inference.local_inference - WARNING - 跳过超长prompt [71/122]: 8610 tokens (最大允许: 1808)
2025-12-25 15:34:28,094 - inference.local_inference - WARNING - 跳过超长prompt [72/122]: 3460 tokens (最大允许: 1808)
2025-12-25 15:34:28,113 - inference.local_inference - WARNING - 跳过超长prompt [73/122]: 8573 tokens (最大允许: 1808)
2025-12-25 15:34:28,131 - inference.local_inference - WARNING - 跳过超长prompt [74/122]: 8594 tokens (最大允许: 1808)
2025-12-25 15:34:28,151 - inference.local_inference - WARNING - 跳过超长prompt [75/122]: 8613 tokens (最大允许: 1808)
2025-12-25 15:34:28,170 - inference.local_inference - WARNING - 跳过超长prompt [76/122]: 8594 tokens (最大允许: 1808)
2025-12-25 15:34:28,188 - inference.local_inference - WARNING - 跳过超长prompt [77/122]: 8600 tokens (最大允许: 1808)
2025-12-25 15:34:28,208 - inference.local_inference - WARNING - 跳过超长prompt [78/122]: 8609 tokens (最大允许: 1808)
2025-12-25 15:34:28,229 - inference.local_inference - WARNING - 跳过超长prompt [79/122]: 8591 tokens (最大允许: 1808)
2025-12-25 15:34:28,249 - inference.local_inference - WARNING - 跳过超长prompt [80/122]: 8608 tokens (最大允许: 1808)
2025-12-25 15:34:28,270 - inference.local_inference - WARNING - 跳过超长prompt [81/122]: 8544 tokens (最大允许: 1808)
2025-12-25 15:34:28,289 - inference.local_inference - WARNING - 跳过超长prompt [82/122]: 8545 tokens (最大允许: 1808)
2025-12-25 15:34:28,307 - inference.local_inference - WARNING - 跳过超长prompt [83/122]: 8598 tokens (最大允许: 1808)
2025-12-25 15:34:28,327 - inference.local_inference - WARNING - 跳过超长prompt [84/122]: 8599 tokens (最大允许: 1808)
2025-12-25 15:34:28,345 - inference.local_inference - WARNING - 跳过超长prompt [85/122]: 8534 tokens (最大允许: 1808)
2025-12-25 15:34:28,363 - inference.local_inference - WARNING - 跳过超长prompt [86/122]: 8608 tokens (最大允许: 1808)
2025-12-25 15:34:28,383 - inference.local_inference - WARNING - 跳过超长prompt [87/122]: 8533 tokens (最大允许: 1808)
2025-12-25 15:34:28,402 - inference.local_inference - WARNING - 跳过超长prompt [88/122]: 8590 tokens (最大允许: 1808)
2025-12-25 15:34:28,423 - inference.local_inference - WARNING - 跳过超长prompt [89/122]: 8598 tokens (最大允许: 1808)
2025-12-25 15:34:28,445 - inference.local_inference - WARNING - 跳过超长prompt [90/122]: 8575 tokens (最大允许: 1808)
2025-12-25 15:34:28,467 - inference.local_inference - WARNING - 跳过超长prompt [91/122]: 8590 tokens (最大允许: 1808)
2025-12-25 15:34:28,487 - inference.local_inference - WARNING - 跳过超长prompt [92/122]: 8597 tokens (最大允许: 1808)
2025-12-25 15:34:28,508 - inference.local_inference - WARNING - 跳过超长prompt [93/122]: 8620 tokens (最大允许: 1808)
2025-12-25 15:34:28,528 - inference.local_inference - WARNING - 跳过超长prompt [94/122]: 8541 tokens (最大允许: 1808)
2025-12-25 15:34:28,550 - inference.local_inference - WARNING - 跳过超长prompt [95/122]: 8590 tokens (最大允许: 1808)
2025-12-25 15:34:28,573 - inference.local_inference - WARNING - 跳过超长prompt [96/122]: 8603 tokens (最大允许: 1808)
2025-12-25 15:34:28,594 - inference.local_inference - WARNING - 跳过超长prompt [97/122]: 8547 tokens (最大允许: 1808)
2025-12-25 15:34:28,614 - inference.local_inference - WARNING - 跳过超长prompt [98/122]: 8634 tokens (最大允许: 1808)
2025-12-25 15:34:28,633 - inference.local_inference - WARNING - 跳过超长prompt [99/122]: 8533 tokens (最大允许: 1808)
2025-12-25 15:34:28,653 - inference.local_inference - WARNING - 跳过超长prompt [100/122]: 8612 tokens (最大允许: 1808)
2025-12-25 15:34:28,672 - inference.local_inference - WARNING - 跳过超长prompt [101/122]: 8611 tokens (最大允许: 1808)
2025-12-25 15:34:28,693 - inference.local_inference - WARNING - 跳过超长prompt [102/122]: 8620 tokens (最大允许: 1808)
2025-12-25 15:34:28,711 - inference.local_inference - WARNING - 跳过超长prompt [103/122]: 8593 tokens (最大允许: 1808)
2025-12-25 15:34:28,717 - inference.local_inference - WARNING - 跳过超长prompt [104/122]: 2449 tokens (最大允许: 1808)
2025-12-25 15:34:28,737 - inference.local_inference - WARNING - 跳过超长prompt [105/122]: 8619 tokens (最大允许: 1808)
2025-12-25 15:34:28,757 - inference.local_inference - WARNING - 跳过超长prompt [106/122]: 8599 tokens (最大允许: 1808)
2025-12-25 15:34:28,778 - inference.local_inference - WARNING - 跳过超长prompt [107/122]: 8585 tokens (最大允许: 1808)
2025-12-25 15:34:28,801 - inference.local_inference - WARNING - 跳过超长prompt [108/122]: 8531 tokens (最大允许: 1808)
2025-12-25 15:34:28,823 - inference.local_inference - WARNING - 跳过超长prompt [109/122]: 8607 tokens (最大允许: 1808)
2025-12-25 15:34:28,845 - inference.local_inference - WARNING - 跳过超长prompt [110/122]: 8613 tokens (最大允许: 1808)
2025-12-25 15:34:28,867 - inference.local_inference - WARNING - 跳过超长prompt [111/122]: 8620 tokens (最大允许: 1808)
2025-12-25 15:34:28,890 - inference.local_inference - WARNING - 跳过超长prompt [112/122]: 8615 tokens (最大允许: 1808)
2025-12-25 15:34:28,911 - inference.local_inference - WARNING - 跳过超长prompt [113/122]: 8604 tokens (最大允许: 1808)
2025-12-25 15:34:28,933 - inference.local_inference - WARNING - 跳过超长prompt [114/122]: 8595 tokens (最大允许: 1808)
2025-12-25 15:34:28,952 - inference.local_inference - WARNING - 跳过超长prompt [115/122]: 8628 tokens (最大允许: 1808)
2025-12-25 15:34:28,972 - inference.local_inference - WARNING - 跳过超长prompt [116/122]: 8610 tokens (最大允许: 1808)
2025-12-25 15:34:28,991 - inference.local_inference - WARNING - 跳过超长prompt [117/122]: 8603 tokens (最大允许: 1808)
2025-12-25 15:34:29,011 - inference.local_inference - WARNING - 跳过超长prompt [118/122]: 8547 tokens (最大允许: 1808)
2025-12-25 15:34:29,032 - inference.local_inference - WARNING - 跳过超长prompt [119/122]: 8603 tokens (最大允许: 1808)
2025-12-25 15:34:29,052 - inference.local_inference - WARNING - 跳过超长prompt [120/122]: 8616 tokens (最大允许: 1808)
2025-12-25 15:34:29,073 - inference.local_inference - WARNING - 跳过超长prompt [121/122]: 8619 tokens (最大允许: 1808)
2025-12-25 15:34:29,091 - inference.local_inference - WARNING - 跳过超长prompt [122/122]: 8589 tokens (最大允许: 1808)
2025-12-25 15:34:29,091 - inference.local_inference - WARNING - 共跳过 122/122 条超长prompts
2025-12-25 15:34:29,092 - inference.local_inference - ERROR - 所有prompts都超长，返回空列表
2025-12-25 15:34:29,092 - __main__ - INFO - 批次 [129-250] 本地推理完成
2025-12-25 15:34:29,092 - __main__ - INFO - 阶段1完成: 共生成 250 条本地推理结果
2025-12-25 15:34:29,092 - __main__ - WARNING - ⚠️  249/250 条rejected原则为空（可能因prompt超长被跳过）
2025-12-25 15:34:29,092 - __main__ - INFO - 保存vLLM处理结果到: /home/metanew2/output/vllm_cache.json
2025-12-25 15:34:29,169 - __main__ - INFO - vLLM处理结果已安全保存
2025-12-25 15:34:29,170 - __main__ - INFO - ============================================================
2025-12-25 15:34:29,170 - __main__ - INFO - 阶段2/3: API并发生成Chosen（分批处理）
2025-12-25 15:34:29,170 - __main__ - INFO - ============================================================
2025-12-25 15:34:29,170 - __main__ - INFO - API分批处理: 每批 30 条，共 9 批
2025-12-25 15:34:29,170 - __main__ - INFO - API批次 [1-30/250] 开始处理...
2025-12-25 15:34:29,170 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:35:38,146 - __main__ - INFO - API批次 [1-30] 完成
2025-12-25 15:35:38,146 - __main__ - INFO - API批次 [31-60/250] 开始处理...
2025-12-25 15:35:38,146 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:37:05,894 - __main__ - INFO - API批次 [31-60] 完成
2025-12-25 15:37:05,895 - __main__ - INFO - API批次 [61-90/250] 开始处理...
2025-12-25 15:37:05,895 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:38:16,942 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 15:38:16,943 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 15:38:16,972 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8722 tokens (最大允许: 1808)
2025-12-25 15:38:16,992 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8697 tokens (最大允许: 1808)
2025-12-25 15:38:17,011 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8692 tokens (最大允许: 1808)
2025-12-25 15:38:17,029 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8765 tokens (最大允许: 1808)
2025-12-25 15:38:17,049 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8743 tokens (最大允许: 1808)
2025-12-25 15:38:17,067 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8637 tokens (最大允许: 1808)
2025-12-25 15:38:17,085 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8646 tokens (最大允许: 1808)
2025-12-25 15:38:17,104 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8630 tokens (最大允许: 1808)
2025-12-25 15:38:17,122 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:38:17,142 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8825 tokens (最大允许: 1808)
2025-12-25 15:38:17,161 - inference.local_inference - WARNING - 跳过超长prompt [11/128]: 8813 tokens (最大允许: 1808)
2025-12-25 15:38:17,180 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8839 tokens (最大允许: 1808)
2025-12-25 15:38:17,200 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8821 tokens (最大允许: 1808)
2025-12-25 15:38:17,219 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8761 tokens (最大允许: 1808)
2025-12-25 15:38:17,237 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8788 tokens (最大允许: 1808)
2025-12-25 15:38:17,255 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8759 tokens (最大允许: 1808)
2025-12-25 15:38:17,274 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8713 tokens (最大允许: 1808)
2025-12-25 15:38:17,292 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8708 tokens (最大允许: 1808)
2025-12-25 15:38:17,310 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8718 tokens (最大允许: 1808)
2025-12-25 15:38:17,328 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8705 tokens (最大允许: 1808)
2025-12-25 15:38:17,350 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8673 tokens (最大允许: 1808)
2025-12-25 15:38:17,367 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8684 tokens (最大允许: 1808)
2025-12-25 15:38:17,385 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8684 tokens (最大允许: 1808)
2025-12-25 15:38:17,403 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8795 tokens (最大允许: 1808)
2025-12-25 15:38:17,422 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8795 tokens (最大允许: 1808)
2025-12-25 15:38:17,441 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8813 tokens (最大允许: 1808)
2025-12-25 15:38:17,462 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8771 tokens (最大允许: 1808)
2025-12-25 15:38:17,482 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:38:17,502 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8621 tokens (最大允许: 1808)
2025-12-25 15:38:17,522 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 8623 tokens (最大允许: 1808)
2025-12-25 15:38:17,541 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:38:17,561 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8641 tokens (最大允许: 1808)
2025-12-25 15:38:17,580 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8640 tokens (最大允许: 1808)
2025-12-25 15:38:17,600 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8650 tokens (最大允许: 1808)
2025-12-25 15:38:17,619 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:38:17,638 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:38:17,657 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8630 tokens (最大允许: 1808)
2025-12-25 15:38:17,676 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8619 tokens (最大允许: 1808)
2025-12-25 15:38:17,695 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8630 tokens (最大允许: 1808)
2025-12-25 15:38:17,714 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8630 tokens (最大允许: 1808)
2025-12-25 15:38:17,732 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8634 tokens (最大允许: 1808)
2025-12-25 15:38:17,751 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8636 tokens (最大允许: 1808)
2025-12-25 15:38:17,769 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8634 tokens (最大允许: 1808)
2025-12-25 15:38:17,787 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8659 tokens (最大允许: 1808)
2025-12-25 15:38:17,805 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8649 tokens (最大允许: 1808)
2025-12-25 15:38:17,823 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8673 tokens (最大允许: 1808)
2025-12-25 15:38:17,842 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8642 tokens (最大允许: 1808)
2025-12-25 15:38:17,861 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8762 tokens (最大允许: 1808)
2025-12-25 15:38:17,880 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 8768 tokens (最大允许: 1808)
2025-12-25 15:38:17,899 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8770 tokens (最大允许: 1808)
2025-12-25 15:38:17,919 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8770 tokens (最大允许: 1808)
2025-12-25 15:38:17,937 - inference.local_inference - WARNING - 跳过超长prompt [53/128]: 8636 tokens (最大允许: 1808)
2025-12-25 15:38:17,955 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8636 tokens (最大允许: 1808)
2025-12-25 15:38:17,975 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8636 tokens (最大允许: 1808)
2025-12-25 15:38:17,993 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8636 tokens (最大允许: 1808)
2025-12-25 15:38:18,012 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8637 tokens (最大允许: 1808)
2025-12-25 15:38:18,030 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8628 tokens (最大允许: 1808)
2025-12-25 15:38:18,049 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8627 tokens (最大允许: 1808)
2025-12-25 15:38:18,068 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8647 tokens (最大允许: 1808)
2025-12-25 15:38:18,087 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8705 tokens (最大允许: 1808)
2025-12-25 15:38:18,105 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8713 tokens (最大允许: 1808)
2025-12-25 15:38:18,124 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8701 tokens (最大允许: 1808)
2025-12-25 15:38:18,142 - inference.local_inference - WARNING - 跳过超长prompt [64/128]: 8701 tokens (最大允许: 1808)
2025-12-25 15:38:18,161 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8714 tokens (最大允许: 1808)
2025-12-25 15:38:18,180 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8711 tokens (最大允许: 1808)
2025-12-25 15:38:18,198 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8703 tokens (最大允许: 1808)
2025-12-25 15:38:18,217 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8727 tokens (最大允许: 1808)
2025-12-25 15:38:18,236 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8658 tokens (最大允许: 1808)
2025-12-25 15:38:18,254 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8671 tokens (最大允许: 1808)
2025-12-25 15:38:18,272 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8697 tokens (最大允许: 1808)
2025-12-25 15:38:18,290 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8651 tokens (最大允许: 1808)
2025-12-25 15:38:18,295 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 1944 tokens (最大允许: 1808)
2025-12-25 15:38:18,313 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8661 tokens (最大允许: 1808)
2025-12-25 15:38:18,333 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8676 tokens (最大允许: 1808)
2025-12-25 15:38:18,353 - inference.local_inference - WARNING - 跳过超长prompt [76/128]: 8661 tokens (最大允许: 1808)
2025-12-25 15:38:18,373 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8871 tokens (最大允许: 1808)
2025-12-25 15:38:18,392 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8848 tokens (最大允许: 1808)
2025-12-25 15:38:18,415 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8862 tokens (最大允许: 1808)
2025-12-25 15:38:18,433 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8666 tokens (最大允许: 1808)
2025-12-25 15:38:18,452 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 8660 tokens (最大允许: 1808)
2025-12-25 15:38:18,471 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8654 tokens (最大允许: 1808)
2025-12-25 15:38:18,489 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8659 tokens (最大允许: 1808)
2025-12-25 15:38:18,507 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8825 tokens (最大允许: 1808)
2025-12-25 15:38:18,526 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8826 tokens (最大允许: 1808)
2025-12-25 15:38:18,545 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8793 tokens (最大允许: 1808)
2025-12-25 15:38:18,564 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8806 tokens (最大允许: 1808)
2025-12-25 15:38:18,582 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8717 tokens (最大允许: 1808)
2025-12-25 15:38:18,601 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8723 tokens (最大允许: 1808)
2025-12-25 15:38:18,619 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8712 tokens (最大允许: 1808)
2025-12-25 15:38:18,637 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8713 tokens (最大允许: 1808)
2025-12-25 15:38:18,655 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8652 tokens (最大允许: 1808)
2025-12-25 15:38:18,673 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8653 tokens (最大允许: 1808)
2025-12-25 15:38:18,677 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 2130 tokens (最大允许: 1808)
2025-12-25 15:38:18,695 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8654 tokens (最大允许: 1808)
2025-12-25 15:38:18,713 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8674 tokens (最大允许: 1808)
2025-12-25 15:38:18,731 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8683 tokens (最大允许: 1808)
2025-12-25 15:38:18,750 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8690 tokens (最大允许: 1808)
2025-12-25 15:38:18,768 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8681 tokens (最大允许: 1808)
2025-12-25 15:38:18,785 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8644 tokens (最大允许: 1808)
2025-12-25 15:38:18,803 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8639 tokens (最大允许: 1808)
2025-12-25 15:38:18,821 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8641 tokens (最大允许: 1808)
2025-12-25 15:38:18,839 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8641 tokens (最大允许: 1808)
2025-12-25 15:38:18,857 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8655 tokens (最大允许: 1808)
2025-12-25 15:38:18,875 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8671 tokens (最大允许: 1808)
2025-12-25 15:38:18,894 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8667 tokens (最大允许: 1808)
2025-12-25 15:38:18,915 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 8667 tokens (最大允许: 1808)
2025-12-25 15:38:18,934 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8664 tokens (最大允许: 1808)
2025-12-25 15:38:18,951 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8648 tokens (最大允许: 1808)
2025-12-25 15:38:18,969 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 8646 tokens (最大允许: 1808)
2025-12-25 15:38:18,986 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8645 tokens (最大允许: 1808)
2025-12-25 15:38:19,005 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8673 tokens (最大允许: 1808)
2025-12-25 15:38:19,032 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8654 tokens (最大允许: 1808)
2025-12-25 15:38:19,052 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8648 tokens (最大允许: 1808)
2025-12-25 15:38:19,071 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8659 tokens (最大允许: 1808)
2025-12-25 15:38:19,090 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8804 tokens (最大允许: 1808)
2025-12-25 15:38:19,108 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8854 tokens (最大允许: 1808)
2025-12-25 15:38:19,126 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8844 tokens (最大允许: 1808)
2025-12-25 15:38:19,145 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8822 tokens (最大允许: 1808)
2025-12-25 15:38:19,163 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8655 tokens (最大允许: 1808)
2025-12-25 15:38:19,181 - inference.local_inference - WARNING - 跳过超长prompt [122/128]: 8628 tokens (最大允许: 1808)
2025-12-25 15:38:19,200 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8644 tokens (最大允许: 1808)
2025-12-25 15:38:19,218 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8645 tokens (最大允许: 1808)
2025-12-25 15:38:19,236 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8781 tokens (最大允许: 1808)
2025-12-25 15:38:19,254 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8741 tokens (最大允许: 1808)
2025-12-25 15:38:19,272 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8737 tokens (最大允许: 1808)
2025-12-25 15:38:19,289 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8772 tokens (最大允许: 1808)
2025-12-25 15:38:19,289 - inference.local_inference - WARNING - 共跳过 126/128 条超长prompts
2025-12-25 15:39:06,986 - __main__ - INFO - API批次 [61-90] 完成
2025-12-25 15:39:06,987 - __main__ - INFO - API批次 [91-120/250] 开始处理...
2025-12-25 15:39:06,987 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:39:32,776 - __main__ - INFO - API批次 [91-120] 完成
2025-12-25 15:39:32,777 - __main__ - INFO - API批次 [121-150/250] 开始处理...
2025-12-25 15:39:32,777 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:40:16,953 - __main__ - INFO - 批次 [3073-3200] 本地推理完成
2025-12-25 15:40:16,953 - __main__ - INFO - 处理批次 [3201-3328/99842]
2025-12-25 15:40:16,954 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 15:40:16,954 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 15:40:26,763 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 15:40:26,764 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 15:40:30,091 - __main__ - INFO - API批次 [121-150] 完成
2025-12-25 15:40:30,092 - __main__ - INFO - API批次 [151-180/250] 开始处理...
2025-12-25 15:40:30,092 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:41:30,506 - __main__ - INFO - API批次 [151-180] 完成
2025-12-25 15:41:30,506 - __main__ - INFO - API批次 [181-210/250] 开始处理...
2025-12-25 15:41:30,506 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:43:06,674 - __main__ - INFO - API批次 [181-210] 完成
2025-12-25 15:43:06,675 - __main__ - INFO - API批次 [211-240/250] 开始处理...
2025-12-25 15:43:06,675 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:44:32,707 - __main__ - INFO - API批次 [211-240] 完成
2025-12-25 15:44:32,708 - __main__ - INFO - API批次 [241-250/250] 开始处理...
2025-12-25 15:44:32,708 - module.execute_module - INFO - 启动 30 个并发线程调用强模型API
2025-12-25 15:45:02,710 - __main__ - INFO - API批次 [241-250] 完成
2025-12-25 15:45:02,711 - __main__ - INFO - 阶段2完成: 共生成 250 条Chosen结果
2025-12-25 15:45:02,711 - __main__ - INFO - 开始数据质量检查...
2025-12-25 15:45:02,711 - __main__ - INFO - ✅ 数据质量检查通过: 250 条chosen全部非空
2025-12-25 15:45:02,711 - __main__ - INFO - ============================================================
2025-12-25 15:45:02,711 - __main__ - INFO - 阶段3/3: 组装DPO数据并保存为JSONL格式
2025-12-25 15:45:02,712 - __main__ - INFO - ============================================================
2025-12-25 15:45:02,712 - __main__ - INFO - 预检查数据完整性...
2025-12-25 15:45:02,712 - __main__ - INFO - Chosen非空率: 250/250 (100.0%)
2025-12-25 15:45:02,712 - __main__ - INFO - Rejected非空率: 1/250 (0.4%)
2025-12-25 15:45:02,712 - __main__ - INFO - ✅ 数据完整性检查通过
2025-12-25 15:45:02,734 - __main__ - INFO - 已保存 50/250 条到JSONL
2025-12-25 15:45:02,759 - __main__ - INFO - 已保存 100/250 条到JSONL
2025-12-25 15:45:02,778 - __main__ - INFO - 已保存 150/250 条到JSONL
2025-12-25 15:45:02,796 - __main__ - INFO - 已保存 200/250 条到JSONL
2025-12-25 15:45:02,812 - __main__ - INFO - 已保存 250/250 条到JSONL
2025-12-25 15:45:02,829 - __main__ - INFO - DPO数据生成完成: output/bbh/dpo_logical_deduction_seven_objects.jsonl
2025-12-25 15:45:02,829 - __main__ - INFO - 共保存 250 条数据到JSONL格式
2025-12-25 15:45:07,344 - inference.local_inference - INFO - 清理vLLM模型...
2025-12-25 15:45:07,378 - inference.local_inference - INFO - CUDA缓存已清理
2025-12-25 15:45:08,551 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,551 - __main__ - INFO - 数据集名称: bbh
2025-12-25 15:45:08,551 - __main__ - INFO - 数据集路径: dataset/bbh/logical_deduction_three_objects.json
2025-12-25 15:45:08,551 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,551 - __main__ - INFO - 使用数据集适配层加载: bbh
2025-12-25 15:45:08,551 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,551 - __main__ - INFO - [数据集适配层] 开始加载数据集: bbh
2025-12-25 15:45:08,551 - __main__ - INFO - [数据集适配层] 文件路径: dataset/bbh/logical_deduction_three_objects.json
2025-12-25 15:45:08,551 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,552 - __main__ - INFO - [数据集适配层] 已加载 JSON 文件
2025-12-25 15:45:08,552 - __main__ - INFO - 预处理 BBH 数据集: 250 条
2025-12-25 15:45:08,552 - __main__ - INFO - [数据集适配层] 预处理完成: 250 条有效数据
2025-12-25 15:45:08,552 - __main__ - INFO - [数据集适配层] 数据格式已统一为: {'question': str, 'answer': str}
2025-12-25 15:45:08,552 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,552 - __main__ - INFO - 数据集加载成功，共 250 条数据
2025-12-25 15:45:08,552 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,552 - __main__ - INFO - Step 1: 开始生成DPO数据
2025-12-25 15:45:08,552 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,553 - __main__ - INFO - 未发现已有进度，将从头开始处理
2025-12-25 15:45:08,553 - __main__ - INFO - 共需处理 250 条数据，批次大小: 64
2025-12-25 15:45:08,553 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,553 - __main__ - INFO - 阶段1/3: vLLM分批本地推理（所有数据）
2025-12-25 15:45:08,553 - __main__ - INFO - ============================================================
2025-12-25 15:45:08,553 - __main__ - INFO - 处理批次 [1-128/250]
2025-12-25 15:45:08,553 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 15:45:08,553 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 15:45:13,110 - inference.local_inference - INFO - 使用环境变量 CUDA_VISIBLE_DEVICES: 0,1
2025-12-25 15:45:13,110 - inference.local_inference - INFO - ============================================================
2025-12-25 15:45:13,111 - inference.local_inference - INFO - 初始化vLLM本地模型...
2025-12-25 15:45:13,111 - inference.local_inference - INFO - 模型路径: /home/share/hcz/qwen2.5-14b-awq
2025-12-25 15:45:13,111 - inference.local_inference - INFO - ============================================================
2025-12-25 15:46:36,313 - inference.local_inference - INFO - vLLM模型初始化完成
2025-12-25 15:46:44,931 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 15:46:44,932 - __main__ - INFO - 批量生成差异分析: 128 条
2025-12-25 15:50:17,393 - __main__ - INFO -   → 生成Rejected原则 (128 条)...
2025-12-25 15:50:17,394 - __main__ - INFO - 批量生成原则（弱模型）: 128 条
2025-12-25 15:50:17,424 - inference.local_inference - WARNING - 跳过超长prompt [1/128]: 8614 tokens (最大允许: 1808)
2025-12-25 15:50:17,444 - inference.local_inference - WARNING - 跳过超长prompt [2/128]: 8599 tokens (最大允许: 1808)
2025-12-25 15:50:17,464 - inference.local_inference - WARNING - 跳过超长prompt [3/128]: 8612 tokens (最大允许: 1808)
2025-12-25 15:50:17,483 - inference.local_inference - WARNING - 跳过超长prompt [4/128]: 8609 tokens (最大允许: 1808)
2025-12-25 15:50:17,503 - inference.local_inference - WARNING - 跳过超长prompt [5/128]: 8685 tokens (最大允许: 1808)
2025-12-25 15:50:17,528 - inference.local_inference - WARNING - 跳过超长prompt [6/128]: 8678 tokens (最大允许: 1808)
2025-12-25 15:50:17,551 - inference.local_inference - WARNING - 跳过超长prompt [7/128]: 8678 tokens (最大允许: 1808)
2025-12-25 15:50:17,571 - inference.local_inference - WARNING - 跳过超长prompt [8/128]: 8694 tokens (最大允许: 1808)
2025-12-25 15:50:17,591 - inference.local_inference - WARNING - 跳过超长prompt [9/128]: 8666 tokens (最大允许: 1808)
2025-12-25 15:50:17,612 - inference.local_inference - WARNING - 跳过超长prompt [10/128]: 8651 tokens (最大允许: 1808)
2025-12-25 15:50:17,633 - inference.local_inference - WARNING - 跳过超长prompt [12/128]: 8664 tokens (最大允许: 1808)
2025-12-25 15:50:17,652 - inference.local_inference - WARNING - 跳过超长prompt [13/128]: 8620 tokens (最大允许: 1808)
2025-12-25 15:50:17,671 - inference.local_inference - WARNING - 跳过超长prompt [14/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:50:17,691 - inference.local_inference - WARNING - 跳过超长prompt [15/128]: 8635 tokens (最大允许: 1808)
2025-12-25 15:50:17,710 - inference.local_inference - WARNING - 跳过超长prompt [16/128]: 8619 tokens (最大允许: 1808)
2025-12-25 15:50:17,731 - inference.local_inference - WARNING - 跳过超长prompt [17/128]: 8779 tokens (最大允许: 1808)
2025-12-25 15:50:17,751 - inference.local_inference - WARNING - 跳过超长prompt [18/128]: 8762 tokens (最大允许: 1808)
2025-12-25 15:50:17,771 - inference.local_inference - WARNING - 跳过超长prompt [19/128]: 8762 tokens (最大允许: 1808)
2025-12-25 15:50:17,791 - inference.local_inference - WARNING - 跳过超长prompt [20/128]: 8765 tokens (最大允许: 1808)
2025-12-25 15:50:17,810 - inference.local_inference - WARNING - 跳过超长prompt [21/128]: 8625 tokens (最大允许: 1808)
2025-12-25 15:50:17,830 - inference.local_inference - WARNING - 跳过超长prompt [22/128]: 8623 tokens (最大允许: 1808)
2025-12-25 15:50:17,849 - inference.local_inference - WARNING - 跳过超长prompt [23/128]: 8611 tokens (最大允许: 1808)
2025-12-25 15:50:17,874 - inference.local_inference - WARNING - 跳过超长prompt [24/128]: 8622 tokens (最大允许: 1808)
2025-12-25 15:50:17,894 - inference.local_inference - WARNING - 跳过超长prompt [25/128]: 8645 tokens (最大允许: 1808)
2025-12-25 15:50:17,913 - inference.local_inference - WARNING - 跳过超长prompt [26/128]: 8682 tokens (最大允许: 1808)
2025-12-25 15:50:17,934 - inference.local_inference - WARNING - 跳过超长prompt [27/128]: 8660 tokens (最大允许: 1808)
2025-12-25 15:50:17,953 - inference.local_inference - WARNING - 跳过超长prompt [28/128]: 8644 tokens (最大允许: 1808)
2025-12-25 15:50:17,972 - inference.local_inference - WARNING - 跳过超长prompt [29/128]: 8625 tokens (最大允许: 1808)
2025-12-25 15:50:17,992 - inference.local_inference - WARNING - 跳过超长prompt [30/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:50:17,998 - inference.local_inference - WARNING - 跳过超长prompt [31/128]: 2393 tokens (最大允许: 1808)
2025-12-25 15:50:18,016 - inference.local_inference - WARNING - 跳过超长prompt [32/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:50:18,034 - inference.local_inference - WARNING - 跳过超长prompt [33/128]: 8680 tokens (最大允许: 1808)
2025-12-25 15:50:18,055 - inference.local_inference - WARNING - 跳过超长prompt [34/128]: 8684 tokens (最大允许: 1808)
2025-12-25 15:50:18,074 - inference.local_inference - WARNING - 跳过超长prompt [35/128]: 8680 tokens (最大允许: 1808)
2025-12-25 15:50:18,093 - inference.local_inference - WARNING - 跳过超长prompt [36/128]: 8683 tokens (最大允许: 1808)
2025-12-25 15:50:18,111 - inference.local_inference - WARNING - 跳过超长prompt [37/128]: 8671 tokens (最大允许: 1808)
2025-12-25 15:50:18,131 - inference.local_inference - WARNING - 跳过超长prompt [38/128]: 8676 tokens (最大允许: 1808)
2025-12-25 15:50:18,149 - inference.local_inference - WARNING - 跳过超长prompt [39/128]: 8681 tokens (最大允许: 1808)
2025-12-25 15:50:18,166 - inference.local_inference - WARNING - 跳过超长prompt [40/128]: 8672 tokens (最大允许: 1808)
2025-12-25 15:50:18,185 - inference.local_inference - WARNING - 跳过超长prompt [41/128]: 8607 tokens (最大允许: 1808)
2025-12-25 15:50:18,205 - inference.local_inference - WARNING - 跳过超长prompt [42/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:50:18,223 - inference.local_inference - WARNING - 跳过超长prompt [43/128]: 8616 tokens (最大允许: 1808)
2025-12-25 15:50:18,243 - inference.local_inference - WARNING - 跳过超长prompt [44/128]: 8608 tokens (最大允许: 1808)
2025-12-25 15:50:18,264 - inference.local_inference - WARNING - 跳过超长prompt [45/128]: 8699 tokens (最大允许: 1808)
2025-12-25 15:50:18,283 - inference.local_inference - WARNING - 跳过超长prompt [46/128]: 8714 tokens (最大允许: 1808)
2025-12-25 15:50:18,303 - inference.local_inference - WARNING - 跳过超长prompt [47/128]: 8726 tokens (最大允许: 1808)
2025-12-25 15:50:18,323 - inference.local_inference - WARNING - 跳过超长prompt [48/128]: 8711 tokens (最大允许: 1808)
2025-12-25 15:50:18,342 - inference.local_inference - WARNING - 跳过超长prompt [49/128]: 8687 tokens (最大允许: 1808)
2025-12-25 15:50:18,357 - inference.local_inference - WARNING - 跳过超长prompt [50/128]: 6845 tokens (最大允许: 1808)
2025-12-25 15:50:18,376 - inference.local_inference - WARNING - 跳过超长prompt [51/128]: 8702 tokens (最大允许: 1808)
2025-12-25 15:50:18,395 - inference.local_inference - WARNING - 跳过超长prompt [52/128]: 8703 tokens (最大允许: 1808)
2025-12-25 15:50:18,416 - inference.local_inference - WARNING - 跳过超长prompt [54/128]: 8772 tokens (最大允许: 1808)
2025-12-25 15:50:18,436 - inference.local_inference - WARNING - 跳过超长prompt [55/128]: 8776 tokens (最大允许: 1808)
2025-12-25 15:50:18,455 - inference.local_inference - WARNING - 跳过超长prompt [56/128]: 8765 tokens (最大允许: 1808)
2025-12-25 15:50:18,473 - inference.local_inference - WARNING - 跳过超长prompt [57/128]: 8614 tokens (最大允许: 1808)
2025-12-25 15:50:18,492 - inference.local_inference - WARNING - 跳过超长prompt [58/128]: 8622 tokens (最大允许: 1808)
2025-12-25 15:50:18,511 - inference.local_inference - WARNING - 跳过超长prompt [59/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:50:18,529 - inference.local_inference - WARNING - 跳过超长prompt [60/128]: 8618 tokens (最大允许: 1808)
2025-12-25 15:50:18,546 - inference.local_inference - WARNING - 跳过超长prompt [61/128]: 8646 tokens (最大允许: 1808)
2025-12-25 15:50:18,565 - inference.local_inference - WARNING - 跳过超长prompt [62/128]: 8653 tokens (最大允许: 1808)
2025-12-25 15:50:18,583 - inference.local_inference - WARNING - 跳过超长prompt [63/128]: 8645 tokens (最大允许: 1808)
2025-12-25 15:50:18,604 - inference.local_inference - WARNING - 跳过超长prompt [65/128]: 8636 tokens (最大允许: 1808)
2025-12-25 15:50:18,624 - inference.local_inference - WARNING - 跳过超长prompt [66/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:50:18,643 - inference.local_inference - WARNING - 跳过超长prompt [67/128]: 8638 tokens (最大允许: 1808)
2025-12-25 15:50:18,662 - inference.local_inference - WARNING - 跳过超长prompt [68/128]: 8639 tokens (最大允许: 1808)
2025-12-25 15:50:18,680 - inference.local_inference - WARNING - 跳过超长prompt [69/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:50:18,699 - inference.local_inference - WARNING - 跳过超长prompt [70/128]: 8637 tokens (最大允许: 1808)
2025-12-25 15:50:18,717 - inference.local_inference - WARNING - 跳过超长prompt [71/128]: 8645 tokens (最大允许: 1808)
2025-12-25 15:50:18,736 - inference.local_inference - WARNING - 跳过超长prompt [72/128]: 8633 tokens (最大允许: 1808)
2025-12-25 15:50:18,755 - inference.local_inference - WARNING - 跳过超长prompt [73/128]: 8661 tokens (最大允许: 1808)
2025-12-25 15:50:18,774 - inference.local_inference - WARNING - 跳过超长prompt [74/128]: 8641 tokens (最大允许: 1808)
2025-12-25 15:50:18,792 - inference.local_inference - WARNING - 跳过超长prompt [75/128]: 8651 tokens (最大允许: 1808)
2025-12-25 15:50:18,815 - inference.local_inference - WARNING - 跳过超长prompt [77/128]: 8720 tokens (最大允许: 1808)
2025-12-25 15:50:18,834 - inference.local_inference - WARNING - 跳过超长prompt [78/128]: 8701 tokens (最大允许: 1808)
2025-12-25 15:50:18,853 - inference.local_inference - WARNING - 跳过超长prompt [79/128]: 8698 tokens (最大允许: 1808)
2025-12-25 15:50:18,871 - inference.local_inference - WARNING - 跳过超长prompt [80/128]: 8701 tokens (最大允许: 1808)
2025-12-25 15:50:18,894 - inference.local_inference - WARNING - 跳过超长prompt [81/128]: 8624 tokens (最大允许: 1808)
2025-12-25 15:50:18,907 - inference.local_inference - WARNING - 跳过超长prompt [82/128]: 6330 tokens (最大允许: 1808)
2025-12-25 15:50:18,925 - inference.local_inference - WARNING - 跳过超长prompt [83/128]: 8630 tokens (最大允许: 1808)
2025-12-25 15:50:18,945 - inference.local_inference - WARNING - 跳过超长prompt [84/128]: 8619 tokens (最大允许: 1808)
2025-12-25 15:50:18,964 - inference.local_inference - WARNING - 跳过超长prompt [85/128]: 8555 tokens (最大允许: 1808)
2025-12-25 15:50:18,983 - inference.local_inference - WARNING - 跳过超长prompt [86/128]: 8554 tokens (最大允许: 1808)
2025-12-25 15:50:19,003 - inference.local_inference - WARNING - 跳过超长prompt [87/128]: 8568 tokens (最大允许: 1808)
2025-12-25 15:50:19,022 - inference.local_inference - WARNING - 跳过超长prompt [88/128]: 8556 tokens (最大允许: 1808)
2025-12-25 15:50:19,041 - inference.local_inference - WARNING - 跳过超长prompt [89/128]: 8768 tokens (最大允许: 1808)
2025-12-25 15:50:19,060 - inference.local_inference - WARNING - 跳过超长prompt [90/128]: 8775 tokens (最大允许: 1808)
2025-12-25 15:50:19,079 - inference.local_inference - WARNING - 跳过超长prompt [91/128]: 8759 tokens (最大允许: 1808)
2025-12-25 15:50:19,096 - inference.local_inference - WARNING - 跳过超长prompt [92/128]: 8763 tokens (最大允许: 1808)
2025-12-25 15:50:19,114 - inference.local_inference - WARNING - 跳过超长prompt [93/128]: 8741 tokens (最大允许: 1808)
2025-12-25 15:50:19,134 - inference.local_inference - WARNING - 跳过超长prompt [94/128]: 8728 tokens (最大允许: 1808)
2025-12-25 15:50:19,156 - inference.local_inference - WARNING - 跳过超长prompt [95/128]: 8745 tokens (最大允许: 1808)
2025-12-25 15:50:19,178 - inference.local_inference - WARNING - 跳过超长prompt [96/128]: 8727 tokens (最大允许: 1808)
2025-12-25 15:50:19,199 - inference.local_inference - WARNING - 跳过超长prompt [97/128]: 8631 tokens (最大允许: 1808)
2025-12-25 15:50:19,218 - inference.local_inference - WARNING - 跳过超长prompt [98/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:50:19,236 - inference.local_inference - WARNING - 跳过超长prompt [99/128]: 8639 tokens (最大允许: 1808)
2025-12-25 15:50:19,254 - inference.local_inference - WARNING - 跳过超长prompt [100/128]: 8632 tokens (最大允许: 1808)
2025-12-25 15:50:19,274 - inference.local_inference - WARNING - 跳过超长prompt [101/128]: 8815 tokens (最大允许: 1808)
2025-12-25 15:50:19,292 - inference.local_inference - WARNING - 跳过超长prompt [102/128]: 8820 tokens (最大允许: 1808)
2025-12-25 15:50:19,310 - inference.local_inference - WARNING - 跳过超长prompt [103/128]: 8841 tokens (最大允许: 1808)
2025-12-25 15:50:19,330 - inference.local_inference - WARNING - 跳过超长prompt [104/128]: 8818 tokens (最大允许: 1808)
2025-12-25 15:50:19,349 - inference.local_inference - WARNING - 跳过超长prompt [105/128]: 8629 tokens (最大允许: 1808)
2025-12-25 15:50:19,367 - inference.local_inference - WARNING - 跳过超长prompt [106/128]: 8640 tokens (最大允许: 1808)
2025-12-25 15:50:19,391 - inference.local_inference - WARNING - 跳过超长prompt [107/128]: 8631 tokens (最大允许: 1808)
2025-12-25 15:50:19,397 - inference.local_inference - WARNING - 跳过超长prompt [108/128]: 2423 tokens (最大允许: 1808)
2025-12-25 15:50:19,416 - inference.local_inference - WARNING - 跳过超长prompt [109/128]: 8630 tokens (最大允许: 1808)
2025-12-25 15:50:19,433 - inference.local_inference - WARNING - 跳过超长prompt [110/128]: 8618 tokens (最大允许: 1808)
2025-12-25 15:50:19,445 - inference.local_inference - WARNING - 跳过超长prompt [111/128]: 5889 tokens (最大允许: 1808)
2025-12-25 15:50:19,464 - inference.local_inference - WARNING - 跳过超长prompt [112/128]: 8626 tokens (最大允许: 1808)
2025-12-25 15:50:19,483 - inference.local_inference - WARNING - 跳过超长prompt [113/128]: 8589 tokens (最大允许: 1808)
2025-12-25 15:50:19,501 - inference.local_inference - WARNING - 跳过超长prompt [114/128]: 8590 tokens (最大允许: 1808)
2025-12-25 15:50:19,519 - inference.local_inference - WARNING - 跳过超长prompt [115/128]: 8596 tokens (最大允许: 1808)
2025-12-25 15:50:19,538 - inference.local_inference - WARNING - 跳过超长prompt [116/128]: 8596 tokens (最大允许: 1808)
2025-12-25 15:50:19,564 - inference.local_inference - WARNING - 跳过超长prompt [117/128]: 8682 tokens (最大允许: 1808)
2025-12-25 15:50:19,585 - inference.local_inference - WARNING - 跳过超长prompt [118/128]: 8689 tokens (最大允许: 1808)
2025-12-25 15:50:19,604 - inference.local_inference - WARNING - 跳过超长prompt [119/128]: 8690 tokens (最大允许: 1808)
2025-12-25 15:50:19,623 - inference.local_inference - WARNING - 跳过超长prompt [120/128]: 8688 tokens (最大允许: 1808)
2025-12-25 15:50:19,643 - inference.local_inference - WARNING - 跳过超长prompt [121/128]: 8743 tokens (最大允许: 1808)
2025-12-25 15:50:19,664 - inference.local_inference - WARNING - 跳过超长prompt [123/128]: 8749 tokens (最大允许: 1808)
2025-12-25 15:50:19,682 - inference.local_inference - WARNING - 跳过超长prompt [124/128]: 8744 tokens (最大允许: 1808)
2025-12-25 15:50:19,702 - inference.local_inference - WARNING - 跳过超长prompt [125/128]: 8678 tokens (最大允许: 1808)
2025-12-25 15:50:19,721 - inference.local_inference - WARNING - 跳过超长prompt [126/128]: 8675 tokens (最大允许: 1808)
2025-12-25 15:50:19,739 - inference.local_inference - WARNING - 跳过超长prompt [127/128]: 8677 tokens (最大允许: 1808)
2025-12-25 15:50:19,757 - inference.local_inference - WARNING - 跳过超长prompt [128/128]: 8682 tokens (最大允许: 1808)
2025-12-25 15:50:19,757 - inference.local_inference - WARNING - 共跳过 123/128 条超长prompts
2025-12-25 15:52:31,781 - __main__ - INFO - 批次 [3201-3328] 本地推理完成
2025-12-25 15:52:31,782 - __main__ - INFO - 处理批次 [3329-3456/99842]
2025-12-25 15:52:31,783 - __main__ - INFO -   → 生成Baseline答案 (128 条)...
2025-12-25 15:52:31,783 - __main__ - INFO - 批量生成Baseline答案: 128 条
2025-12-25 15:52:41,584 - __main__ - INFO -   → 生成差异分析 (128 条)...
2025-12-25 15:52:41,584 - __main__ - INFO - 批量生成差异分析: 128 条
