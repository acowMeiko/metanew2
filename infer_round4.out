nohup: ignoring input
2026-01-02 21:43:28,929 - __main__ - INFO - Âä†ËΩΩÊï∞ÊçÆÈõÜ: data/test/test_filter.json
2026-01-02 21:43:28,933 - __main__ - INFO - Êï∞ÊçÆÈõÜÂä†ËΩΩÊàêÂäüÔºàJSONÊ†ºÂºèÔºâÔºåÂÖ± 400 Êù°Êï∞ÊçÆ
2026-01-02 21:43:28,933 - __main__ - INFO - Êï∞ÊçÆÂ≠óÊÆµ: ['problem', 'answer', 'solution', 'grading_log', 'difficulty', 'tags']
2026-01-02 21:43:28,934 - __main__ - INFO - ============================================================
2026-01-02 21:43:28,934 - __main__ - INFO - Step 3: ÂºÄÂßãÊé®ÁêÜÔºàÊâπÂ§ÑÁêÜÊ®°ÂºèÔºâ
2026-01-02 21:43:28,934 - __main__ - INFO - ============================================================
2026-01-02 21:43:28,936 - __main__ - INFO - MemoryManager ÂàùÂßãÂåñÂÆåÊàê
2026-01-02 21:43:28,937 - __main__ - INFO - ÊâπÂ§ÑÁêÜÂ§ßÂ∞è: 256
2026-01-02 21:43:28,937 - __main__ - INFO - ============================================================
2026-01-02 21:43:28,937 - __main__ - INFO - Ê≠•È™§ 1/3: ÊâπÈáèÁîüÊàê‰ªªÂä°ÊèèËø∞
2026-01-02 21:43:28,937 - __main__ - INFO - ============================================================
2026-01-02 21:43:28,937 - __main__ - INFO - ÊúâÊïàÊï∞ÊçÆ: 400 Êù°
2026-01-02 21:43:28,937 - __main__ - INFO - Â∞ÜÂàÜ 2 ÊâπÂ§ÑÁêÜÔºàÊØèÊâπ 256 Êù°Ôºâ
ÁîüÊàê‰ªªÂä°ÊèèËø∞:   0%|          | 0/2 [00:00<?, ?it/s]INFO 01-02 21:43:32 [__init__.py:239] Automatically detected platform cuda.
2026-01-02 21:43:33,646 - inference.local_inference - INFO - ‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáè CUDA_VISIBLE_DEVICES: 0,1,2,3
2026-01-02 21:43:33,646 - inference.local_inference - INFO - ============================================================
2026-01-02 21:43:33,646 - inference.local_inference - INFO - ÂàùÂßãÂåñvLLMÊú¨Âú∞Ê®°Âûã...
2026-01-02 21:43:33,646 - inference.local_inference - INFO - Ê®°ÂûãË∑ØÂæÑ: /home/share/hcz/qwen2.5-14b-awq
2026-01-02 21:43:33,646 - inference.local_inference - INFO - ============================================================
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 01-02 21:43:40 [config.py:585] This model supports multiple tasks: {'classify', 'generate', 'reward', 'embed', 'score'}. Defaulting to 'generate'.
INFO 01-02 21:43:40 [config.py:1519] Defaulting to use mp for distributed inference
INFO 01-02 21:43:40 [config.py:1697] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 01-02 21:43:42 [core.py:54] Initializing a V1 LLM engine (v0.8.2) with config: model='/home/models/qwen_dpo4_lora', speculative_config=None, tokenizer='/home/models/qwen_dpo4_lora', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/home/models/qwen_dpo4_lora, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 01-02 21:43:42 [multiproc_worker_utils.py:306] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-02 21:43:42 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 10485760, 10, 'psm_472b7169'), local_subscribe_addr='ipc:///tmp/b55e18c3-f587-4619-8259-772a04e9e73f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 01-02 21:43:42 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fea6253ca10>
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:42 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0bf5a8f2'), local_subscribe_addr='ipc:///tmp/377efd0b-5663-491f-9d20-33f824d1d4c4', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 01-02 21:43:43 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fea6093b850>
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:43 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_08f15e07'), local_subscribe_addr='ipc:///tmp/714e966c-a68b-49fa-b83b-4b450f1c8d5f', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 01-02 21:43:43 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fea6095c3d0>
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:43 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_500b0f65'), local_subscribe_addr='ipc:///tmp/c6e75af1-423f-47d1-8942-60909b3a8b8e', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 01-02 21:43:44 [utils.py:2321] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fea6095c810>
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:44 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c1e0cd8c'), local_subscribe_addr='ipc:///tmp/d8e69e59-7bf4-47e7-8f9f-8ef2ab93fd1d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:46 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:46 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:46 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:46 [utils.py:931] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:46 [pynccl.py:69] vLLM is using nccl==2.21.5
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:48 [custom_all_reduce_utils.py:244] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:48 [shm_broadcast.py:259] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_b6f9e11c'), local_subscribe_addr='ipc:///tmp/41787817-21a3-4030-82a0-5ed889d402be', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:48 [parallel_state.py:954] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:48 [parallel_state.py:954] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:48 [parallel_state.py:954] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:48 [parallel_state.py:954] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:48 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:48 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:48 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:48 [cuda.py:220] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:48 [gpu_model_runner.py:1174] Starting to load model /home/models/qwen_dpo4_lora...
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:48 [gpu_model_runner.py:1174] Starting to load model /home/models/qwen_dpo4_lora...
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:48 [gpu_model_runner.py:1174] Starting to load model /home/models/qwen_dpo4_lora...
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:48 [gpu_model_runner.py:1174] Starting to load model /home/models/qwen_dpo4_lora...
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m WARNING 01-02 21:43:49 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m WARNING 01-02 21:43:49 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m WARNING 01-02 21:43:49 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m WARNING 01-02 21:43:49 [topk_topp_sampler.py:63] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m 
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/6 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m [A
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m Loading safetensors checkpoint shards:  17% Completed | 1/6 [00:00<00:01,  2.92it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m [A
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m Loading safetensors checkpoint shards:  33% Completed | 2/6 [00:00<00:01,  2.48it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m [A
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m Loading safetensors checkpoint shards:  50% Completed | 3/6 [00:01<00:01,  2.36it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m [A
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m Loading safetensors checkpoint shards:  67% Completed | 4/6 [00:01<00:00,  2.34it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m [A
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m Loading safetensors checkpoint shards:  83% Completed | 5/6 [00:02<00:00,  2.35it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m [A[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:51 [loader.py:447] Loading weights took 2.54 seconds
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:51 [loader.py:447] Loading weights took 2.56 seconds
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:51 [loader.py:447] Loading weights took 2.55 seconds

[1;36m(VllmWorker rank=0 pid=1642519)[0;0m Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:02<00:00,  2.49it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m [ALoading safetensors checkpoint shards: 100% Completed | 6/6 [00:02<00:00,  2.45it/s]
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m 
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:51 [loader.py:447] Loading weights took 2.49 seconds
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:43:51 [gpu_model_runner.py:1186] Model loading took 6.9460 GB and 3.461457 seconds
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:43:51 [gpu_model_runner.py:1186] Model loading took 6.9460 GB and 3.489642 seconds
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:43:52 [gpu_model_runner.py:1186] Model loading took 6.9460 GB and 3.489513 seconds
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:43:52 [gpu_model_runner.py:1186] Model loading took 6.9460 GB and 3.534415 seconds
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:44:02 [backends.py:415] Using cache directory: /root/.cache/vllm/torch_compile_cache/51c051114c/rank_3_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:44:02 [backends.py:425] Dynamo bytecode transform time: 10.11 s
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:44:02 [backends.py:415] Using cache directory: /root/.cache/vllm/torch_compile_cache/51c051114c/rank_1_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:44:02 [backends.py:425] Dynamo bytecode transform time: 10.28 s
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:44:02 [backends.py:415] Using cache directory: /root/.cache/vllm/torch_compile_cache/51c051114c/rank_0_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:44:02 [backends.py:425] Dynamo bytecode transform time: 10.28 s
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:44:02 [backends.py:415] Using cache directory: /root/.cache/vllm/torch_compile_cache/51c051114c/rank_2_0 for vLLM's torch.compile
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:44:02 [backends.py:425] Dynamo bytecode transform time: 10.37 s
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:44:02 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:44:03 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:44:03 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:44:03 [backends.py:115] Directly load the compiled graph for shape None from the cache
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:44:13 [monitor.py:33] torch.compile takes 10.11 s in total
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:44:13 [monitor.py:33] torch.compile takes 10.28 s in total
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:44:13 [monitor.py:33] torch.compile takes 10.37 s in total
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:44:13 [monitor.py:33] torch.compile takes 10.28 s in total
INFO 01-02 21:44:16 [kv_cache_utils.py:566] GPU KV cache size: 949,600 tokens
INFO 01-02 21:44:16 [kv_cache_utils.py:569] Maximum concurrency for 32,768 tokens per request: 28.98x
INFO 01-02 21:44:16 [kv_cache_utils.py:566] GPU KV cache size: 1,247,168 tokens
INFO 01-02 21:44:16 [kv_cache_utils.py:569] Maximum concurrency for 32,768 tokens per request: 38.06x
INFO 01-02 21:44:16 [kv_cache_utils.py:566] GPU KV cache size: 1,247,168 tokens
INFO 01-02 21:44:16 [kv_cache_utils.py:569] Maximum concurrency for 32,768 tokens per request: 38.06x
INFO 01-02 21:44:16 [kv_cache_utils.py:566] GPU KV cache size: 1,251,264 tokens
INFO 01-02 21:44:16 [kv_cache_utils.py:569] Maximum concurrency for 32,768 tokens per request: 38.19x
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:44:41 [custom_all_reduce.py:229] Registering 6499 cuda graph addresses
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:44:41 [custom_all_reduce.py:229] Registering 6499 cuda graph addresses
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:44:41 [custom_all_reduce.py:229] Registering 6499 cuda graph addresses
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:44:41 [custom_all_reduce.py:229] Registering 6499 cuda graph addresses
[1;36m(VllmWorker rank=3 pid=1642559)[0;0m INFO 01-02 21:44:41 [gpu_model_runner.py:1534] Graph capturing finished in 25 secs, took 0.71 GiB
[1;36m(VllmWorker rank=1 pid=1642531)[0;0m INFO 01-02 21:44:41 [gpu_model_runner.py:1534] Graph capturing finished in 25 secs, took 0.71 GiB
[1;36m(VllmWorker rank=2 pid=1642544)[0;0m INFO 01-02 21:44:41 [gpu_model_runner.py:1534] Graph capturing finished in 25 secs, took 0.71 GiB
[1;36m(VllmWorker rank=0 pid=1642519)[0;0m INFO 01-02 21:44:41 [gpu_model_runner.py:1534] Graph capturing finished in 25 secs, took 0.71 GiB
INFO 01-02 21:44:41 [core.py:151] init engine (profile, create kv cache, warmup model) took 49.44 seconds
2026-01-02 21:44:41,506 - inference.local_inference - INFO - vLLMÊ®°ÂûãÂàùÂßãÂåñÂÆåÊàê
ÁîüÊàê‰ªªÂä°ÊèèËø∞:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [02:04<02:04, 124.13s/it]ÁîüÊàê‰ªªÂä°ÊèèËø∞: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [02:43<00:00, 74.06s/it] ÁîüÊàê‰ªªÂä°ÊèèËø∞: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [02:43<00:00, 81.57s/it]
2026-01-02 21:46:12,077 - __main__ - INFO - ‰ªªÂä°ÊèèËø∞ÁîüÊàêÂÆåÊàê: 400 Êù°
2026-01-02 21:46:12,091 - __main__ - INFO - ‰ªªÂä°ÊèèËø∞Â∑≤‰øùÂ≠òÂà∞: /home/metanew2/output/task_descriptions.json
2026-01-02 21:46:12,091 - __main__ - INFO - ============================================================
2026-01-02 21:46:12,091 - __main__ - INFO - Ê≠•È™§ 2/3: Ëß£Êûê‰ªªÂä°ÊèèËø∞Âπ∂Ê£ÄÁ¥¢ÂéüÂàô
2026-01-02 21:46:12,091 - __main__ - INFO - ============================================================
Ê£ÄÁ¥¢ÂéüÂàô:   0%|          | 0/400 [00:00<?, ?it/s]Ê£ÄÁ¥¢ÂéüÂàô:   0%|          | 1/400 [00:15<1:45:12, 15.82s/it]Ê£ÄÁ¥¢ÂéüÂàô:   0%|          | 2/400 [00:45<2:39:57, 24.11s/it]Ê£ÄÁ¥¢ÂéüÂàô:   1%|          | 3/400 [00:49<1:38:51, 14.94s/it]Ê£ÄÁ¥¢ÂéüÂàô:   1%|          | 4/400 [01:20<2:19:00, 21.06s/it]Ê£ÄÁ¥¢ÂéüÂàô:   1%|‚ñè         | 5/400 [01:50<2:39:30, 24.23s/it]Ê£ÄÁ¥¢ÂéüÂàô:   2%|‚ñè         | 6/400 [02:20<2:52:25, 26.26s/it]Ê£ÄÁ¥¢ÂéüÂàô:   2%|‚ñè         | 7/400 [02:50<3:00:11, 27.51s/it]Ê£ÄÁ¥¢ÂéüÂàô:   2%|‚ñè         | 8/400 [02:54<2:11:06, 20.07s/it]Ê£ÄÁ¥¢ÂéüÂàô:   2%|‚ñè         | 9/400 [03:00<1:42:07, 15.67s/it]Ê£ÄÁ¥¢ÂéüÂàô:   2%|‚ñé         | 10/400 [03:31<2:13:05, 20.48s/it]Ê£ÄÁ¥¢ÂéüÂàô:   3%|‚ñé         | 11/400 [04:02<2:33:55, 23.74s/it]Ê£ÄÁ¥¢ÂéüÂàô:   3%|‚ñé         | 12/400 [04:06<1:54:41, 17.74s/it]Ê£ÄÁ¥¢ÂéüÂàô:   3%|‚ñé         | 13/400 [04:36<2:17:47, 21.36s/it]2026-01-02 21:50:48,663 - __main__ - WARNING - Á¨¨ 14 È°π: Êú™ÊâæÂà∞JSONÊ†ºÂºèÔºåÂéüÂßãÂìçÂ∫î: To solve the problem, we need to follow the structured analysis steps:

1. **Analyze the domain of the question:**
   - The question is related to number theory and sequences, specifically the Fibonac...
Ê£ÄÁ¥¢ÂéüÂàô:   4%|‚ñç         | 15/400 [04:41<1:20:51, 12.60s/it]Ê£ÄÁ¥¢ÂéüÂàô:   4%|‚ñç         | 16/400 [04:54<1:20:49, 12.63s/it]Ê£ÄÁ¥¢ÂéüÂàô:   4%|‚ñç         | 17/400 [05:23<1:48:55, 17.06s/it]Ê£ÄÁ¥¢ÂéüÂàô:   4%|‚ñç         | 18/400 [05:54<2:13:01, 20.89s/it]Ê£ÄÁ¥¢ÂéüÂàô:   5%|‚ñç         | 19/400 [06:25<2:29:55, 23.61s/it]Ê£ÄÁ¥¢ÂéüÂàô:   5%|‚ñå         | 20/400 [06:55<2:41:41, 25.53s/it]2026-01-02 21:53:07,891 - __main__ - WARNING - Á¨¨ 21 È°π: JSONËß£ÊûêÂ§±Ë¥•
2026-01-02 21:53:07,892 - __main__ - WARNING -   ÂÄôÈÄâJSONÊï∞Èáè: 3
2026-01-02 21:53:07,892 - __main__ - WARNING -   ÊúÄÂêé‰∏Ä‰∏™ÂÄôÈÄâ: {{
  "taskDescription": {{
    "description": "Determine the sum of the roots of a specified equation involving polynomial and logarithmic terms."
  }...
Ê£ÄÁ¥¢ÂéüÂàô:   6%|‚ñå         | 22/400 [07:27<2:13:23, 21.17s/it]Ê£ÄÁ¥¢ÂéüÂàô:   6%|‚ñå         | 23/400 [07:31<1:47:19, 17.08s/it]Ê£ÄÁ¥¢ÂéüÂàô:   6%|‚ñå         | 24/400 [08:01<2:07:48, 20.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:   6%|‚ñã         | 25/400 [08:05<1:40:10, 16.03s/it]Ê£ÄÁ¥¢ÂéüÂàô:   6%|‚ñã         | 26/400 [08:10<1:19:18, 12.72s/it]Ê£ÄÁ¥¢ÂéüÂàô:   7%|‚ñã         | 27/400 [08:40<1:50:11, 17.73s/it]2026-01-02 21:54:52,481 - __main__ - WARNING - Á¨¨ 28 È°π: Êú™ÊâæÂà∞JSONÊ†ºÂºèÔºåÂéüÂßãÂìçÂ∫î: To solve the problem, we need to follow the structured analysis steps:

1. **Analyze the domain of the question:**
   - The question is related to geometry and trigonometry, specifically dealing with ...
Ê£ÄÁ¥¢ÂéüÂàô:   8%|‚ñä         | 30/400 [09:11<1:24:29, 13.70s/it]Ê£ÄÁ¥¢ÂéüÂàô:   8%|‚ñä         | 31/400 [09:33<1:34:23, 15.35s/it]Ê£ÄÁ¥¢ÂéüÂàô:   8%|‚ñä         | 32/400 [09:36<1:16:37, 12.49s/it]Ê£ÄÁ¥¢ÂéüÂàô:   8%|‚ñä         | 33/400 [10:05<1:42:10, 16.70s/it]Ê£ÄÁ¥¢ÂéüÂàô:   8%|‚ñä         | 34/400 [10:17<1:34:49, 15.54s/it]Ê£ÄÁ¥¢ÂéüÂàô:   9%|‚ñâ         | 35/400 [10:21<1:15:33, 12.42s/it]Ê£ÄÁ¥¢ÂéüÂàô:   9%|‚ñâ         | 36/400 [10:25<1:01:05, 10.07s/it]Ê£ÄÁ¥¢ÂéüÂàô:  10%|‚ñâ         | 39/400 [10:55<59:42,  9.92s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  10%|‚ñà         | 40/400 [10:59<52:21,  8.73s/it]Ê£ÄÁ¥¢ÂéüÂàô:  10%|‚ñà         | 41/400 [11:30<1:22:43, 13.83s/it]Ê£ÄÁ¥¢ÂéüÂàô:  11%|‚ñà         | 43/400 [11:55<1:19:05, 13.29s/it]Ê£ÄÁ¥¢ÂéüÂàô:  11%|‚ñà         | 44/400 [12:24<1:39:54, 16.84s/it]Ê£ÄÁ¥¢ÂéüÂàô:  12%|‚ñà‚ñè        | 46/400 [12:54<1:34:43, 16.06s/it]Ê£ÄÁ¥¢ÂéüÂàô:  12%|‚ñà‚ñè        | 47/400 [12:58<1:19:24, 13.50s/it]Ê£ÄÁ¥¢ÂéüÂàô:  12%|‚ñà‚ñè        | 48/400 [13:02<1:05:58, 11.25s/it]Ê£ÄÁ¥¢ÂéüÂàô:  12%|‚ñà‚ñè        | 49/400 [13:06<55:18,  9.45s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  12%|‚ñà‚ñé        | 50/400 [13:11<47:04,  8.07s/it]Ê£ÄÁ¥¢ÂéüÂàô:  13%|‚ñà‚ñé        | 51/400 [13:41<1:22:42, 14.22s/it]Ê£ÄÁ¥¢ÂéüÂàô:  13%|‚ñà‚ñé        | 52/400 [13:45<1:05:42, 11.33s/it]Ê£ÄÁ¥¢ÂéüÂàô:  13%|‚ñà‚ñé        | 53/400 [14:15<1:36:14, 16.64s/it]Ê£ÄÁ¥¢ÂéüÂàô:  14%|‚ñà‚ñé        | 54/400 [14:19<1:15:08, 13.03s/it]Ê£ÄÁ¥¢ÂéüÂàô:  14%|‚ñà‚ñç        | 55/400 [14:20<54:49,  9.53s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  14%|‚ñà‚ñç        | 56/400 [14:29<53:59,  9.42s/it]Ê£ÄÁ¥¢ÂéüÂàô:  14%|‚ñà‚ñç        | 57/400 [14:34<44:57,  7.86s/it]Ê£ÄÁ¥¢ÂéüÂàô:  15%|‚ñà‚ñç        | 59/400 [15:04<1:03:22, 11.15s/it]Ê£ÄÁ¥¢ÂéüÂàô:  15%|‚ñà‚ñå        | 60/400 [15:35<1:30:52, 16.04s/it]Ê£ÄÁ¥¢ÂéüÂàô:  15%|‚ñà‚ñå        | 61/400 [16:04<1:50:45, 19.60s/it]Ê£ÄÁ¥¢ÂéüÂàô:  16%|‚ñà‚ñå        | 62/400 [16:37<2:10:17, 23.13s/it]Ê£ÄÁ¥¢ÂéüÂàô:  16%|‚ñà‚ñå        | 64/400 [17:07<1:49:27, 19.55s/it]Ê£ÄÁ¥¢ÂéüÂàô:  16%|‚ñà‚ñã        | 66/400 [17:39<1:41:25, 18.22s/it]Ê£ÄÁ¥¢ÂéüÂàô:  17%|‚ñà‚ñã        | 68/400 [18:11<1:36:12, 17.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:  17%|‚ñà‚ñã        | 69/400 [18:41<1:50:54, 20.11s/it]Ê£ÄÁ¥¢ÂéüÂàô:  18%|‚ñà‚ñä        | 70/400 [19:12<2:03:07, 22.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:  18%|‚ñà‚ñä        | 71/400 [19:43<2:14:41, 24.56s/it]Ê£ÄÁ¥¢ÂéüÂàô:  18%|‚ñà‚ñä        | 72/400 [20:14<2:22:25, 26.05s/it]Ê£ÄÁ¥¢ÂéüÂàô:  18%|‚ñà‚ñä        | 73/400 [20:25<2:00:53, 22.18s/it]Ê£ÄÁ¥¢ÂéüÂàô:  18%|‚ñà‚ñä        | 74/400 [20:55<2:12:08, 24.32s/it]Ê£ÄÁ¥¢ÂéüÂàô:  19%|‚ñà‚ñâ        | 75/400 [21:25<2:20:16, 25.90s/it]Ê£ÄÁ¥¢ÂéüÂàô:  20%|‚ñà‚ñâ        | 78/400 [21:56<1:33:31, 17.43s/it]Ê£ÄÁ¥¢ÂéüÂàô:  20%|‚ñà‚ñâ        | 79/400 [22:28<1:49:32, 20.48s/it]Ê£ÄÁ¥¢ÂéüÂàô:  20%|‚ñà‚ñà        | 81/400 [22:59<1:38:08, 18.46s/it]Ê£ÄÁ¥¢ÂéüÂàô:  20%|‚ñà‚ñà        | 82/400 [23:29<1:51:41, 21.07s/it]Ê£ÄÁ¥¢ÂéüÂàô:  21%|‚ñà‚ñà        | 83/400 [24:00<2:02:37, 23.21s/it]Ê£ÄÁ¥¢ÂéüÂàô:  21%|‚ñà‚ñà        | 84/400 [24:29<2:10:39, 24.81s/it]Ê£ÄÁ¥¢ÂéüÂàô:  21%|‚ñà‚ñà‚ñè       | 85/400 [25:00<2:17:35, 26.21s/it]Ê£ÄÁ¥¢ÂéüÂàô:  22%|‚ñà‚ñà‚ñè       | 89/400 [25:04<57:35, 11.11s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  22%|‚ñà‚ñà‚ñé       | 90/400 [25:33<1:14:15, 14.37s/it]Ê£ÄÁ¥¢ÂéüÂàô:  23%|‚ñà‚ñà‚ñé       | 92/400 [26:04<1:15:25, 14.69s/it]Ê£ÄÁ¥¢ÂéüÂàô:  23%|‚ñà‚ñà‚ñé       | 93/400 [26:08<1:04:37, 12.63s/it]Ê£ÄÁ¥¢ÂéüÂàô:  24%|‚ñà‚ñà‚ñç       | 95/400 [26:12<45:03,  8.86s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  24%|‚ñà‚ñà‚ñç       | 96/400 [26:16<39:55,  7.88s/it]Ê£ÄÁ¥¢ÂéüÂàô:  24%|‚ñà‚ñà‚ñç       | 98/400 [26:24<32:45,  6.51s/it]Ê£ÄÁ¥¢ÂéüÂàô:  25%|‚ñà‚ñà‚ñç       | 99/400 [26:55<58:08, 11.59s/it]Ê£ÄÁ¥¢ÂéüÂàô:  25%|‚ñà‚ñà‚ñå       | 100/400 [26:59<49:17,  9.86s/it]Ê£ÄÁ¥¢ÂéüÂàô:  25%|‚ñà‚ñà‚ñå       | 101/400 [27:30<1:15:17, 15.11s/it]Ê£ÄÁ¥¢ÂéüÂàô:  26%|‚ñà‚ñà‚ñå       | 103/400 [28:01<1:14:59, 15.15s/it]Ê£ÄÁ¥¢ÂéüÂàô:  26%|‚ñà‚ñà‚ñå       | 104/400 [28:31<1:31:15, 18.50s/it]Ê£ÄÁ¥¢ÂéüÂàô:  26%|‚ñà‚ñà‚ñã       | 105/400 [29:00<1:44:06, 21.18s/it]Ê£ÄÁ¥¢ÂéüÂàô:  26%|‚ñà‚ñà‚ñã       | 106/400 [29:30<1:54:35, 23.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:  27%|‚ñà‚ñà‚ñã       | 107/400 [30:00<2:03:32, 25.30s/it]Ê£ÄÁ¥¢ÂéüÂàô:  27%|‚ñà‚ñà‚ñã       | 108/400 [30:31<2:09:53, 26.69s/it]Ê£ÄÁ¥¢ÂéüÂàô:  27%|‚ñà‚ñà‚ñã       | 109/400 [30:43<1:50:00, 22.68s/it]Ê£ÄÁ¥¢ÂéüÂàô:  28%|‚ñà‚ñà‚ñä       | 111/400 [30:46<1:03:08, 13.11s/it]Ê£ÄÁ¥¢ÂéüÂàô:  28%|‚ñà‚ñà‚ñä       | 112/400 [31:16<1:22:15, 17.14s/it]Ê£ÄÁ¥¢ÂéüÂàô:  28%|‚ñà‚ñà‚ñä       | 113/400 [31:27<1:15:10, 15.72s/it]Ê£ÄÁ¥¢ÂéüÂàô:  29%|‚ñà‚ñà‚ñâ       | 115/400 [31:57<1:12:38, 15.29s/it]Ê£ÄÁ¥¢ÂéüÂàô:  29%|‚ñà‚ñà‚ñâ       | 116/400 [32:33<1:35:50, 20.25s/it]Ê£ÄÁ¥¢ÂéüÂàô:  29%|‚ñà‚ñà‚ñâ       | 117/400 [33:04<1:47:27, 22.78s/it]Ê£ÄÁ¥¢ÂéüÂàô:  30%|‚ñà‚ñà‚ñâ       | 119/400 [33:34<1:31:33, 19.55s/it]Ê£ÄÁ¥¢ÂéüÂàô:  30%|‚ñà‚ñà‚ñà       | 120/400 [34:03<1:42:07, 21.88s/it]Ê£ÄÁ¥¢ÂéüÂàô:  30%|‚ñà‚ñà‚ñà       | 121/400 [34:33<1:50:21, 23.73s/it]Ê£ÄÁ¥¢ÂéüÂàô:  30%|‚ñà‚ñà‚ñà       | 122/400 [35:04<1:58:51, 25.65s/it]Ê£ÄÁ¥¢ÂéüÂàô:  31%|‚ñà‚ñà‚ñà       | 123/400 [35:34<2:03:57, 26.85s/it]Ê£ÄÁ¥¢ÂéüÂàô:  31%|‚ñà‚ñà‚ñà       | 124/400 [35:38<1:34:09, 20.47s/it]Ê£ÄÁ¥¢ÂéüÂàô:  32%|‚ñà‚ñà‚ñà‚ñè      | 127/400 [36:08<1:07:23, 14.81s/it]Ê£ÄÁ¥¢ÂéüÂàô:  32%|‚ñà‚ñà‚ñà‚ñè      | 129/400 [36:39<1:07:56, 15.04s/it]Ê£ÄÁ¥¢ÂéüÂàô:  33%|‚ñà‚ñà‚ñà‚ñé      | 131/400 [36:42<47:30, 10.59s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  33%|‚ñà‚ñà‚ñà‚ñé      | 133/400 [37:12<53:17, 11.98s/it]Ê£ÄÁ¥¢ÂéüÂàô:  34%|‚ñà‚ñà‚ñà‚ñé      | 134/400 [37:42<1:07:56, 15.33s/it]Ê£ÄÁ¥¢ÂéüÂàô:  34%|‚ñà‚ñà‚ñà‚ñç      | 137/400 [37:46<40:05,  9.15s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  34%|‚ñà‚ñà‚ñà‚ñç      | 138/400 [38:20<58:59, 13.51s/it]Ê£ÄÁ¥¢ÂéüÂàô:  35%|‚ñà‚ñà‚ñà‚ñç      | 139/400 [38:25<50:40, 11.65s/it]Ê£ÄÁ¥¢ÂéüÂàô:  35%|‚ñà‚ñà‚ñà‚ñå      | 140/400 [38:56<1:09:54, 16.13s/it]Ê£ÄÁ¥¢ÂéüÂàô:  36%|‚ñà‚ñà‚ñà‚ñã      | 145/400 [39:01<28:40,  6.75s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  36%|‚ñà‚ñà‚ñà‚ñã      | 146/400 [39:05<26:55,  6.36s/it]Ê£ÄÁ¥¢ÂéüÂàô:  37%|‚ñà‚ñà‚ñà‚ñã      | 147/400 [39:09<25:23,  6.02s/it]Ê£ÄÁ¥¢ÂéüÂàô:  37%|‚ñà‚ñà‚ñà‚ñã      | 149/400 [39:13<19:34,  4.68s/it]Ê£ÄÁ¥¢ÂéüÂàô:  38%|‚ñà‚ñà‚ñà‚ñä      | 150/400 [39:35<33:04,  7.94s/it]Ê£ÄÁ¥¢ÂéüÂàô:  38%|‚ñà‚ñà‚ñà‚ñä      | 151/400 [39:39<29:25,  7.09s/it]Ê£ÄÁ¥¢ÂéüÂàô:  38%|‚ñà‚ñà‚ñà‚ñä      | 152/400 [39:43<26:18,  6.36s/it]Ê£ÄÁ¥¢ÂéüÂàô:  39%|‚ñà‚ñà‚ñà‚ñâ      | 155/400 [39:47<15:43,  3.85s/it]Ê£ÄÁ¥¢ÂéüÂàô:  39%|‚ñà‚ñà‚ñà‚ñâ      | 157/400 [39:53<14:46,  3.65s/it]Ê£ÄÁ¥¢ÂéüÂàô:  40%|‚ñà‚ñà‚ñà‚ñâ      | 158/400 [40:12<26:26,  6.56s/it]Ê£ÄÁ¥¢ÂéüÂàô:  40%|‚ñà‚ñà‚ñà‚ñâ      | 159/400 [40:17<24:16,  6.04s/it]Ê£ÄÁ¥¢ÂéüÂàô:  40%|‚ñà‚ñà‚ñà‚ñà      | 160/400 [40:47<46:25, 11.61s/it]Ê£ÄÁ¥¢ÂéüÂàô:  41%|‚ñà‚ñà‚ñà‚ñà      | 163/400 [40:51<26:07,  6.61s/it]Ê£ÄÁ¥¢ÂéüÂàô:  41%|‚ñà‚ñà‚ñà‚ñà      | 164/400 [41:22<44:12, 11.24s/it]Ê£ÄÁ¥¢ÂéüÂàô:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 165/400 [41:34<44:54, 11.47s/it]Ê£ÄÁ¥¢ÂéüÂàô:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 166/400 [42:05<1:01:58, 15.89s/it]Ê£ÄÁ¥¢ÂéüÂàô:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 167/400 [42:16<57:01, 14.69s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 168/400 [42:20<45:54, 11.87s/it]Ê£ÄÁ¥¢ÂéüÂàô:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 169/400 [42:24<37:29,  9.74s/it]Ê£ÄÁ¥¢ÂéüÂàô:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 170/400 [42:55<1:00:10, 15.70s/it]Ê£ÄÁ¥¢ÂéüÂàô:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 171/400 [42:59<47:07, 12.35s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 172/400 [43:29<1:07:01, 17.64s/it]Ê£ÄÁ¥¢ÂéüÂàô:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 173/400 [44:04<1:25:21, 22.56s/it]Ê£ÄÁ¥¢ÂéüÂàô:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 174/400 [44:34<1:33:58, 24.95s/it]Ê£ÄÁ¥¢ÂéüÂàô:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 175/400 [45:05<1:39:22, 26.50s/it]Ê£ÄÁ¥¢ÂéüÂàô:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 176/400 [45:34<1:42:15, 27.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 177/400 [45:36<1:13:41, 19.83s/it]Ê£ÄÁ¥¢ÂéüÂàô:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 178/400 [46:07<1:25:32, 23.12s/it]Ê£ÄÁ¥¢ÂéüÂàô:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 179/400 [46:38<1:33:52, 25.49s/it]Ê£ÄÁ¥¢ÂéüÂàô:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 180/400 [47:08<1:38:18, 26.81s/it]Ê£ÄÁ¥¢ÂéüÂàô:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 181/400 [47:30<1:33:10, 25.53s/it]Ê£ÄÁ¥¢ÂéüÂàô:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 182/400 [47:34<1:09:13, 19.05s/it]Ê£ÄÁ¥¢ÂéüÂàô:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 183/400 [47:39<52:53, 14.63s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 185/400 [48:00<46:08, 12.88s/it]Ê£ÄÁ¥¢ÂéüÂàô:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 186/400 [48:30<1:00:44, 17.03s/it]Ê£ÄÁ¥¢ÂéüÂàô:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 187/400 [48:34<48:20, 13.62s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 188/400 [48:38<38:50, 10.99s/it]Ê£ÄÁ¥¢ÂéüÂàô:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 189/400 [49:12<1:01:10, 17.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 190/400 [49:39<1:10:35, 20.17s/it]Ê£ÄÁ¥¢ÂéüÂàô:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 191/400 [50:09<1:20:01, 22.97s/it]Ê£ÄÁ¥¢ÂéüÂàô:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 192/400 [50:39<1:26:43, 25.02s/it]Ê£ÄÁ¥¢ÂéüÂàô:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 195/400 [51:09<57:23, 16.80s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 196/400 [51:40<1:06:55, 19.68s/it]Ê£ÄÁ¥¢ÂéüÂàô:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 197/400 [52:10<1:14:33, 22.04s/it]Ê£ÄÁ¥¢ÂéüÂàô:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 198/400 [52:40<1:21:05, 24.08s/it]Ê£ÄÁ¥¢ÂéüÂàô:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 200/400 [52:43<48:41, 14.61s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 201/400 [53:14<1:01:22, 18.50s/it]Ê£ÄÁ¥¢ÂéüÂàô:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 202/400 [53:35<1:03:06, 19.12s/it]Ê£ÄÁ¥¢ÂéüÂàô:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 204/400 [53:39<39:24, 12.06s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 207/400 [54:10<35:56, 11.17s/it]Ê£ÄÁ¥¢ÂéüÂàô:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 208/400 [54:32<42:10, 13.18s/it]Ê£ÄÁ¥¢ÂéüÂàô:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 209/400 [54:35<34:59, 10.99s/it]Ê£ÄÁ¥¢ÂéüÂàô:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 210/400 [54:39<29:44,  9.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 212/400 [55:11<37:42, 12.03s/it]Ê£ÄÁ¥¢ÂéüÂàô:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 213/400 [55:41<49:47, 15.98s/it]Ê£ÄÁ¥¢ÂéüÂàô:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 216/400 [56:16<42:51, 13.98s/it]Ê£ÄÁ¥¢ÂéüÂàô:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 217/400 [56:47<52:06, 17.09s/it]Ê£ÄÁ¥¢ÂéüÂàô:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 218/400 [57:18<1:01:07, 20.15s/it]Ê£ÄÁ¥¢ÂéüÂàô:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 221/400 [57:50<46:16, 15.51s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 222/400 [57:54<39:42, 13.39s/it]Ê£ÄÁ¥¢ÂéüÂàô:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 223/400 [58:05<38:27, 13.04s/it]Ê£ÄÁ¥¢ÂéüÂàô:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 224/400 [58:09<32:10, 10.97s/it]Ê£ÄÁ¥¢ÂéüÂàô:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 225/400 [58:34<41:32, 14.24s/it]Ê£ÄÁ¥¢ÂéüÂàô:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 226/400 [58:56<47:07, 16.25s/it]Ê£ÄÁ¥¢ÂéüÂàô:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 227/400 [58:59<37:15, 12.92s/it]Ê£ÄÁ¥¢ÂéüÂàô:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 228/400 [59:30<50:58, 17.78s/it]Ê£ÄÁ¥¢ÂéüÂàô:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 231/400 [59:59<37:55, 13.46s/it]Ê£ÄÁ¥¢ÂéüÂàô:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 232/400 [1:00:35<50:12, 17.93s/it]Ê£ÄÁ¥¢ÂéüÂàô:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 233/400 [1:01:05<57:49, 20.78s/it]Ê£ÄÁ¥¢ÂéüÂàô:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 234/400 [1:01:35<1:03:42, 23.03s/it]Ê£ÄÁ¥¢ÂéüÂàô:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 235/400 [1:02:07<1:10:00, 25.46s/it]Ê£ÄÁ¥¢ÂéüÂàô:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 236/400 [1:02:38<1:13:08, 26.76s/it]Ê£ÄÁ¥¢ÂéüÂàô:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 237/400 [1:02:42<55:32, 20.45s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 239/400 [1:03:12<48:20, 18.02s/it]Ê£ÄÁ¥¢ÂéüÂàô:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 240/400 [1:03:42<55:39, 20.87s/it]Ê£ÄÁ¥¢ÂéüÂàô:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 241/400 [1:03:52<48:22, 18.25s/it]Ê£ÄÁ¥¢ÂéüÂàô:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 242/400 [1:04:22<56:09, 21.32s/it]Ê£ÄÁ¥¢ÂéüÂàô:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 243/400 [1:04:52<1:01:59, 23.69s/it]Ê£ÄÁ¥¢ÂéüÂàô:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 244/400 [1:04:56<47:10, 18.14s/it]  Ê£ÄÁ¥¢ÂéüÂàô:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 245/400 [1:04:57<34:20, 13.29s/it]Ê£ÄÁ¥¢ÂéüÂàô:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 246/400 [1:05:11<34:12, 13.33s/it]Ê£ÄÁ¥¢ÂéüÂàô:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 248/400 [1:05:40<35:19, 13.94s/it]Ê£ÄÁ¥¢ÂéüÂàô:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 249/400 [1:05:46<29:58, 11.91s/it]Ê£ÄÁ¥¢ÂéüÂàô:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 250/400 [1:06:00<31:35, 12.64s/it]Ê£ÄÁ¥¢ÂéüÂàô:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 251/400 [1:06:03<24:53, 10.03s/it]Ê£ÄÁ¥¢ÂéüÂàô:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 252/400 [1:06:07<20:33,  8.34s/it]Ê£ÄÁ¥¢ÂéüÂàô:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 253/400 [1:06:37<35:12, 14.37s/it]Ê£ÄÁ¥¢ÂéüÂàô:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 255/400 [1:07:08<35:52, 14.84s/it]Ê£ÄÁ¥¢ÂéüÂàô:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 256/400 [1:07:12<29:16, 12.20s/it]Ê£ÄÁ¥¢ÂéüÂàô:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 258/400 [1:07:19<20:24,  8.62s/it]Ê£ÄÁ¥¢ÂéüÂàô:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 260/400 [1:07:49<25:57, 11.12s/it]Ê£ÄÁ¥¢ÂéüÂàô:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 261/400 [1:08:22<36:06, 15.59s/it]Ê£ÄÁ¥¢ÂéüÂàô:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 262/400 [1:08:55<45:12, 19.66s/it]Ê£ÄÁ¥¢ÂéüÂàô:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 263/400 [1:09:25<50:33, 22.14s/it]Ê£ÄÁ¥¢ÂéüÂàô:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 264/400 [1:09:54<54:34, 24.08s/it]Ê£ÄÁ¥¢ÂéüÂàô:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 265/400 [1:09:58<41:53, 18.62s/it]Ê£ÄÁ¥¢ÂéüÂàô:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 266/400 [1:10:10<37:31, 16.80s/it]Ê£ÄÁ¥¢ÂéüÂàô:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 267/400 [1:10:43<47:00, 21.21s/it]Ê£ÄÁ¥¢ÂéüÂàô:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 269/400 [1:11:12<39:57, 18.30s/it]Ê£ÄÁ¥¢ÂéüÂàô:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 270/400 [1:11:44<46:39, 21.53s/it]Ê£ÄÁ¥¢ÂéüÂàô:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 271/400 [1:12:09<48:26, 22.53s/it]Ê£ÄÁ¥¢ÂéüÂàô:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 273/400 [1:12:13<29:18, 13.84s/it]Ê£ÄÁ¥¢ÂéüÂàô:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 274/400 [1:12:32<31:31, 15.01s/it]Ê£ÄÁ¥¢ÂéüÂàô:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 275/400 [1:13:03<39:41, 19.05s/it]Ê£ÄÁ¥¢ÂéüÂàô:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 276/400 [1:13:33<45:16, 21.91s/it]Ê£ÄÁ¥¢ÂéüÂàô:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 278/400 [1:14:03<38:33, 18.97s/it]Ê£ÄÁ¥¢ÂéüÂàô:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 279/400 [1:14:33<43:20, 21.49s/it]Ê£ÄÁ¥¢ÂéüÂàô:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 281/400 [1:14:47<30:58, 15.61s/it]Ê£ÄÁ¥¢ÂéüÂàô:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 282/400 [1:15:17<36:58, 18.80s/it]Ê£ÄÁ¥¢ÂéüÂàô:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 283/400 [1:15:47<41:55, 21.50s/it]Ê£ÄÁ¥¢ÂéüÂàô:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 284/400 [1:16:16<45:30, 23.54s/it]Ê£ÄÁ¥¢ÂéüÂàô:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 285/400 [1:16:20<35:12, 18.37s/it]Ê£ÄÁ¥¢ÂéüÂàô:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 286/400 [1:16:50<41:02, 21.60s/it]Ê£ÄÁ¥¢ÂéüÂàô:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 287/400 [1:16:54<31:17, 16.62s/it]Ê£ÄÁ¥¢ÂéüÂàô:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 288/400 [1:17:33<42:48, 22.93s/it]Ê£ÄÁ¥¢ÂéüÂàô:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 289/400 [1:18:03<46:27, 25.11s/it]Ê£ÄÁ¥¢ÂéüÂàô:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 293/400 [1:18:35<25:30, 14.31s/it]Ê£ÄÁ¥¢ÂéüÂàô:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 294/400 [1:18:39<21:57, 12.43s/it]Ê£ÄÁ¥¢ÂéüÂàô:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 296/400 [1:18:43<15:23,  8.88s/it]Ê£ÄÁ¥¢ÂéüÂàô:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 297/400 [1:18:47<13:36,  7.93s/it]Ê£ÄÁ¥¢ÂéüÂàô:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 298/400 [1:19:19<22:28, 13.22s/it]Ê£ÄÁ¥¢ÂéüÂàô:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 300/400 [1:19:49<23:07, 13.87s/it]Ê£ÄÁ¥¢ÂéüÂàô:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 301/400 [1:20:19<28:33, 17.31s/it]Ê£ÄÁ¥¢ÂéüÂàô:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 302/400 [1:20:48<33:01, 20.22s/it]Ê£ÄÁ¥¢ÂéüÂàô:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 303/400 [1:21:20<37:21, 23.11s/it]Ê£ÄÁ¥¢ÂéüÂàô:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 307/400 [1:21:50<21:32, 13.89s/it]Ê£ÄÁ¥¢ÂéüÂàô:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 308/400 [1:21:54<18:40, 12.18s/it]Ê£ÄÁ¥¢ÂéüÂàô:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 309/400 [1:22:24<23:47, 15.69s/it]Ê£ÄÁ¥¢ÂéüÂàô:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 310/400 [1:22:54<28:29, 18.99s/it]Ê£ÄÁ¥¢ÂéüÂàô:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 312/400 [1:23:24<25:33, 17.42s/it]Ê£ÄÁ¥¢ÂéüÂàô:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 313/400 [1:23:55<29:18, 20.22s/it]Ê£ÄÁ¥¢ÂéüÂàô:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 314/400 [1:24:25<32:16, 22.52s/it]Ê£ÄÁ¥¢ÂéüÂàô:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 315/400 [1:24:35<27:34, 19.47s/it]Ê£ÄÁ¥¢ÂéüÂàô:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 316/400 [1:24:37<20:38, 14.74s/it]Ê£ÄÁ¥¢ÂéüÂàô:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 317/400 [1:25:07<26:11, 18.93s/it]Ê£ÄÁ¥¢ÂéüÂàô:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 319/400 [1:25:36<23:06, 17.12s/it]Ê£ÄÁ¥¢ÂéüÂàô:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 320/400 [1:26:01<25:08, 18.86s/it]Ê£ÄÁ¥¢ÂéüÂàô:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 321/400 [1:26:31<28:33, 21.69s/it]Ê£ÄÁ¥¢ÂéüÂàô:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 322/400 [1:27:00<30:57, 23.82s/it]Ê£ÄÁ¥¢ÂéüÂàô:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 323/400 [1:27:04<23:32, 18.34s/it]Ê£ÄÁ¥¢ÂéüÂàô:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 324/400 [1:27:34<27:24, 21.64s/it]Ê£ÄÁ¥¢ÂéüÂàô:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 325/400 [1:27:45<22:58, 18.38s/it]Ê£ÄÁ¥¢ÂéüÂàô:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 326/400 [1:28:21<29:11, 23.67s/it]Ê£ÄÁ¥¢ÂéüÂàô:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 327/400 [1:28:51<30:59, 25.47s/it]Ê£ÄÁ¥¢ÂéüÂàô:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 328/400 [1:29:20<32:00, 26.67s/it]Ê£ÄÁ¥¢ÂéüÂàô:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 329/400 [1:29:50<32:34, 27.53s/it]Ê£ÄÁ¥¢ÂéüÂàô:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 330/400 [1:30:20<32:58, 28.26s/it]Ê£ÄÁ¥¢ÂéüÂàô:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 331/400 [1:30:24<24:15, 21.09s/it]Ê£ÄÁ¥¢ÂéüÂàô:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 332/400 [1:30:54<26:47, 23.64s/it]Ê£ÄÁ¥¢ÂéüÂàô:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 333/400 [1:30:56<19:18, 17.29s/it]Ê£ÄÁ¥¢ÂéüÂàô:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 334/400 [1:30:57<13:33, 12.33s/it]Ê£ÄÁ¥¢ÂéüÂàô:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 335/400 [1:31:27<19:02, 17.58s/it]Ê£ÄÁ¥¢ÂéüÂàô:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 336/400 [1:31:31<14:25, 13.52s/it]Ê£ÄÁ¥¢ÂéüÂàô:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 337/400 [1:32:02<19:54, 18.95s/it]Ê£ÄÁ¥¢ÂéüÂàô:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 338/400 [1:32:32<22:59, 22.25s/it]Ê£ÄÁ¥¢ÂéüÂàô:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 340/400 [1:33:03<18:57, 18.96s/it]Ê£ÄÁ¥¢ÂéüÂàô:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 341/400 [1:33:34<21:44, 22.10s/it]Ê£ÄÁ¥¢ÂéüÂàô:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 342/400 [1:34:04<23:23, 24.19s/it]Ê£ÄÁ¥¢ÂéüÂàô:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 343/400 [1:34:35<24:33, 25.84s/it]Ê£ÄÁ¥¢ÂéüÂàô:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 344/400 [1:35:05<25:16, 27.08s/it]Ê£ÄÁ¥¢ÂéüÂàô:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 347/400 [1:35:34<15:28, 17.51s/it]Ê£ÄÁ¥¢ÂéüÂàô:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 350/400 [1:35:53<10:33, 12.68s/it]Ê£ÄÁ¥¢ÂéüÂàô:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 351/400 [1:36:23<12:48, 15.68s/it]Ê£ÄÁ¥¢ÂéüÂàô:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 352/400 [1:36:53<14:47, 18.48s/it]Ê£ÄÁ¥¢ÂéüÂàô:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 353/400 [1:37:23<16:30, 21.07s/it]Ê£ÄÁ¥¢ÂéüÂàô:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 354/400 [1:37:54<17:54, 23.36s/it]Ê£ÄÁ¥¢ÂéüÂàô:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 357/400 [1:38:24<11:52, 16.56s/it]Ê£ÄÁ¥¢ÂéüÂàô:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 358/400 [1:38:53<13:21, 19.09s/it]Ê£ÄÁ¥¢ÂéüÂàô:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 359/400 [1:39:24<14:50, 21.71s/it]Ê£ÄÁ¥¢ÂéüÂàô:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 360/400 [1:39:54<15:46, 23.66s/it]Ê£ÄÁ¥¢ÂéüÂàô:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 361/400 [1:39:58<12:09, 18.70s/it]Ê£ÄÁ¥¢ÂéüÂàô:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 362/400 [1:40:29<13:47, 21.78s/it]Ê£ÄÁ¥¢ÂéüÂàô:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 365/400 [1:40:59<09:02, 15.50s/it]Ê£ÄÁ¥¢ÂéüÂàô:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 368/400 [1:41:29<07:00, 13.13s/it]Ê£ÄÁ¥¢ÂéüÂàô:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 370/400 [1:41:32<04:56,  9.88s/it]Ê£ÄÁ¥¢ÂéüÂàô:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 371/400 [1:42:08<06:52, 14.23s/it]Ê£ÄÁ¥¢ÂéüÂàô:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 372/400 [1:42:41<08:26, 18.08s/it]Ê£ÄÁ¥¢ÂéüÂàô:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 373/400 [1:42:42<06:24, 14.26s/it]Ê£ÄÁ¥¢ÂéüÂàô:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 374/400 [1:42:50<05:31, 12.76s/it]Ê£ÄÁ¥¢ÂéüÂàô:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 375/400 [1:43:20<07:07, 17.08s/it]Ê£ÄÁ¥¢ÂéüÂàô:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 376/400 [1:43:50<08:15, 20.66s/it]Ê£ÄÁ¥¢ÂéüÂàô:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 377/400 [1:44:21<08:59, 23.48s/it]Ê£ÄÁ¥¢ÂéüÂàô:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 378/400 [1:44:32<07:16, 19.85s/it]Ê£ÄÁ¥¢ÂéüÂàô:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 379/400 [1:45:02<07:58, 22.80s/it]Ê£ÄÁ¥¢ÂéüÂàô:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 381/400 [1:45:32<06:06, 19.31s/it]Ê£ÄÁ¥¢ÂéüÂàô:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 382/400 [1:45:54<05:57, 19.85s/it]Ê£ÄÁ¥¢ÂéüÂàô:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 383/400 [1:45:56<04:20, 15.29s/it]Ê£ÄÁ¥¢ÂéüÂàô:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 385/400 [1:46:26<03:47, 15.15s/it]Ê£ÄÁ¥¢ÂéüÂàô:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 386/400 [1:46:30<02:55, 12.57s/it]Ê£ÄÁ¥¢ÂéüÂàô:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 388/400 [1:46:42<01:59,  9.98s/it]Ê£ÄÁ¥¢ÂéüÂàô:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 389/400 [1:47:13<02:42, 14.73s/it]Ê£ÄÁ¥¢ÂéüÂàô:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 390/400 [1:47:43<03:02, 18.29s/it]Ê£ÄÁ¥¢ÂéüÂàô:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 391/400 [1:48:12<03:10, 21.17s/it]Ê£ÄÁ¥¢ÂéüÂàô:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 392/400 [1:48:16<02:11, 16.40s/it]Ê£ÄÁ¥¢ÂéüÂàô:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 393/400 [1:48:46<02:21, 20.22s/it]Ê£ÄÁ¥¢ÂéüÂàô:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 394/400 [1:49:15<02:17, 22.85s/it]Ê£ÄÁ¥¢ÂéüÂàô:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 395/400 [1:49:36<01:50, 22.13s/it]Ê£ÄÁ¥¢ÂéüÂàô:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 397/400 [1:49:40<00:39, 13.06s/it]Ê£ÄÁ¥¢ÂéüÂàô: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 399/400 [1:49:52<00:10, 10.23s/it]Ê£ÄÁ¥¢ÂéüÂàô: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [1:49:52<00:00, 16.48s/it]
2026-01-02 23:36:04,138 - __main__ - INFO - ÊàêÂäüËß£Êûê‰ªªÂä°ÊèèËø∞: 307 Êù°
2026-01-02 23:36:04,139 - __main__ - INFO -   - ÊâæÂà∞ÂéüÂàô: 134 Êù°
2026-01-02 23:36:04,139 - __main__ - INFO -   - Êú™ÊâæÂà∞ÂéüÂàôÔºàÂ∞ÜÁõ¥Êé•ÂõûÁ≠îÔºâ: 173 Êù°
2026-01-02 23:36:04,140 - __main__ - INFO - Ëß£ÊûêÂ§±Ë¥•: 93 Êù°
2026-01-02 23:36:04,140 - __main__ - INFO -   - Á©∫ÂìçÂ∫î: 0 Êù°
2026-01-02 23:36:04,140 - __main__ - INFO -   - JSONËß£ÊûêÂ§±Ë¥•: 93 Êù°
2026-01-02 23:36:04,140 - __main__ - INFO - ============================================================
2026-01-02 23:36:04,140 - __main__ - INFO - Ê≠•È™§ 3/3: ÊâπÈáèÁîüÊàêÁ≠îÊ°à
2026-01-02 23:36:04,140 - __main__ - INFO - ============================================================
2026-01-02 23:36:04,140 - __main__ - INFO - Â∞ÜÂàÜ 2 ÊâπÂ§ÑÁêÜÔºàÊØèÊâπ 256 Êù°Ôºâ
ÁîüÊàêÁ≠îÊ°à:   0%|          | 0/2 [00:00<?, ?it/s]ÁîüÊàêÁ≠îÊ°à:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [01:05<01:05, 65.78s/it]ÁîüÊàêÁ≠îÊ°à: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:52<00:00, 54.76s/it]ÁîüÊàêÁ≠îÊ°à: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:52<00:00, 56.42s/it]
2026-01-02 23:37:56,973 - __main__ - INFO - Á≠îÊ°àÁîüÊàêÂÆåÊàê: 307 Êù°
2026-01-02 23:37:56,974 - __main__ - INFO - ============================================================
2026-01-02 23:37:56,974 - __main__ - INFO - ÁªÑË£ÖÁªìÊûú
2026-01-02 23:37:56,974 - __main__ - INFO - ============================================================
2026-01-02 23:37:57,000 - __main__ - INFO - ============================================================
2026-01-02 23:37:57,000 - __main__ - INFO - ÂºÄÂßãËÆ°ÁÆóÂáÜÁ°ÆÁéá
2026-01-02 23:37:57,000 - __main__ - INFO - ============================================================
2026-01-02 23:37:57,034 - __main__ - INFO - 
============================================================
2026-01-02 23:37:57,034 - __main__ - INFO - ÂáÜÁ°ÆÁéáÊä•Âëä
2026-01-02 23:37:57,034 - __main__ - INFO - ============================================================
2026-01-02 23:37:57,035 - __main__ - INFO - ÊÄª‰ΩìÂáÜÁ°ÆÁéá: 103/307 = 33.55%
2026-01-02 23:37:57,035 - __main__ - INFO - 
ÁªìÊûúÂ∑≤‰øùÂ≠ò:
2026-01-02 23:37:57,035 - __main__ - INFO -   - Êé®ÁêÜÁªìÊûú: /home/metanew2/output/local_inference_round2.json
2026-01-02 23:37:57,035 - __main__ - INFO -   - Â∏¶ÂáÜÁ°ÆÁéáÊ†áÊ≥®: /home/metanew2/output/local_inference_with_accuracy.json
2026-01-02 23:37:57,035 - __main__ - INFO -   - ÂáÜÁ°ÆÁéáÁªüËÆ°: /home/metanew2/output/accuracy_stats.json
2026-01-02 23:37:57,035 - __main__ - INFO - 
Êé®ÁêÜÂÆåÊàê!
2026-01-02 23:37:57,035 - __main__ - INFO -   - ÊàêÂäüÊé®ÁêÜ: 307 È°π
2026-01-02 23:37:57,035 - __main__ - INFO -   - Êú™ÊâæÂà∞ÂéüÂàô: 93 È°π
2026-01-02 23:37:57,035 - __main__ - INFO -   - ÊÄªÊï∞ÊçÆÈáè: 400 È°π
2026-01-02 23:38:02,124 - inference.local_inference - INFO - Ê∏ÖÁêÜvLLMÊ®°Âûã...
2026-01-02 23:38:02,169 - inference.local_inference - INFO - CUDAÁºìÂ≠òÂ∑≤Ê∏ÖÁêÜ
